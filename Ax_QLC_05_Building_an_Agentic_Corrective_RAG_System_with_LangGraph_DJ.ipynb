{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5487f8fd22d6479d944869b09c267b0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a1b39e930d01402f937cfe37fc61a5f5",
              "IPY_MODEL_2eb811af1ece47efb5dfa86741a40e81",
              "IPY_MODEL_ec5f6a7c7e4d4b969e669424baae01f6"
            ],
            "layout": "IPY_MODEL_f1505f399f1a44ad8b93ce66bc9dbc08"
          }
        },
        "a1b39e930d01402f937cfe37fc61a5f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_826edc7b32044d0ca0dcc35f4165b2b4",
            "placeholder": "​",
            "style": "IPY_MODEL_35dddfcfe8684631a960c19f01792097",
            "value": "modules.json: 100%"
          }
        },
        "2eb811af1ece47efb5dfa86741a40e81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fb73d85ac174f9b95e38cdac671bb11",
            "max": 229,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_75bd2e8808b84d018a99fdf9b79f1549",
            "value": 229
          }
        },
        "ec5f6a7c7e4d4b969e669424baae01f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be5048d85fe645f084f12f2899af1197",
            "placeholder": "​",
            "style": "IPY_MODEL_2d242557ce924adcb8ffc6fea1d7d82d",
            "value": " 229/229 [00:00&lt;00:00, 19.0kB/s]"
          }
        },
        "f1505f399f1a44ad8b93ce66bc9dbc08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "826edc7b32044d0ca0dcc35f4165b2b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35dddfcfe8684631a960c19f01792097": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3fb73d85ac174f9b95e38cdac671bb11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75bd2e8808b84d018a99fdf9b79f1549": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "be5048d85fe645f084f12f2899af1197": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d242557ce924adcb8ffc6fea1d7d82d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e99897710524d9991c2989e9e1bf054": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_12461d3926fd404fa3dcf6e44c3d2921",
              "IPY_MODEL_4f882f573c154e058baa97922d047937",
              "IPY_MODEL_6baf1c6911ff4692b0a631f4fafadf78"
            ],
            "layout": "IPY_MODEL_e88de669fcba492aba085fbdc74edfa8"
          }
        },
        "12461d3926fd404fa3dcf6e44c3d2921": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f6db6c974d442258db86bd9323a304d",
            "placeholder": "​",
            "style": "IPY_MODEL_52c21c5569a04560bdc15e19a58e58d6",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "4f882f573c154e058baa97922d047937": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9f2b789655f49a7948cb392d6f955b9",
            "max": 266,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_25eb9a5ac7cf4a59af90c6090c125bef",
            "value": 266
          }
        },
        "6baf1c6911ff4692b0a631f4fafadf78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_132f2bd1342843278589d6f116eb68e5",
            "placeholder": "​",
            "style": "IPY_MODEL_d72cecb659ca4ecb8a8fa4ac3b188d29",
            "value": " 266/266 [00:00&lt;00:00, 29.2kB/s]"
          }
        },
        "e88de669fcba492aba085fbdc74edfa8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f6db6c974d442258db86bd9323a304d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52c21c5569a04560bdc15e19a58e58d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9f2b789655f49a7948cb392d6f955b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25eb9a5ac7cf4a59af90c6090c125bef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "132f2bd1342843278589d6f116eb68e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d72cecb659ca4ecb8a8fa4ac3b188d29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a7c35280aa849ffb8aa8c9662975b22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ded220bbf21e4c17b148ad9e43e69b6c",
              "IPY_MODEL_c047d1dd0c1643d39e20de0e995c7102",
              "IPY_MODEL_2f726b2633e5449489d932fa2891057d"
            ],
            "layout": "IPY_MODEL_6ebea7b499124f689798fae4a8c591f9"
          }
        },
        "ded220bbf21e4c17b148ad9e43e69b6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_449a7b12b19f46649079d3b0d9b2c53e",
            "placeholder": "​",
            "style": "IPY_MODEL_656f7bd3289a4209a2a0274403854e99",
            "value": "README.md: 100%"
          }
        },
        "c047d1dd0c1643d39e20de0e995c7102": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d9f8e84f5484aa0a645a8997fa9abe0",
            "max": 114063,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9f57612cc1e848709e05a6484f31013d",
            "value": 114063
          }
        },
        "2f726b2633e5449489d932fa2891057d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_446debb9ff3649c1b8dbc5618df0fec9",
            "placeholder": "​",
            "style": "IPY_MODEL_ad628f348ac143e990e02a197a85c159",
            "value": " 114k/114k [00:00&lt;00:00, 10.5MB/s]"
          }
        },
        "6ebea7b499124f689798fae4a8c591f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "449a7b12b19f46649079d3b0d9b2c53e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "656f7bd3289a4209a2a0274403854e99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d9f8e84f5484aa0a645a8997fa9abe0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f57612cc1e848709e05a6484f31013d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "446debb9ff3649c1b8dbc5618df0fec9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad628f348ac143e990e02a197a85c159": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb603fd1d96f400e8cceb93b35a173fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d8b2f292aef34741a3e7816ec1419c30",
              "IPY_MODEL_6ffe676b960c468db707721ae8cb4a7a",
              "IPY_MODEL_234b5cda9bfc4e989c54729032d36121"
            ],
            "layout": "IPY_MODEL_4c91cfddc87f4f468bcb043ad92bd050"
          }
        },
        "d8b2f292aef34741a3e7816ec1419c30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_241a6f57d0b245c39805617c32c05cd2",
            "placeholder": "​",
            "style": "IPY_MODEL_ec8155b77343451aa6b26e6dd1f4e594",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "6ffe676b960c468db707721ae8cb4a7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_547d78b081354149a5e0a7ebc4026b79",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d0bd029888494224bf37e8a4c4615e87",
            "value": 53
          }
        },
        "234b5cda9bfc4e989c54729032d36121": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d57206f638b148ebb4aa0a382775c4d4",
            "placeholder": "​",
            "style": "IPY_MODEL_3385c4de78434feb86420e5513007fb0",
            "value": " 53.0/53.0 [00:00&lt;00:00, 5.40kB/s]"
          }
        },
        "4c91cfddc87f4f468bcb043ad92bd050": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "241a6f57d0b245c39805617c32c05cd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec8155b77343451aa6b26e6dd1f4e594": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "547d78b081354149a5e0a7ebc4026b79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0bd029888494224bf37e8a4c4615e87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d57206f638b148ebb4aa0a382775c4d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3385c4de78434feb86420e5513007fb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "039182ccbd7b49b29d8023bf6ad8ba05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a5cac565479d408397a2137f9704d4c9",
              "IPY_MODEL_bf35dea17c184a7eb9c03b45436968ce",
              "IPY_MODEL_117313afabf14c1da9f5d614d8d81215"
            ],
            "layout": "IPY_MODEL_633ccaf088ad4a6694d9353f23b34a8a"
          }
        },
        "a5cac565479d408397a2137f9704d4c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0bb1ef123ea4734a213e75b82b87a13",
            "placeholder": "​",
            "style": "IPY_MODEL_e58b3b834c2a4740b289529fb12496c0",
            "value": "config.json: 100%"
          }
        },
        "bf35dea17c184a7eb9c03b45436968ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a67fa6eba653408c96577c8686f2eb7a",
            "max": 677,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e8698f2f5e244097bdaff3ab9765a575",
            "value": 677
          }
        },
        "117313afabf14c1da9f5d614d8d81215": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2530db1bb0b84f3f868255092eec5bf1",
            "placeholder": "​",
            "style": "IPY_MODEL_db4e005f36384aaeba9dd00c6c9f538f",
            "value": " 677/677 [00:00&lt;00:00, 64.0kB/s]"
          }
        },
        "633ccaf088ad4a6694d9353f23b34a8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0bb1ef123ea4734a213e75b82b87a13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e58b3b834c2a4740b289529fb12496c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a67fa6eba653408c96577c8686f2eb7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8698f2f5e244097bdaff3ab9765a575": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2530db1bb0b84f3f868255092eec5bf1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db4e005f36384aaeba9dd00c6c9f538f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f89180695b2422594ccdc6a269296c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e0af365d0d494120b9be7bfaa2297340",
              "IPY_MODEL_7d34b576ffd440c38015325d771e1d14",
              "IPY_MODEL_0b88e689dbe248209a3d89ed56ce5c45"
            ],
            "layout": "IPY_MODEL_2d81c872b1e541aeb58a034da34f2be5"
          }
        },
        "e0af365d0d494120b9be7bfaa2297340": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6ded7214fcc454f869d9240f5a111c6",
            "placeholder": "​",
            "style": "IPY_MODEL_fb332cc010ac4f8c8720219282480730",
            "value": "model.safetensors: 100%"
          }
        },
        "7d34b576ffd440c38015325d771e1d14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9ce59034fe74c7db8083b2e327b23f7",
            "max": 670328392,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_57867ed8a387407baf6ea73d76b7ef06",
            "value": 670328392
          }
        },
        "0b88e689dbe248209a3d89ed56ce5c45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd3e22fa22b24e9398b6ad4e90b28c71",
            "placeholder": "​",
            "style": "IPY_MODEL_f23cec91f9a64606bdf2d5bacfa22394",
            "value": " 670M/670M [00:16&lt;00:00, 42.6MB/s]"
          }
        },
        "2d81c872b1e541aeb58a034da34f2be5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6ded7214fcc454f869d9240f5a111c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb332cc010ac4f8c8720219282480730": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9ce59034fe74c7db8083b2e327b23f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57867ed8a387407baf6ea73d76b7ef06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dd3e22fa22b24e9398b6ad4e90b28c71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f23cec91f9a64606bdf2d5bacfa22394": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a74ad8662f04810bec5727cdde4b158": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a547a92c9c28401282a1a3c8bdcc5102",
              "IPY_MODEL_37f79a6e4f9144138308e31486f0996f",
              "IPY_MODEL_02400aad8c774014807eb3f2d7880705"
            ],
            "layout": "IPY_MODEL_1b162edf156e4c93ae1aeebbfc653be1"
          }
        },
        "a547a92c9c28401282a1a3c8bdcc5102": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_affcfcb1ec3147eea67107be48393ab6",
            "placeholder": "​",
            "style": "IPY_MODEL_711f14699d124201aed25802e1503666",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "37f79a6e4f9144138308e31486f0996f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4dc840f92994df9b9642ea2f0fc7aa5",
            "max": 1242,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_24169194eb4c45158bfe034c21ff3a9c",
            "value": 1242
          }
        },
        "02400aad8c774014807eb3f2d7880705": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bc2875c7adb4a20ab120ae5ede9e30c",
            "placeholder": "​",
            "style": "IPY_MODEL_8dac924372d440979415267dd462b025",
            "value": " 1.24k/1.24k [00:00&lt;00:00, 137kB/s]"
          }
        },
        "1b162edf156e4c93ae1aeebbfc653be1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "affcfcb1ec3147eea67107be48393ab6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "711f14699d124201aed25802e1503666": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4dc840f92994df9b9642ea2f0fc7aa5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24169194eb4c45158bfe034c21ff3a9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4bc2875c7adb4a20ab120ae5ede9e30c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dac924372d440979415267dd462b025": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3c80a8bf30a4cb8b8e97e0e83e2e547": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f8215c0bff26402385de6e22fde801eb",
              "IPY_MODEL_64b3e2ce05e54a62923490d151b3579c",
              "IPY_MODEL_bdac9e420ecf4f79a7aa4a80e0f04a0d"
            ],
            "layout": "IPY_MODEL_36d0aadaee724bcfb916a8fa39180579"
          }
        },
        "f8215c0bff26402385de6e22fde801eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07c925e5eea046bebc5ebf9128794179",
            "placeholder": "​",
            "style": "IPY_MODEL_19e91c1d64ba4013adec5ed5736cce13",
            "value": "vocab.txt: 100%"
          }
        },
        "64b3e2ce05e54a62923490d151b3579c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_842ab30e1cb1439780ccef41ba80d6fb",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0034ee0a8df94b6da610ec72eab54921",
            "value": 231508
          }
        },
        "bdac9e420ecf4f79a7aa4a80e0f04a0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28dc4f6ef1bd4968be6eb327a3726a61",
            "placeholder": "​",
            "style": "IPY_MODEL_32928ad6413740e489278c3710e6ca6a",
            "value": " 232k/232k [00:00&lt;00:00, 16.6MB/s]"
          }
        },
        "36d0aadaee724bcfb916a8fa39180579": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07c925e5eea046bebc5ebf9128794179": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19e91c1d64ba4013adec5ed5736cce13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "842ab30e1cb1439780ccef41ba80d6fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0034ee0a8df94b6da610ec72eab54921": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "28dc4f6ef1bd4968be6eb327a3726a61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32928ad6413740e489278c3710e6ca6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "288ee73854684c9a8da1055a019867f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b87c788a7cda4aaf9e4750413fc29c85",
              "IPY_MODEL_b4f84d5880df46d3b48fd2ba39d7266d",
              "IPY_MODEL_987ba920693a4f11977419b19f482552"
            ],
            "layout": "IPY_MODEL_329dfc0be5334dd99f06e345c1c0efce"
          }
        },
        "b87c788a7cda4aaf9e4750413fc29c85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cebb840ed4df4ba5a2513015a53273d4",
            "placeholder": "​",
            "style": "IPY_MODEL_a4bea1460e24480e8f104e8206b1559e",
            "value": "tokenizer.json: 100%"
          }
        },
        "b4f84d5880df46d3b48fd2ba39d7266d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa8b8fa253dd4dc3920dedabd19aa66a",
            "max": 711396,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d3c512cde7da4f7e9e862ee964513488",
            "value": 711396
          }
        },
        "987ba920693a4f11977419b19f482552": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec87acf4145f4bde9e9bc4d3d032231f",
            "placeholder": "​",
            "style": "IPY_MODEL_1f09bfe4296243fb8fa64c5fd7877482",
            "value": " 711k/711k [00:00&lt;00:00, 42.1MB/s]"
          }
        },
        "329dfc0be5334dd99f06e345c1c0efce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cebb840ed4df4ba5a2513015a53273d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4bea1460e24480e8f104e8206b1559e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa8b8fa253dd4dc3920dedabd19aa66a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3c512cde7da4f7e9e862ee964513488": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ec87acf4145f4bde9e9bc4d3d032231f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f09bfe4296243fb8fa64c5fd7877482": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50e023aab818487283a79b628e3ad8c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_89e1c7c707e349eebe70498e28b5808c",
              "IPY_MODEL_9e84c597035d46889801a0b4f3edc207",
              "IPY_MODEL_8b43b922a6a94d96998ee42a2a573855"
            ],
            "layout": "IPY_MODEL_fd87ef42f36b4e3999b5d9b3b52f8d88"
          }
        },
        "89e1c7c707e349eebe70498e28b5808c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ea11c716e6448af948c5d280ccfe940",
            "placeholder": "​",
            "style": "IPY_MODEL_35b4672c16134f2d9116ac6d7ccb031a",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "9e84c597035d46889801a0b4f3edc207": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46913dbe78ff4a02b1a034795e535dad",
            "max": 695,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a6ff8b9a127d4ed68ab222318c44e110",
            "value": 695
          }
        },
        "8b43b922a6a94d96998ee42a2a573855": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2387b3707a9d4cf8a9054ca078abf660",
            "placeholder": "​",
            "style": "IPY_MODEL_a17f2dbddd8640fdbbd3a28eb1c8d12d",
            "value": " 695/695 [00:00&lt;00:00, 72.7kB/s]"
          }
        },
        "fd87ef42f36b4e3999b5d9b3b52f8d88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ea11c716e6448af948c5d280ccfe940": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35b4672c16134f2d9116ac6d7ccb031a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46913dbe78ff4a02b1a034795e535dad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6ff8b9a127d4ed68ab222318c44e110": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2387b3707a9d4cf8a9054ca078abf660": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a17f2dbddd8640fdbbd3a28eb1c8d12d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3dda71a8b8b74c35a7f21afc90bb4de9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8df8b3dd6c09402689ee9f95e6921e58",
              "IPY_MODEL_bd43554041a8484d9aa1809cb191b498",
              "IPY_MODEL_8d5aece249e341299adfb3962d685d6e"
            ],
            "layout": "IPY_MODEL_daf7e029427a4aafb42e9caa8648c26e"
          }
        },
        "8df8b3dd6c09402689ee9f95e6921e58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_758cfce007964e01aa63cc3027bee942",
            "placeholder": "​",
            "style": "IPY_MODEL_c018bef61f2245e097c3cbe72d937c55",
            "value": "1_Pooling%2Fconfig.json: 100%"
          }
        },
        "bd43554041a8484d9aa1809cb191b498": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce5cf0dfb39f4098a43d893b26613da0",
            "max": 297,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8c1bbf5a492a460d95ca8d512e3e4dd2",
            "value": 297
          }
        },
        "8d5aece249e341299adfb3962d685d6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e89024e5fb54bcc934f414a7970be03",
            "placeholder": "​",
            "style": "IPY_MODEL_89b025fbafb5424c81bd7b644dda947c",
            "value": " 297/297 [00:00&lt;00:00, 25.5kB/s]"
          }
        },
        "daf7e029427a4aafb42e9caa8648c26e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "758cfce007964e01aa63cc3027bee942": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c018bef61f2245e097c3cbe72d937c55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce5cf0dfb39f4098a43d893b26613da0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c1bbf5a492a460d95ca8d512e3e4dd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2e89024e5fb54bcc934f414a7970be03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89b025fbafb5424c81bd7b644dda947c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aa1reXo/Agentic-AI/blob/main/Ax_QLC_05_Building_an_Agentic_Corrective_RAG_System_with_LangGraph_DJ.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project - Building an Agentic Corrective RAG System with LangGraph"
      ],
      "metadata": {
        "id": "A_fZFcme18vK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project will cover a full hands-on workflow and demonstration of how to build an Agentic Corrective RAG (CRAG) System with LangGraph\n",
        "\n",
        "The idea would be to implement the workflow taking inspiration from the [Corrective Retrieval Augmented Generation](https://arxiv.org/pdf/2401.15884) research paper.\n",
        "\n",
        "The main challenge of RAG systems include:\n",
        "\n",
        "- Poor Retrieval can lead to issues in LLM response generation\n",
        "- Bad retrieval or lack of information in the vector database can also lead to out of context or hallucinated answers\n",
        "\n",
        "The idea is to couple a RAG system with a few checks in place and perform web searches if there is a lack of relevant context documents to the given user query as follows:\n",
        "\n",
        "![](https://i.imgur.com/uhybMhT.png)\n"
      ],
      "metadata": {
        "id": "NYBpZTjLnEXb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can build this as an agentic RAG system by having a specific functionality step as a node in the graph and use LangGraph to implement it. Key steps in the node will include prompts being sent to LLMs to perform specific tasks as seen in the detailed workflow below:\n",
        "\n",
        "![](https://i.imgur.com/eV87ZwX.gif)\n",
        "\n",
        "\n",
        "___Created By: [Dipanjan (DJ)](https://www.linkedin.com/in/dipanjans/)___\n"
      ],
      "metadata": {
        "id": "aMX5MULw4JXP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install OpenAI, and LangChain dependencies"
      ],
      "metadata": {
        "id": "L1KvMtf54l0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain==0.3.14\n",
        "!pip install langchain-google-genai==2.0.9\n",
        "!pip install langchain-community==0.3.14\n",
        "!pip install langgraph==0.2.64\n",
        "!pip install langchain-huggingface"
      ],
      "metadata": {
        "id": "2evPp14fy258",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "744f0468-dfa8-4644-b3e8-e19fa94c4822"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain==0.3.14\n",
            "  Downloading langchain-0.3.14-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.14) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.14) (2.0.38)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.14) (3.11.12)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.14) (0.3.35)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.14) (0.3.6)\n",
            "Collecting langsmith<0.3,>=0.1.17 (from langchain==0.3.14)\n",
            "  Downloading langsmith-0.2.11-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.14) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.14) (2.10.6)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.14) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.14) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14) (1.18.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain==0.3.14) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain==0.3.14) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain==0.3.14) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.17->langchain==0.3.14) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.17->langchain==0.3.14) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.17->langchain==0.3.14) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.14) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.14) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.3.14) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.3.14) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.3.14) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.3.14) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.14) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.14) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.14) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.14) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain==0.3.14) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.14) (1.3.1)\n",
            "Downloading langchain-0.3.14-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langsmith-0.2.11-py3-none-any.whl (326 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.9/326.9 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langsmith, langchain\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.3.8\n",
            "    Uninstalling langsmith-0.3.8:\n",
            "      Successfully uninstalled langsmith-0.3.8\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.18\n",
            "    Uninstalling langchain-0.3.18:\n",
            "      Successfully uninstalled langchain-0.3.18\n",
            "Successfully installed langchain-0.3.14 langsmith-0.2.11\n",
            "Collecting langchain-google-genai==2.0.9\n",
            "  Downloading langchain_google_genai-2.0.9-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai==2.0.9)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: google-generativeai<0.9.0,>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai==2.0.9) (0.8.4)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.27 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai==2.0.9) (0.3.35)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai==2.0.9) (2.10.6)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.9) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.9) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.9) (2.160.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.9) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.9) (4.25.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.9) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.9) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.9) (1.26.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-google-genai==2.0.9) (0.2.11)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-google-genai==2.0.9) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-google-genai==2.0.9) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-google-genai==2.0.9) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-google-genai==2.0.9) (24.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai==2.0.9) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai==2.0.9) (2.27.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.9) (1.67.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.9) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.9) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.9) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.9) (4.9)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.27->langchain-google-genai==2.0.9) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-google-genai==2.0.9) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-google-genai==2.0.9) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-google-genai==2.0.9) (1.0.0)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.9) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.9) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.9) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.9) (1.70.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.9) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.9) (3.2.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-google-genai==2.0.9) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-google-genai==2.0.9) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-google-genai==2.0.9) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-google-genai==2.0.9) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-google-genai==2.0.9) (0.14.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.9) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.9) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.9) (2.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-google-genai==2.0.9) (1.3.1)\n",
            "Downloading langchain_google_genai-2.0.9-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Installing collected packages: filetype, langchain-google-genai\n",
            "Successfully installed filetype-1.2.0 langchain-google-genai-2.0.9\n",
            "Collecting langchain-community==0.3.14\n",
            "  Downloading langchain_community-0.3.14-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.14) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.14) (2.0.38)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.14) (3.11.12)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community==0.3.14)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community==0.3.14)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.14 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.14) (0.3.14)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.14) (0.3.35)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.14) (0.2.11)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.14) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community==0.3.14)\n",
            "  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.14) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.14) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.14) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.14) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.14) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.14) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.14) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.14) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.14) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.14)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.14)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.14->langchain-community==0.3.14) (0.3.6)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.14->langchain-community==0.3.14) (2.10.6)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain-community==0.3.14) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain-community==0.3.14) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain-community==0.3.14) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community==0.3.14) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community==0.3.14) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community==0.3.14) (1.0.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community==0.3.14)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community==0.3.14) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community==0.3.14) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community==0.3.14) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community==0.3.14) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community==0.3.14) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community==0.3.14) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community==0.3.14) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community==0.3.14) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain-community==0.3.14) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.14->langchain-community==0.3.14) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.14->langchain-community==0.3.14) (2.27.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.14)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community==0.3.14) (1.3.1)\n",
            "Downloading langchain_community-0.3.14-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.14 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.7.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n",
            "Collecting langgraph==0.2.64\n",
            "  Downloading langgraph-0.2.64-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43 in /usr/local/lib/python3.11/dist-packages (from langgraph==0.2.64) (0.3.35)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph==0.2.64)\n",
            "  Downloading langgraph_checkpoint-2.0.16-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph==0.2.64)\n",
            "  Downloading langgraph_sdk-0.1.53-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.64) (0.2.11)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.64) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.64) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.64) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.64) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.64) (4.12.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.64) (2.10.6)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph==0.2.64) (1.1.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.64) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.64) (3.10.15)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.64) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.64) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.64) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.64) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.64) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.64) (3.0.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.64) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.64) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.64) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.64) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.64) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.64) (2.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.64) (1.3.1)\n",
            "Downloading langgraph-0.2.64-py3-none-any.whl (142 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.6/142.6 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.0.16-py3-none-any.whl (38 kB)\n",
            "Downloading langgraph_sdk-0.1.53-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langgraph-sdk, langgraph-checkpoint, langgraph\n",
            "Successfully installed langgraph-0.2.64 langgraph-checkpoint-2.0.16 langgraph-sdk-0.1.53\n",
            "Collecting langchain-huggingface\n",
            "  Downloading langchain_huggingface-0.1.2-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.28.1)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.3.35)\n",
            "Requirement already satisfied: sentence-transformers>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (3.4.1)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.21.0)\n",
            "Requirement already satisfied: transformers>=4.39.0 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (4.48.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.12.2)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.2.11)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.33)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (2.10.6)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.5.1+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (11.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.0->langchain-huggingface) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.0->langchain-huggingface) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.0->langchain-huggingface) (0.5.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2025.1.31)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.5.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.0.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.3.1)\n",
            "Downloading langchain_huggingface-0.1.2-py3-none-any.whl (21 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, langchain-huggingface\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed langchain-huggingface-0.1.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-chroma==0.2.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WFM0a1EoRSUQ",
        "outputId": "7cba9659-8c89-4f9d-a544-35003e3c48af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-chroma==0.2.2\n",
            "  Downloading langchain_chroma-0.2.2-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43 in /usr/local/lib/python3.11/dist-packages (from langchain-chroma==0.2.2) (0.3.35)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain-chroma==0.2.2) (1.26.4)\n",
            "Collecting chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0 (from langchain-chroma==0.2.2)\n",
            "  Downloading chromadb-0.6.3-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting build>=1.0.3 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2)\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (2.10.6)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi>=0.95.2 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2)\n",
            "  Downloading fastapi-0.115.8-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting posthog>=2.4.0 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2)\n",
            "  Downloading posthog-3.14.2-py2.py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (4.12.2)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2)\n",
            "  Downloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (1.16.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.30.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.51b0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (1.16.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (0.21.0)\n",
            "Collecting pypika>=0.48.9 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (4.67.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (1.70.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2)\n",
            "  Downloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (0.15.1)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2)\n",
            "  Downloading kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2)\n",
            "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (3.10.15)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (13.9.4)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-chroma==0.2.2) (0.2.11)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-chroma==0.2.2) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-chroma==0.2.2) (24.2)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting starlette<0.46.0,>=0.40.0 (from fastapi>=0.95.2->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2)\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-chroma==0.2.2) (3.0.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (2.3.0)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2)\n",
            "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-chroma==0.2.2) (1.0.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (4.25.6)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (1.2.18)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (75.1.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (1.67.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.30.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.30.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-proto==1.30.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2)\n",
            "  Downloading opentelemetry_proto-1.30.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2)\n",
            "  Downloading opentelemetry_sdk-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting protobuf (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2)\n",
            "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.51b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-instrumentation==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2)\n",
            "  Downloading opentelemetry_instrumentation-0.51b0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2)\n",
            "  Downloading opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-util-http==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2)\n",
            "  Downloading opentelemetry_util_http-0.51b0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (1.17.2)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2)\n",
            "  Downloading opentelemetry_api-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting importlib-metadata<=8.5.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2)\n",
            "  Downloading importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (2.27.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (0.28.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (1.0.1)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2)\n",
            "  Downloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (14.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (2024.10.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (3.4.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (1.3.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain-chroma==0.2.2) (0.6.1)\n",
            "Downloading langchain_chroma-0.2.2-py3-none-any.whl (11 kB)\n",
            "Downloading chromadb-0.6.3-py3-none-any.whl (611 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Downloading fastapi-0.115.8-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.30.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.30.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.30.0-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.51b0-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.51b0-py3-none-any.whl (30 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.51b0-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl (177 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.30.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_util_http-0.51b0-py3-none-any.whl (7.3 kB)\n",
            "Downloading opentelemetry_sdk-1.30.0-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.14.2-py2.py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.9/73.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n",
            "Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53771 sha256=0d25405faf4149731d5e5af9498ee25248e784db325295a073e31268e85bf839\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, durationpy, uvloop, uvicorn, pyproject_hooks, protobuf, overrides, opentelemetry-util-http, mmh3, importlib-metadata, humanfriendly, httptools, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, starlette, posthog, opentelemetry-proto, opentelemetry-api, coloredlogs, build, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, onnxruntime, kubernetes, fastapi, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb, langchain-chroma\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.6\n",
            "    Uninstalling protobuf-4.25.6:\n",
            "      Successfully uninstalled protobuf-4.25.6\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.6.1\n",
            "    Uninstalling importlib_metadata-8.6.1:\n",
            "      Successfully uninstalled importlib_metadata-8.6.1\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.16.0\n",
            "    Uninstalling opentelemetry-api-1.16.0:\n",
            "      Successfully uninstalled opentelemetry-api-1.16.0\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.37b0\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.37b0:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.37b0\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.16.0\n",
            "    Uninstalling opentelemetry-sdk-1.16.0:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.16.0\n",
            "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.1 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-0.6.3 coloredlogs-15.0.1 durationpy-0.9 fastapi-0.115.8 httptools-0.6.4 humanfriendly-10.0 importlib-metadata-8.5.0 kubernetes-32.0.1 langchain-chroma-0.2.2 mmh3-5.1.0 monotonic-1.6 onnxruntime-1.20.1 opentelemetry-api-1.30.0 opentelemetry-exporter-otlp-proto-common-1.30.0 opentelemetry-exporter-otlp-proto-grpc-1.30.0 opentelemetry-instrumentation-0.51b0 opentelemetry-instrumentation-asgi-0.51b0 opentelemetry-instrumentation-fastapi-0.51b0 opentelemetry-proto-1.30.0 opentelemetry-sdk-1.30.0 opentelemetry-semantic-conventions-0.51b0 opentelemetry-util-http-0.51b0 overrides-7.7.0 posthog-3.14.2 protobuf-5.29.3 pypika-0.48.9 pyproject_hooks-1.2.0 starlette-0.45.3 uvicorn-0.34.0 uvloop-0.21.0 watchfiles-1.0.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "importlib_metadata"
                ]
              },
              "id": "31874a90427d4021b320a95b402b01bf"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enter Open AI API Key"
      ],
      "metadata": {
        "id": "H9c37cLnSrbg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "\n",
        "# OPENAI_KEY = getpass('Enter your OpenAI Key: ')\n",
        "GEMINI_API_KEY = getpass('Enter your Google Gemini API Key: ')"
      ],
      "metadata": {
        "id": "cv3JzCEx_PAd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26ed5d21-a871-4a95-a143-35e7cc36d11e"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Google Gemini API Key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enter Tavily Search API Key\n",
        "\n",
        "Get a free API key from [here](https://tavily.com/#api)"
      ],
      "metadata": {
        "id": "ucWRRI3QztL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TAVILY_API_KEY = getpass('Enter Tavily Search API Key: ')"
      ],
      "metadata": {
        "id": "mK-1WLzOrJdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7811e29-bf5d-4e0b-fe84-67293e8a1ef5"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter Tavily Search API Key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Environment Variables"
      ],
      "metadata": {
        "id": "1T0s0um5Svfa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# os.environ['OPENAI_API_KEY'] = OPENAI_KEY\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GEMINI_API_KEY\n",
        "os.environ['TAVILY_API_KEY'] = TAVILY_API_KEY"
      ],
      "metadata": {
        "id": "x1YSuHNF_lbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build a Search Index for Wikipedia Data\n",
        "\n",
        "We will build a vector database for retrieval and search by taking a subset of documents from wikipedia, similar to our project from previous modules"
      ],
      "metadata": {
        "id": "eXI8uXDtcsCD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Open AI Embedding Models\n",
        "\n",
        "LangChain enables us to access Open AI embedding models which include the newest models: a smaller and highly efficient `text-embedding-3-small` model, and a larger and more powerful `text-embedding-3-large` model."
      ],
      "metadata": {
        "id": "M8nHAP7XOGOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# you can also use huggingface open source model embeddings\n",
        "# make sure to !pip install langchain-huggingface first\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "# check out model details here: https://huggingface.co/mixedbread-ai/mxbai-embed-large-v1\n",
        "model_name = \"mixedbread-ai/mxbai-embed-large-v1\"\n",
        "\n",
        "hf_embed_model = HuggingFaceEmbeddings(\n",
        "    model_name=model_name,\n",
        ")"
      ],
      "metadata": {
        "id": "jzrIVI2NAHC1",
        "outputId": "8629f9ac-2233-4f25-b686-beaa0373715d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493,
          "referenced_widgets": [
            "5487f8fd22d6479d944869b09c267b0e",
            "a1b39e930d01402f937cfe37fc61a5f5",
            "2eb811af1ece47efb5dfa86741a40e81",
            "ec5f6a7c7e4d4b969e669424baae01f6",
            "f1505f399f1a44ad8b93ce66bc9dbc08",
            "826edc7b32044d0ca0dcc35f4165b2b4",
            "35dddfcfe8684631a960c19f01792097",
            "3fb73d85ac174f9b95e38cdac671bb11",
            "75bd2e8808b84d018a99fdf9b79f1549",
            "be5048d85fe645f084f12f2899af1197",
            "2d242557ce924adcb8ffc6fea1d7d82d",
            "4e99897710524d9991c2989e9e1bf054",
            "12461d3926fd404fa3dcf6e44c3d2921",
            "4f882f573c154e058baa97922d047937",
            "6baf1c6911ff4692b0a631f4fafadf78",
            "e88de669fcba492aba085fbdc74edfa8",
            "4f6db6c974d442258db86bd9323a304d",
            "52c21c5569a04560bdc15e19a58e58d6",
            "c9f2b789655f49a7948cb392d6f955b9",
            "25eb9a5ac7cf4a59af90c6090c125bef",
            "132f2bd1342843278589d6f116eb68e5",
            "d72cecb659ca4ecb8a8fa4ac3b188d29",
            "8a7c35280aa849ffb8aa8c9662975b22",
            "ded220bbf21e4c17b148ad9e43e69b6c",
            "c047d1dd0c1643d39e20de0e995c7102",
            "2f726b2633e5449489d932fa2891057d",
            "6ebea7b499124f689798fae4a8c591f9",
            "449a7b12b19f46649079d3b0d9b2c53e",
            "656f7bd3289a4209a2a0274403854e99",
            "6d9f8e84f5484aa0a645a8997fa9abe0",
            "9f57612cc1e848709e05a6484f31013d",
            "446debb9ff3649c1b8dbc5618df0fec9",
            "ad628f348ac143e990e02a197a85c159",
            "eb603fd1d96f400e8cceb93b35a173fc",
            "d8b2f292aef34741a3e7816ec1419c30",
            "6ffe676b960c468db707721ae8cb4a7a",
            "234b5cda9bfc4e989c54729032d36121",
            "4c91cfddc87f4f468bcb043ad92bd050",
            "241a6f57d0b245c39805617c32c05cd2",
            "ec8155b77343451aa6b26e6dd1f4e594",
            "547d78b081354149a5e0a7ebc4026b79",
            "d0bd029888494224bf37e8a4c4615e87",
            "d57206f638b148ebb4aa0a382775c4d4",
            "3385c4de78434feb86420e5513007fb0",
            "039182ccbd7b49b29d8023bf6ad8ba05",
            "a5cac565479d408397a2137f9704d4c9",
            "bf35dea17c184a7eb9c03b45436968ce",
            "117313afabf14c1da9f5d614d8d81215",
            "633ccaf088ad4a6694d9353f23b34a8a",
            "e0bb1ef123ea4734a213e75b82b87a13",
            "e58b3b834c2a4740b289529fb12496c0",
            "a67fa6eba653408c96577c8686f2eb7a",
            "e8698f2f5e244097bdaff3ab9765a575",
            "2530db1bb0b84f3f868255092eec5bf1",
            "db4e005f36384aaeba9dd00c6c9f538f",
            "6f89180695b2422594ccdc6a269296c2",
            "e0af365d0d494120b9be7bfaa2297340",
            "7d34b576ffd440c38015325d771e1d14",
            "0b88e689dbe248209a3d89ed56ce5c45",
            "2d81c872b1e541aeb58a034da34f2be5",
            "b6ded7214fcc454f869d9240f5a111c6",
            "fb332cc010ac4f8c8720219282480730",
            "b9ce59034fe74c7db8083b2e327b23f7",
            "57867ed8a387407baf6ea73d76b7ef06",
            "dd3e22fa22b24e9398b6ad4e90b28c71",
            "f23cec91f9a64606bdf2d5bacfa22394",
            "6a74ad8662f04810bec5727cdde4b158",
            "a547a92c9c28401282a1a3c8bdcc5102",
            "37f79a6e4f9144138308e31486f0996f",
            "02400aad8c774014807eb3f2d7880705",
            "1b162edf156e4c93ae1aeebbfc653be1",
            "affcfcb1ec3147eea67107be48393ab6",
            "711f14699d124201aed25802e1503666",
            "a4dc840f92994df9b9642ea2f0fc7aa5",
            "24169194eb4c45158bfe034c21ff3a9c",
            "4bc2875c7adb4a20ab120ae5ede9e30c",
            "8dac924372d440979415267dd462b025",
            "a3c80a8bf30a4cb8b8e97e0e83e2e547",
            "f8215c0bff26402385de6e22fde801eb",
            "64b3e2ce05e54a62923490d151b3579c",
            "bdac9e420ecf4f79a7aa4a80e0f04a0d",
            "36d0aadaee724bcfb916a8fa39180579",
            "07c925e5eea046bebc5ebf9128794179",
            "19e91c1d64ba4013adec5ed5736cce13",
            "842ab30e1cb1439780ccef41ba80d6fb",
            "0034ee0a8df94b6da610ec72eab54921",
            "28dc4f6ef1bd4968be6eb327a3726a61",
            "32928ad6413740e489278c3710e6ca6a",
            "288ee73854684c9a8da1055a019867f4",
            "b87c788a7cda4aaf9e4750413fc29c85",
            "b4f84d5880df46d3b48fd2ba39d7266d",
            "987ba920693a4f11977419b19f482552",
            "329dfc0be5334dd99f06e345c1c0efce",
            "cebb840ed4df4ba5a2513015a53273d4",
            "a4bea1460e24480e8f104e8206b1559e",
            "aa8b8fa253dd4dc3920dedabd19aa66a",
            "d3c512cde7da4f7e9e862ee964513488",
            "ec87acf4145f4bde9e9bc4d3d032231f",
            "1f09bfe4296243fb8fa64c5fd7877482",
            "50e023aab818487283a79b628e3ad8c3",
            "89e1c7c707e349eebe70498e28b5808c",
            "9e84c597035d46889801a0b4f3edc207",
            "8b43b922a6a94d96998ee42a2a573855",
            "fd87ef42f36b4e3999b5d9b3b52f8d88",
            "6ea11c716e6448af948c5d280ccfe940",
            "35b4672c16134f2d9116ac6d7ccb031a",
            "46913dbe78ff4a02b1a034795e535dad",
            "a6ff8b9a127d4ed68ab222318c44e110",
            "2387b3707a9d4cf8a9054ca078abf660",
            "a17f2dbddd8640fdbbd3a28eb1c8d12d",
            "3dda71a8b8b74c35a7f21afc90bb4de9",
            "8df8b3dd6c09402689ee9f95e6921e58",
            "bd43554041a8484d9aa1809cb191b498",
            "8d5aece249e341299adfb3962d685d6e",
            "daf7e029427a4aafb42e9caa8648c26e",
            "758cfce007964e01aa63cc3027bee942",
            "c018bef61f2245e097c3cbe72d937c55",
            "ce5cf0dfb39f4098a43d893b26613da0",
            "8c1bbf5a492a460d95ca8d512e3e4dd2",
            "2e89024e5fb54bcc934f414a7970be03",
            "89b025fbafb5424c81bd7b644dda947c"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5487f8fd22d6479d944869b09c267b0e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/266 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4e99897710524d9991c2989e9e1bf054"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/114k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a7c35280aa849ffb8aa8c9662975b22"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb603fd1d96f400e8cceb93b35a173fc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/677 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "039182ccbd7b49b29d8023bf6ad8ba05"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/670M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6f89180695b2422594ccdc6a269296c2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.24k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a74ad8662f04810bec5727cdde4b158"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a3c80a8bf30a4cb8b8e97e0e83e2e547"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "288ee73854684c9a8da1055a019867f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "50e023aab818487283a79b628e3ad8c3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling%2Fconfig.json:   0%|          | 0.00/297 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3dda71a8b8b74c35a7f21afc90bb4de9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get the wikipedia data"
      ],
      "metadata": {
        "id": "RA_-hzHbFeSP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if you can't download using the following code\n",
        "# go to https://drive.google.com/file/d/1oWBnoxBZ1Mpeond8XDUSO6J9oAjcRDyW download it\n",
        "# manually upload it on colab\n",
        "!gdown 1oWBnoxBZ1Mpeond8XDUSO6J9oAjcRDyW"
      ],
      "metadata": {
        "id": "RZFMYH-yFhWn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38568a98-306c-4f71-b08d-376d9518c7da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1oWBnoxBZ1Mpeond8XDUSO6J9oAjcRDyW\n",
            "From (redirected): https://drive.google.com/uc?id=1oWBnoxBZ1Mpeond8XDUSO6J9oAjcRDyW&confirm=t&uuid=769a0aa0-9dd0-4726-9220-394d2d68efee\n",
            "To: /content/simplewiki-2020-11-01.jsonl.gz\n",
            "100% 50.2M/50.2M [00:00<00:00, 148MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load and Chunk Documents"
      ],
      "metadata": {
        "id": "4_ReSz-3PVwW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gzip\n",
        "import json\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "wikipedia_filepath = 'simplewiki-2020-11-01.jsonl.gz'\n",
        "\n",
        "docs = []\n",
        "with gzip.open(wikipedia_filepath, 'rt', encoding='utf8') as fIn:\n",
        "    for line in fIn:\n",
        "        data = json.loads(line.strip())\n",
        "        #Add all paragraphs\n",
        "        #passages.extend(data['paragraphs'])\n",
        "        #Only add the first paragraph\n",
        "        docs.append({\n",
        "                        'metadata': {\n",
        "                                        'title': data.get('title'),\n",
        "                                        'article_id': data.get('id')\n",
        "                        },\n",
        "                        'data': ' '.join(data.get('paragraphs')[0:3]) # restrict data to first 3 paragraphs to run later modules faster\n",
        "        })\n",
        "\n",
        "# We subset our data so we only use a subset of wikipedia documents to run things faster\n",
        "docs = [doc for doc in docs for x in ['india']\n",
        "              if x in doc['data'].lower().split()]\n",
        "# Create docs\n",
        "docs = [Document(page_content=doc['data'],\n",
        "                 metadata=doc['metadata']) for doc in docs]\n",
        "# Chunk docs\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=300)\n",
        "chunked_docs = splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "WwLEBC4nF9ly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(chunked_docs)"
      ],
      "metadata": {
        "id": "G4E1zYFSG7J-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86437d0b-4414-4b27-c427-e4bf2dcff795"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1322"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chunked_docs[:3]"
      ],
      "metadata": {
        "id": "aSbhERAyGw0v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e5a877e-06e4-4974-af9b-7a13fe57c8e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'title': 'Basil', 'article_id': '73985'}, page_content='Basil (\"Ocimum basilicum\") ( or ) is a plant of the Family Lamiaceae. It is also known as Sweet Basil or Tulsi. It is a tender low-growing herb that is grown as a perennial in warm, tropical climates. Basil is originally native to India and other tropical regions of Asia. It has been cultivated there for more than 5,000 years. It is prominently featured in many cuisines throughout the world. Some of them are Italian, Thai, Vietnamese and Laotian cuisines. It grows to between 30–60\\xa0cm tall. It has light green, silky leaves 3–5\\xa0cm long and 1–3\\xa0cm broad. The leaves are opposite each other. The flowers are quite big. They are white in color and arranged as a spike. The plant tastes somewhat like anise, with a strong, pungent, sweet smell. Basil is very sensitive to cold. It is best grown in hot, dry conditions. While most common varieties are treated as annuals, some are perennial, including African Blue and Holy Thai basil. The word \"basil\" comes from the Greek βασιλεύς (\"basileus\"), meaning \"royal\". This is because it is believed to have grown above the spot where St. Constantine and Helen discovered the Holy Cross. The \"Oxford English Dictionary\" quotes speculations that basil may have been used in \"some royal unguent, bath, or medicine\". Basil is still considered the \"king of herbs\" by many cookery authors. An alternative etymology has \"basil\" coming from the Latin word \"basilicus\", meaning dragon and being the root for basilisk, but this likely was a linguistic reworking of the word as brought from Greece.'),\n",
              " Document(metadata={'title': 'Roerich’s Pact', 'article_id': '259745'}, page_content='The Roerich Pact is a treaty on Protection of Artistic and Scientific Institutions and Historic Monuments, signed by the representatives of 21 states in the Oval Office of the White House on 15 April 1935. As of January 1, 1990, the Roerich Pact had been ratified by ten nations: Brazil, Chile, Colombia, Cuba, the Dominican Republic, El Salvador, Guatemala, Mexico, the United States, and Venezuela. It went into effect on 26 August 1935. The Government of India approved the Treaty in 1948, but did not take any further formal action. The Roerich Pact is also known as \"Pax Cultura\" (\"Cultural Peace\" or \"Peace through Culture\"). The most important part of the Roerich Pact is the legal recognition that the protection of culture is always more important than any military necessity. Russian painter and philosopher Nicholas Roerich (1874-1947) started the modern movement for the defense of cultural objects, in order for a “Peace of Civilizations”. Nicholas Roerich was born on October 9, 1874, in St. Petersburg. He became a successful painter. One of his paintings was purchased by Nicholas II of Russia.'),\n",
              " Document(metadata={'title': 'Nico Hülkenberg', 'article_id': '260252'}, page_content='Nicolas \"Nico\" Hülkenberg (born 19 August 1987 in Emmerich am Rhein, North Rhine-Westphalia) is a German racing driver. He races in Formula One for Williams. He won the 2009 GP2 Series championship. He is a past champion in Formula Three Euroseries and the A1 Grand Prix, as part of A1 Team Germany. He is one of three drivers to win the GP2 series championship in his first season. The other two are Lewis Hamilton and Nico Rosberg. Hülkenberg earned his first pole position at the Brazilian Grand Prix. His lap time was over one second faster than second place Sebastian Vettel on a drying circuit. It was the first pole for Williams in 100 races, since the European Grand Prix. After the Abu Dhabi GP, it was announced that Hülkenberg would not race for Williams in 2011. For the season, he is the third driver for the Force India team.')]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a Vector DB and persist on disk\n",
        "\n",
        "Here we initialize a connection to a Chroma vector DB client, and also we want to save to disk, so we simply initialize the Chroma client and pass the directory where we want the data to be saved to."
      ],
      "metadata": {
        "id": "-PnV9lAXZw9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_chroma import Chroma\n",
        "\n",
        "# create vector DB of docs and embeddings - takes < 1 min on Colab\n",
        "chroma_db = Chroma.from_documents(documents=chunked_docs,\n",
        "                                  collection_name='rag_wikipedia_db',\n",
        "                                  embedding=hf_embed_model,\n",
        "                                  # need to set the distance function to cosine else it uses euclidean by default\n",
        "                                  # check https://docs.trychroma.com/guides#changing-the-distance-function\n",
        "                                  collection_metadata={\"hnsw:space\": \"cosine\"},\n",
        "                                  persist_directory=\"./wikipedia_db\")"
      ],
      "metadata": {
        "id": "kRYfcrsHUxyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup a Vector Database Retriever\n",
        "\n",
        "Here we use the following retrieval strategy:\n",
        "\n",
        "- Similarity with Threshold Retrieval\n"
      ],
      "metadata": {
        "id": "bprZC4S6TLfj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Similarity with Threshold Retrieval\n",
        "\n",
        "We use cosine similarity here and retrieve the top 3 similar documents based on the user input query and also introduce a cutoff to not return any documents which are below a certain similarity threshold"
      ],
      "metadata": {
        "id": "8foBD2xmCDYc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_threshold_retriever = chroma_db.as_retriever(search_type=\"similarity_score_threshold\",\n",
        "                                                        search_kwargs={\"k\": 3,\n",
        "                                                                       \"score_threshold\": 0.5})"
      ],
      "metadata": {
        "id": "6ROSNwqeCMRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"what is the capital of India?\"\n",
        "top3_docs = similarity_threshold_retriever.invoke(query)\n",
        "top3_docs"
      ],
      "metadata": {
        "id": "Nv93k_QpCZv7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d6866d3-9644-4d3a-8b5a-3e1ea178a992"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='a1363031-c896-47e5-9bad-6a3726443180', metadata={'article_id': '5117', 'title': 'New Delhi'}, page_content='New Delhi () is the capital of India and a union territory of the megacity of Delhi. It has a very old history and is home to several monuments where the city is expensive to live in. In traditional Indian geography it falls under the North Indian zone. The city has an area of about 42.7\\xa0km. New Delhi has a population of about 9.4 Million people.'),\n",
              " Document(id='85a45b0b-01b8-43b4-a018-ba22c665347e', metadata={'article_id': '1968', 'title': 'Capital city'}, page_content=\"A capital city (or capital town or just capital) is a city or town, specified by law or constitution, by the government of a country, or part of a country, such as a state, province or county. It usually serves as the location of the government's central meeting place and offices. Most of the country's leaders and officials work in the capital city. Capitals are usually among the largest cities in their regions; often they are the biggest. For example, Montevideo is Uruguay's capital as well as its biggest city. The capital city may also be the most important center of commerce, as in London or Bangkok. However, a capital is not always the largest city in a country. For example, the capital of the India is New Delhi, which is smaller than Mumbai; and the capital of Pakistan is Islamabad, which is smaller than Karachi. Also, in countries with subdivisions like the United States, the capital cities or towns of the federated states are often not the largest or most populated town. For example, New York City is the biggest city in the United States and in New York but is not the capital of either.\"),\n",
              " Document(id='4e829e82-9a03-4a86-8fbd-5ba6cf7938ee', metadata={'article_id': '22106', 'title': 'Delhi'}, page_content='Delhi (; \"Dillī\"; \"Dillī\"; \"Dēhlī\"), officially the National Capital Territory of Delhi (NCT), is a territory in India. It includes the country\\'s capital New Delhi. It covers an area of . It is bigger than the Faroe Islands but smaller than Guadeloupe. Delhi is a part of the National Capital Region, which has 12.5 million residents. The governance of Delhi is like that of a state in India. It has its own legislature, high court and a council of executive ministers. Delhi is on the banks of the Yamuna River. Historians have evidence that people have been living in this region since at least the 6th century BC. People also believe that the legendary city of Indraprastha was here. This city has many remains and monuments of historic importance. The India Gate is a war memorial in Delhi. On the India gate there are names of some of the people who fought for India during 1914 until 1921.')]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"what is an agentic ai system?\"\n",
        "top3_docs = similarity_threshold_retriever.invoke(query)\n",
        "top3_docs"
      ],
      "metadata": {
        "id": "obsI3yKOO0KL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b240339-1415-4897-ad61-0204cfb5d75d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.vectorstores.base:No relevant docs were retrieved using the relevance score threshold 0.5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a Query Retrieval Grader\n",
        "\n",
        "Here we will use an LLM itself to grade if any retrieved document is relevant to the given question - Answer will be either `yes` or `no`"
      ],
      "metadata": {
        "id": "RXeilff0c9X5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from pydantic import BaseModel, Field\n",
        "# from langchain_openai import ChatOpenAI\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.output_parsers import PydanticOutputParser\n",
        "\n",
        "\n",
        "# Data model for LLM output format\n",
        "class GradeDocuments(BaseModel):\n",
        "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
        "    binary_score: str = Field(\n",
        "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
        "    )\n",
        "\n",
        "\n",
        "# LLM for grading\n",
        "# llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
        "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
        "\n",
        "# Prompt template for grading\n",
        "SYS_PROMPT = \"\"\"You are an expert grader assessing relevance of a retrieved document to a user question.\n",
        "                Follow these instructions for grading:\n",
        "                  - If the document contains keyword(s) or semantic meaning related to the question, grade it as relevant.\n",
        "                  - The overall grade should focus more on the semantic meaning rather than just individual common words.\n",
        "                  - Your grade should be either 'yes' or 'no' to indicate whether the document is relevant to the question or not.\n",
        "             \"\"\"\n",
        "grade_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", SYS_PROMPT),\n",
        "        (\"human\", \"\"\"Retrieved document:\n",
        "                     {document}\n",
        "\n",
        "                     User question:\n",
        "                     {question}\n",
        "                  \"\"\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Build grader chain\n",
        "doc_grader = (grade_prompt\n",
        "                  |\n",
        "              structured_llm_grader)"
      ],
      "metadata": {
        "id": "ubFlSqlMSU99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"what is the capital of India?\"\n",
        "top3_docs = similarity_threshold_retriever.invoke(query)\n",
        "for doc in top3_docs:\n",
        "    print(doc.page_content)\n",
        "    print('GRADE:', doc_grader.invoke({\"document\": doc.page_content, \"question\": query}))\n",
        "    print()"
      ],
      "metadata": {
        "id": "UuiAlPIbaC0W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f208eed-cd83-40a0-b4a9-01c7f9a71587"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Delhi () is the capital of India and a union territory of the megacity of Delhi. It has a very old history and is home to several monuments where the city is expensive to live in. In traditional Indian geography it falls under the North Indian zone. The city has an area of about 42.7 km. New Delhi has a population of about 9.4 Million people.\n",
            "GRADE: binary_score='yes'\n",
            "\n",
            "A capital city (or capital town or just capital) is a city or town, specified by law or constitution, by the government of a country, or part of a country, such as a state, province or county. It usually serves as the location of the government's central meeting place and offices. Most of the country's leaders and officials work in the capital city. Capitals are usually among the largest cities in their regions; often they are the biggest. For example, Montevideo is Uruguay's capital as well as its biggest city. The capital city may also be the most important center of commerce, as in London or Bangkok. However, a capital is not always the largest city in a country. For example, the capital of the India is New Delhi, which is smaller than Mumbai; and the capital of Pakistan is Islamabad, which is smaller than Karachi. Also, in countries with subdivisions like the United States, the capital cities or towns of the federated states are often not the largest or most populated town. For example, New York City is the biggest city in the United States and in New York but is not the capital of either.\n",
            "GRADE: binary_score='yes'\n",
            "\n",
            "Delhi (; \"Dillī\"; \"Dillī\"; \"Dēhlī\"), officially the National Capital Territory of Delhi (NCT), is a territory in India. It includes the country's capital New Delhi. It covers an area of . It is bigger than the Faroe Islands but smaller than Guadeloupe. Delhi is a part of the National Capital Region, which has 12.5 million residents. The governance of Delhi is like that of a state in India. It has its own legislature, high court and a council of executive ministers. Delhi is on the banks of the Yamuna River. Historians have evidence that people have been living in this region since at least the 6th century BC. People also believe that the legendary city of Indraprastha was here. This city has many remains and monuments of historic importance. The India Gate is a war memorial in Delhi. On the India gate there are names of some of the people who fought for India during 1914 until 1921.\n",
            "GRADE: binary_score='yes'\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"what is an agentic ai system?\"\n",
        "top3_docs = similarity_threshold_retriever.invoke(query)\n",
        "for doc in top3_docs:\n",
        "    print(doc.page_content)\n",
        "    print('GRADE:', doc_grader.invoke({\"question\": query, \"document\": doc.page_content}))\n",
        "    print()"
      ],
      "metadata": {
        "id": "9YNBjaO4ahnF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "824a76fc-eba5-4079-8d87-b2f1021bb6f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.vectorstores.base:No relevant docs were retrieved using the relevance score threshold 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"who won the champions league in 2024?\"\n",
        "top3_docs = similarity_threshold_retriever.invoke(query)\n",
        "for doc in top3_docs:\n",
        "    print(doc.page_content)\n",
        "    print('GRADE:', doc_grader.invoke({\"question\": query, \"document\": doc.page_content}))\n",
        "    print()"
      ],
      "metadata": {
        "id": "8lw0moL0dWjf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "292229dd-7df1-4b99-995a-40cd0e10c719"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.vectorstores.base:No relevant docs were retrieved using the relevance score threshold 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build a QA RAG Chain\n",
        "\n",
        "We will now connect our retriever to an LLM and build our QA RAG Chain"
      ],
      "metadata": {
        "id": "Bfn4Z4Em55bb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "# from langchain_openai import ChatOpenAI\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from operator import itemgetter\n",
        "\n",
        "# Create RAG prompt for response generation\n",
        "prompt = \"\"\"You are an assistant for question-answering tasks.\n",
        "            Use the following pieces of retrieved context to answer the question.\n",
        "            If no context is present or if you don't know the answer, just say that you don't know the answer.\n",
        "            Do not make up the answer unless it is there in the provided context.\n",
        "            Give a detailed answer and to the point answer with regard to the question.\n",
        "\n",
        "            Question:\n",
        "            {question}\n",
        "\n",
        "            Context:\n",
        "            {context}\n",
        "\n",
        "            Answer:\n",
        "         \"\"\"\n",
        "prompt_template = ChatPromptTemplate.from_template(prompt)\n",
        "\n",
        "# Initialize connection with GPT-4o\n",
        "# chatgpt = ChatOpenAI(model_name='gpt-4o', temperature=0)\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
        "# Used for separating context docs with new lines\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "# create QA RAG chain\n",
        "qa_rag_chain = (\n",
        "    {\n",
        "        \"context\": (itemgetter('context')\n",
        "                        |\n",
        "                    RunnableLambda(format_docs)),\n",
        "        \"question\": itemgetter('question')\n",
        "    }\n",
        "      |\n",
        "    prompt_template\n",
        "      |\n",
        "     llm\n",
        "      |\n",
        "    StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "8Pu5U9HNkl-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"what is the capital of India?\"\n",
        "top3_docs = similarity_threshold_retriever.invoke(query)\n",
        "result = qa_rag_chain.invoke(\n",
        "    {\"context\": top3_docs, \"question\": query}\n",
        ")\n",
        "print(result)"
      ],
      "metadata": {
        "id": "9Wj-MZr2eEq8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b961258-145b-40b1-d484-5fac59690ec5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The capital of India is New Delhi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"who won the champions league in 2024?\"\n",
        "top3_docs = similarity_threshold_retriever.invoke(query)\n",
        "result = qa_rag_chain.invoke(\n",
        "    {\"context\": top3_docs, \"question\": query}\n",
        ")\n",
        "print(result)"
      ],
      "metadata": {
        "id": "i_BK5xvbeYmz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b2d16fc-f701-4722-ebba-2f18059139b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.vectorstores.base:No relevant docs were retrieved using the relevance score threshold 0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I don't know the answer. The provided context does not contain information about who won the Champions League in 2024.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a Query Rephraser\n",
        "\n",
        "We will now build a query rephraser which will use an LLM to rephrase the input user query into a better version which is optimized for web search"
      ],
      "metadata": {
        "id": "-Fp8Eh0x5bMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LLM for question rewriting\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
        "\n",
        "# Prompt template for rewriting\n",
        "SYS_PROMPT = \"\"\"Act as a question re-writer and perform the following task:\n",
        "                 - Convert the following input question to a better version that is optimized for web search.\n",
        "                 - When re-writing, look at the input question and try to reason about the underlying semantic intent / meaning.\n",
        "\n",
        "                Just return the question, no explanations or answers.\n",
        "             \"\"\"\n",
        "re_write_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", SYS_PROMPT),\n",
        "        (\"human\", \"\"\"Here is the initial question:\n",
        "                     {question}\n",
        "\n",
        "                     Formulate an improved question.\n",
        "                  \"\"\",\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "# Create rephraser chain\n",
        "question_rewriter = (re_write_prompt\n",
        "                        |\n",
        "                       llm\n",
        "                        |\n",
        "                     StrOutputParser())"
      ],
      "metadata": {
        "id": "Mm7T22tmfYWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"who won the champions league in 2024?\"\n",
        "question_rewriter.invoke({\"question\": query})"
      ],
      "metadata": {
        "id": "2bGCpLKzhTUr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c48c11e8-2aac-4988-ef76-12bd51b7675e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Who won the 2024 UEFA Champions League final?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Web Search Tool\n",
        "\n",
        "Here we will be using the [Tavily API](https://tavily.com/#api) for our web searches"
      ],
      "metadata": {
        "id": "howf-v0ARWbv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "tavily_search = TavilySearchAPIWrapper()\n",
        "\n",
        "@tool\n",
        "def search_web(query: str) -> list:\n",
        "    \"\"\"Search the web for a query. Userful for general information or general news\"\"\"\n",
        "    results = tavily_search.raw_results(query=query,\n",
        "                                        max_results=8,\n",
        "                                        search_depth='advanced',\n",
        "                                        include_answer=False,\n",
        "                                        include_raw_content=True)\n",
        "    results = [r['raw_content'] for r in results['results']]\n",
        "    return results"
      ],
      "metadata": {
        "id": "Ue8xgu9WpuPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_web.invoke('Champions league 2024 final')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74CZm8taUhpC",
        "outputId": "6a8e6179-cd82-4074-deda-3c0ed53e3420"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Jump to content\\nMain menu\\nSearch\\nGive to Wikipedia\\nCreate account\\nLog in\\nPersonal tools\\nToggle the table of contents\\n2024 UEFA Champions League final\\n31 languages\\nPage\\nTalk\\nRead\\nChange\\nChange source\\nView history\\nTools\\nFrom Simple English Wikipedia, the free encyclopedia\\n2024 UEFA Champions League final\\nWembley Stadium in London hosted the final.\\nEvent   2023–24 UEFA Champions League\\nBorussia Dortmund   Real Madrid\\n0   2\\nDate    1\\xa0June\\xa02024\\nVenue   Wembley Stadium, London\\nMan of the Match    Dani Carvajal (Real Madrid)[1]\\nReferee Slavko Vinčić (Slovenia)[2]\\nAttendance  86,212[3]\\nWeather Cloudy\\n18\\xa0°C (64\\xa0°F)\\n54% humidity[4]\\n← 2023\\n2025 →\\nThe 2024 UEFA Champions League final was the last match of the 2023–24 UEFA Champions League, which is a big football competition in Europe. It\\'s the 69th season of this tournament organized by UEFA, and it\\'s been called the UEFA Champions League for 32 seasons now. This final happened at Wembley Stadium in London, England, on June 1, 2024.[5][6] The team that won, Real Madrid, gets to play against the winners of the 2023–24 UEFA Europa League, Atalanta, in the 2024 UEFA Super Cup.\\nMatch[change | change source]\\nDetails[change | change source]\\n2023-24 UEFA Champions League\\n1\\xa0June\\xa02024\\n21:00 CEST\\nFinal\\nBorussia Dortmund   0–2  Real Madrid\\n    Report  Carvajal 74\\' Vinicius 83\\'\\nWembley Stadium, London\\nAttendance: 86,212\\nReferee: Slavko Vinčić (Slovenia)\\nMatch rules\\n\\n90 minutes\\n30 minutes of extra time if necessary\\nPenalty shoot-out if scores still level\\nTwelve named substitutes\\nMaximum of five substitutions, with a sixth allowed in extra time[note 1]\\nNotes[change | change source]\\n↑ Each team can make three substitutions during the regular game and one more during extra time. This doesn\\'t include substitutions made at half-time, before extra time starts, and at half-time during extra time.\\nOther websites[change | change source]\\nOfficial website\\nvte\\nEuropean Cup and UEFA Champions League\\nEuropean Cup era, 1955–1992\\nSeasons \\n1955–561956–571957–581958–591959–601960–611961–621962–631963–641964–651965–661966–671967–681968–691969–701970–711971–721972–731973–741974–751975–761976–771977–781978–791979–801980–811981–821982–831983–841984–851985–861986–871987–881988–891989–901990–911991–92\\nFinals\\n1956195719581959196019611962196319641965196619671968196919701971197219731974197519761977197819791980198119821983198419851986198719881989199019911992\\nUEFA Champions League era, 1992–present\\nSeasons \\n1992–931993–941994–951995–961996–971997–981998–991999–20002000–012001–022002–032003–042004–052005–062006–072007–082008–092009–102010–112011–122012–132013–142014–152015–162016–172017–182018–192019–202020–212021–222022–232023–242024–25\\nFinals\\n199319941995199619971998199920002001200220032004200520062007200820092010201120122013201420152016201720182019202020212022202320242025\\nHistory FinalsWinning managersWinning playersRecords and statistics Top scorersHat-tricksAppearancesPerformance comparisonAnthemBroadcastersTrophy\\nReferences[change | change source]\\n↑ \"Official Champions League final PlayStation Player of the Match: Dani Carvajal\". UEFA. 1 June 2024. Archived from the original on 3 June 2024. Retrieved 1 June 2024.\\n↑ \"Referee teams for 2024 UEFA club competition finals announced\". UEFA. 13 May 2024. Archived from the original on 13 May 2024. Retrieved 13 May 2024.\\n↑ Cite error: The named reference report 1 June was used but no text was provided for refs named (see the help page).\\n↑ \"Tactical Line-ups – Final – Saturday 1 June 2024\" (PDF). UEFA. 1 June 2024. Archived (PDF) from the original on 3 June 2024. Retrieved 1 June 2024.\\n↑ \"UEFA competitions to resume in August\". UEFA.com. Union of European Football Associations. 17 June 2020. Retrieved 17 June 2020.\\n↑ \"International match calendar and access list for the 2023/24 season\". UEFA Circular Letter. No.\\xa065/2022. Union of European Football Associations. 26 September 2022. Retrieved 27 September 2022.\\nCategory: UEFA Champions League finals\\nThis page was last changed on 11 July 2024, at 04:58.\\nText is available under the Creative Commons Attribution-ShareAlike License and the GFDL; additional terms may apply. See Terms of Use for details.\\nPrivacy policy\\nAbout Wikipedia\\nDisclaimers\\nCode of Conduct\\nDevelopers\\nStatistics\\nCookie statement\\nMobile view',\n",
              " 'Jump to content\\nMain menu\\nSearch\\nDonate\\nCreate account\\nLog in\\nPersonal tools\\nToggle the table of contents\\n2024 UEFA Champions League final\\n31 languages\\nArticle\\nTalk\\nRead\\nEdit\\nView history\\nTools\\nFrom Wikipedia, the free encyclopedia\\n2024 UEFA Champions League final\\nMatch programme cover\\nEvent   2023–24 UEFA Champions League\\nBorussia Dortmund   Real Madrid\\n0   2\\nDate    1\\xa0June\\xa02024\\nVenue   Wembley Stadium, London\\nMan of the Match    Dani Carvajal (Real Madrid)[1]\\nReferee Slavko Vinčić (Slovenia)[2]\\nAttendance  86,212[3]\\nWeather Cloudy\\n18\\xa0°C (64\\xa0°F)\\n54% humidity[4]\\n← 2023\\n2025 →\\nThe 2024 UEFA Champions League final was the final match of the 2023–24 UEFA Champions League, the 69th season of Europe\\'s premier club football tournament organised by UEFA, and the 32nd season since it was renamed from the European Champion Clubs\\' Cup to the UEFA Champions League. It was held at Wembley Stadium in London, England, on 1 June 2024,[5] between German club Borussia Dortmund and Spanish club Real Madrid. Due to the postponement and relocation of the 2020 final, the final hosts were shifted back a year, with London instead hosting the 2024 final.[6]\\nReal Madrid won the match 2–0 for a record-extending 15th title, and their sixth in eleven seasons.[7] As winners, they earned a spot to play in the 2024 UEFA Super Cup, against the winners of the 2023–24 UEFA Europa League, Atalanta. They also earned a chance to compete in the inaugural edition of the FIFA Intercontinental Cup. As they had already qualified for the 2025 FIFA Club World Cup by winning the same tournament in 2022, the spot intended for the winners was redistributed via the UEFA club ranking, with Dortmund claiming one of those spots.[8]\\nBackground[edit]\\nFor Borussia Dortmund, this was their third UEFA Champions League final appearance, the first since the 1–2 Der Klassiker loss against Bayern Munich in 2013, which was also held at Wembley Stadium, and the first European final for manager Edin Terzić.[9] Additionally, Dortmund played one European Cup Winners\\' Cup final (winning in 1966)[10] and two UEFA Cup finals (losing in 1993 and 2002).[11]\\nReal Madrid played in a record-extending 18th European Cup/UEFA Champions League final, and their second in three years. They previously won 14 finals (in 1956, 1957, 1958, 1959, 1960, 1966, 1998, 2000, 2002, 2014, 2016, 2017, 2018 and 2022) and lost three (1962, 1964 and 1981).[9] Their manager Carlo Ancelotti reached a record-extending sixth UEFA Champions League final as manager, winning in 2003 and 2007 and losing in 2005 while in charge of Milan, and winning the 2014 and 2022 finals with Real Madrid.[12] Real Madrid also played in two European Cup Winners\\' Cup finals (losing in 1971 and 1983)[10] and two UEFA Cup finals (winning in 1985 and 1986).[11]\\nThis was the first Champions League final between the two clubs,[9] and their first meeting in European competitions since the 2017–18 Champions League group stage encounters, when Madrid won 3–1 away and 3–2 at home. Of their previous fourteen encounters, Dortmund won three matches, Real won six matches and five finished as a draw.[13]\\nUntil the semi-finals, Borussia Dortmund had the best defence in the 2023–24 Champions League with six clean sheets and eight goals conceded. In contrast, Real Madrid goalkeepers had the most goal-scoring opportunities to prevent in the same season.[14]\\nPrevious finals[edit]\\nIn the following table, finals until 1992 were in the European Cup era, since 1993 were in the UEFA Champions League era.[15]\\nTeam    Previous final appearances (bold indicates winners)\\n Borussia Dortmund  2 (1997, 2013)\\n Real Madrid    17 (1956, 1957, 1958, 1959, 1960, 1962, 1964, 1966, 1981, 1998, 2000, 2002, 2014, 2016, 2017, 2018, 2022)\\nVenue[edit]\\nThis was the third UEFA Champions League final to take place at the rebuilt Wembley Stadium, having previously been held in 2011 and 2013. Overall, it was the eighth final to be held in London, with the other five matches taking place at the original Wembley Stadium in 1963, 1968, 1971, 1978, and 1992. The match was the ninth European Cup final held in England, with the 2003 final having been held at Old Trafford in Manchester, equalling the record of nine European Cup finals held in each of Italy, Germany and Spain. It was also the thirteenth held in the United Kingdom, with the 1960, 1976 and 2002 finals held in Scotland and the 2017 final held in Wales.[16] Wembley Stadium was also a host venue at UEFA Euro 2020, with eight matches played at the stadium including the semi-finals and final.[17]\\nHost selection[edit]\\nAn open bidding process was launched on 22 February 2019 by UEFA to select the 2022 and 2023 UEFA Champions League final venues.[18] Associations had until 22 March 2019 to express interest, and bid dossiers had to be submitted by 1 July 2019.[19]\\nThe Football Association was reported to have bid with Wembley Stadium in London to host the 2023 final, in order to mark the centenary of the opening of the original stadium in 1923.[19] Wembley Stadium was selected by the UEFA Executive Committee during their meeting in Ljubljana, Slovenia, on 24 September 2019,[20] where the hosts for the 2021 and 2022 UEFA Champions League finals were also appointed.[21]\\nOn 17 June 2020, the UEFA Executive Committee announced that due to the postponement and relocation of the 2020 final, London would instead host the 2024 final.[6]\\nRoute to the final[edit]\\nFurther information: 2023–24 UEFA Champions League\\nNote: In all results below, the score of the finalist is given first (H: home; A: away).\\nBorussia Dortmund  Round    Real Madrid\\nOpponent    Result  Group stage Opponent    Result\\n Paris Saint-Germain    0–2 (A) Matchday 1   Union Berlin   1–0 (H)\\n Milan  0–0 (H) Matchday 2   Napoli 3–2 (A)\\n Newcastle United   1–0 (A) Matchday 3   Braga  2–1 (A)\\n Newcastle United   2–0 (H) Matchday 4   Braga  3–0 (H)\\n Milan  3–1 (A) Matchday 5   Napoli 4–2 (H)\\n Paris Saint-Germain    1–1 (H) Matchday 6   Union Berlin   3–2 (A)\\nGroup F winners\\nPos Team\\nvte\\n    Pld Pts\\n1    Borussia Dortmund  6   11\\n2    Paris Saint-Germain    6   8\\n3    Milan  6   8\\n4    Newcastle United   6   5\\nSource: UEFA\\n    Final standings Group C winners\\nPos Team\\nvte\\n    Pld Pts\\n1    Real Madrid    6   18\\n2    Napoli 6   10\\n3    Braga  6   4\\n4    Union Berlin   6   2\\nSource: UEFA\\nOpponent    Agg.    1st leg 2nd leg Knockout phase  Opponent    Agg.    1st leg 2nd leg\\n PSV Eindhoven  3–1 1–1 (A) 2–0 (H) Round of 16  RB Leipzig 2–1 1–0 (A) 1–1 (H)\\n Atlético Madrid    5–4 1–2 (A) 4–2 (H) Quarter-finals   Manchester City    4–4 (4–3 p) 3–3 (H) 1–1 (a.e.t.) (A)\\n Paris Saint-Germain    2–0 1–0 (H) 1–0 (A) Semi-finals  Bayern Munich  4–3 2–2 (A) 2–1 (H)\\nBorussia Dortmund[edit]\\nSee also: 2023–24 Borussia Dortmund season\\nBorussia Dortmund defender Mats Hummels (left) and midfielder Marco Reus (right) were the only players from the club\\'s 2013 final squad; Hummels scored the winner in the second leg of the semi-final against Paris Saint-Germain to book their place in the final, which was the last match for the club for both of them.\\nBorussia Dortmund qualified for the Champions League group stage by finishing as runners-up in the 2022–23 Bundesliga. In the group stage, they were drawn into Group F, alongside Ligue 1 winners Paris Saint-Germain, Serie A fourth-place team Milan and Premier League fourth-place side Newcastle United,[22] which was widely regarded as the \\'group of death\\'.[23][24]\\nIn Dortmund\\'s opener of the group stage, they faced Paris Saint-Germain at the Parc des Princes and lost 0–2, with goals from Kylian Mbappé and Achraf Hakimi.[25] On matchday 2, Dortmund drew in a 0–0 stalemate at the Westfalenstadion against Milan.[26] On matchday 3, Dortmund defeated Newcastle United away from home 1–0, with a goal from Felix Nmecha.[27] On matchday 4, Dortmund won 2–0 over Newcastle United at home, with goals coming from Niclas Füllkrug and Julian Brandt.[28] On matchday 5, Dortmund got a 3–1 win against Milan at the San Siro, with goals by Marco Reus, Jamie Bynoe-Gittens and Karim Adeyemi, as Samuel Chukwueze got the temporary equaliser for the hosts.[29] On matchday 6, returning to the Westfalenstadion, the hosts held Paris Saint-Germain to a 1–1 draw, with a goal from Adeyemi and a strike from Warren Zaïre-Emery for the visitors.[30]\\nIn the round of 16, Dortmund were drawn against Dutch club PSV Eindhoven. In the first leg held at the Philips Stadion, Dortmund drew 1–1, with goals from Donyell Malen and Luuk de Jong.[31] In the reverse leg, Dortmund defeated PSV 2–0, with goals from Jadon Sancho and Reus, to win 3–1 on aggregate and advance to the quarter-finals.[32]\\nIn the quarter-finals, Dortmund were drawn against Spanish side Atlético Madrid. In the first leg, at the Metropolitano Stadium, the Germans suffered a 1–2 loss, with goals being scored by Rodrigo De Paul, Samuel Lino and Sébastien Haller, whose late goal rescued Dortmund\\'s chances for the progression.[33] In the second leg, Dortmund produced a 4–2 win at home, trailing down 3–4 on aggregate in the second half and qualifying to the semi-finals 5–4 on aggregate, as Brandt, Ian Maatsen, Füllkrug, Marcel Sabitzer, Mats Hummels (own goal) and Ángel Correa got on the scoresheet.[34]\\nIn the semi-finals, Dortmund were drawn against Paris Saint-Germain, making it a rematch of this season\\'s group stage clash. In the first leg, at the Westfalenstadion, a lone winner from Füllkrug gave Dortmund a 1–0 victory.[35] In the second leg, at the Parc des Princes, the visitors won 1–0 once again, with the only goal of the match coming from Hummels. Dortmund won 2–0 on aggregate to qualify for their first Champions League final in eleven years.[36]\\nReal Madrid[edit]\\nSee also: 2023–24 Real Madrid CF season\\nForward Joselu (left), who was on loan to Real Madrid from Espanyol, scored two late decisive goals in the second leg of the semi-final against Bayern Munich to send Madrid to the final. He and fellow forwards Rodrygo (middle) and Vinícius Júnior (right) were their club\\'s top scorers in the competition with five goals each.\\nThe 2024 UEFA Champions League final marked Real Madrid midfielder Toni Kroos\\' last club football match and his sixth appearance in the competition\\'s final.\\nReal Madrid qualified for the Champions League group stage as 2022–23 La Liga runners-up. They were drawn in Group C, alongside reigning Serie A champions Napoli, third placed Primeira Liga team Braga, and fourth placed Bundesliga team Union Berlin.[22]\\nMadrid went on to end the group stage recording an impressive 6 out of 6 wins in all games. The team opened the group stage at the Santiago Bernabéu against Union Berlin, with a late Jude Bellingham goal sealing a 1–0 win.[37] On matchday 2, the team grabbed a 3–2 away win against Napoli at the Stadio Diego Armando Maradona, with finishes coming from Vinícius Júnior, Bellingham, and an own goal from Napoli goalkeeper Alex Meret, with goals coming from Leo Østigård and Piotr Zieliński for the hosts.[38] On matchday 3, Madrid defeated Braga away 2–1, with Rodrygo and Bellingham on the scoresheet, and Álvaro Djaló scoring for his team.[39] On matchday 4, Madrid dominated Braga 3–0 at home with strikes from Brahim Díaz, Vinícius, and Rodrygo.[40] On matchday 5, Madrid obtained a 4–2 home win against Napoli, with goals coming from Vinícius, Bellingham, Nico Paz, and Joselu, as well as Giovanni Simeone and André-Frank Zambo Anguissa on the scoresheet for the visitors.[41] On matchday 6, they obtained a 3–2 win away against Union Berlin, after a Joselu brace and Dani Ceballos scoring the winner, with strikes from Kevin Volland and Alex Král for the hosts.[42]\\nIn the round of 16, Madrid were drawn against German club RB Leipzig. In the first leg held at the Red Bull Arena, a lone Brahim strike prevailed Madrid to a 1–0 away win.[43] In the second leg, Madrid were held to a 1–1 draw, despite Willi Orbán scoring for his team, Vinícius\\'s goal was enough for Madrid to advance 2–1 on aggregate.[44]\\nIn the quarter-finals, Madrid were drawn against English champions and reigning UEFA Champions League winners Manchester City for the third consecutive season. The first leg at the Santiago Bernabéu ended in an intense 3–3 draw, in which goals from Bernardo Silva, Phil Foden, and Joško Gvardiol were denied by replies from a Rúben Dias own goal, Rodrygo, and Federico Valverde.[45] The second leg at the City of Manchester Stadium also ended in a draw, as Rodrygo\\'s early goal was cancelled out by a Kevin De Bruyne equaliser. The match ended 1–1 after extra time and went into the penalty shootout to decide the winner after a 4–4 aggregate draw. It was Madrid\\'s first Champions League shootout since the 2016 final. Goalkeeper Andriy Lunin saved two crucial penalties from Silva and Mateo Kovačić, with only Luka Modrić missing his spot kick for the visitors, while Antonio Rüdiger scored the decisive final penalty to send his team to the semi-finals.[46]\\nIn the semi-finals, Madrid were drawn against German champions Bayern Munich, the first \"European Clásico\" since the 2017–18 UEFA Champions League season. In the first leg at the Allianz Arena, a Vinícius double cancelled goals coming from Leroy Sané and Harry Kane for the hosts for a 2–2 draw.[47] In the second leg at the Santiago Bernabéu, with Madrid initially trailing from an Alphonso Davies goal, Joselu\\'s double in the closing minutes of the game stunned the visitors to bring his team to a 2–1 victory in the match and 4–3 on aggregate, as they progressed to their sixth final in ten years.[48]\\nPre-match[edit]\\nIdentity[edit]\\nThe visual identity of the 2024 UEFA Champions League final was unveiled at the group stage draw in Monaco on 31 August 2023.[49]\\nOfficials[edit]\\nSlovenian referee Slavko Vinčić officiated the final.\\nOn 13 May 2024, Slovenian referee Slavko Vinčić was appointed to take charge of the final by UEFA, along with fellow Slovenes Tomaž Klančnik and Andraž Kovačič as assistant referees, and Nejc Kajtazović as the video assistant referee.[2] The first three officials had previously officiated together in the 2022 UEFA Europa League final.[50] They were joined by fellow countryman Rade Obrenović as assistant VAR and Frenchman François Letexier as the fourth official.[2]\\nOpening ceremony[edit]\\nLenny Kravitz, the headline act of the opening ceremony.\\nOn 16 May 2024, American singer Lenny Kravitz was named as the headline act of the opening ceremony.[51] He performed with his band a medley of his songs: \"Fly Away\", \"Human\" and \"Are You Gonna Go My Way\".[52]\\nMatch[edit]\\nSummary[edit]\\nReal Madrid defender Dani Carvajal was named man of the match and became the first defender to score in a final since Sergio Ramos in 2016.\\nThe match kicked off at 20:00 local time with an attendance of 86,212 fans. In the 21st minute, Mats Hummels played a pass to Karim Adeyemi, who rounded Thibaut Courtois by nudging the ball to the goalkeeper\\'s right and attempting to shoot, but Dani Carvajal tracked back to block his effort. Two minutes later, Adeyemi played a pass through the centre of the Madrid defence and released Niclas Füllkrug, who struck the woodwork. Dortmund then produced a counter-attack after Brandt played a pass to Adeyemi, who was unable to beat Courtois from a tight angle, with the latter stretching out to make the initial parry, before saving Füllkrug\\'s follow-up attempt. There were four minutes of added time after a series of pitch invasions earlier in the match.[53][54]\\nNeither side made any lineup changes during the interval. In the 49th minute, Toni Kroos whipped in a free kick towards the Dortmund penalty area, with Carvajal sending his header over the bar. Madrid continued their pressure as Vinícius Júnior whipped a cross towards the penalty area, which Nico Schlotterbeck nodded straight to Carvajal, whose half-volley effort was blocked by Ian Maatsen. Dortmund pushed again for a goal as Adeyemi played a cross into the penalty area towards Füllkrug, who managed to direct a powerful header that was saved by Courtois. Vinícius played another cross from the left flank to former Dortmund midfielder Jude Bellingham, who missed the ball which flew inches wide of the post. Dortmund then made their first substitution of the final, as Adeyemi came off for Marco Reus.[53][54]\\nWith 15 minutes to go, Carvajal gave Madrid the lead in the 74th minute, heading in Kroos\\' corner from the left. Madrid had another chance to score, with Eduardo Camavinga cutting the ball back from the byline on the left to Bellingham, who looked to strike the ball past Gregor Kobel, only for Schlotterbeck to block his effort. Dortmund then made two attacking changes, as captain Emre Can and Julian Brandt came off for Donyell Malen and Sébastien Haller. Madrid came close to scoring a second again, as Kobel saved Camavinga\\'s effort from outside the box and Nacho\\'s header from a Kroos corner.[53][54]\\nIn the 83rd minute, Maatsen played a pass that was intercepted by Bellingham, who teed up Vinícius to his left, with the latter taking a touch and putting the ball past Kobel to double Madrid\\'s lead. Madrid then made their first changes as Bellingham and Kroos came off for Joselu and Luka Modrić. Dortmund made their last substitution, with Jadon Sancho brought off for Jamie Bynoe-Gittens. Dortmund thought they had pulled one back, as Malen played a cross into the penalty area to Füllkrug, who powered a header into the left-hand side of the net, leaving Courtois with no chance. However, the goal was immediately disallowed by the referee after Füllkrug was shown to be in an offside position. Madrid made their two other substitutions in stoppage time, with Rodrygo and Vinícius brought off for Éder Militão and Lucas Vázquez. The match ended after five minutes of stoppage time, with Madrid winning 2–0.[53][54]\\nDetails[edit]\\nThe \"home\" team (for administrative purposes) was determined by an additional draw held after the quarter-final and semi-final draws.[55]\\n1\\xa0June\\xa02024\\n20:00 BST\\nBorussia Dortmund   0–2  Real Madrid\\n    Report\\nCarvajal  74\\'\\nVinícius  83\\'\\nWembley Stadium, London\\nAttendance: 86,212[3]\\nReferee: Slavko Vinčić (Slovenia)\\nBorussia Dortmund[4]\\nReal Madrid[4]\\nGK  1    Gregor Kobel\\nRB  26   Julian Ryerson\\nCB  15   Mats Hummels   \\xa079\\'\\nCB  4    Nico Schlotterbeck \\xa040\\'\\nLB  22   Ian Maatsen\\nCM  23   Emre Can (c)       \\xa080\\'\\nCM  20   Marcel Sabitzer    \\xa043\\'\\nRW  10   Jadon Sancho       \\xa087\\'\\nAM  19   Julian Brandt      \\xa080\\'\\nLW  27   Karim Adeyemi      \\xa072\\'\\nCF  14   Niclas Füllkrug\\nSubstitutes:\\nGK  33   Alexander Meyer\\nGK  35   Marcel Lotka\\nDF  25   Niklas Süle\\nMF  6    Salih Özcan\\nMF  8    Felix Nmecha\\nMF  11   Marco Reus     \\xa072\\'\\nMF  17   Marius Wolf\\nMF  38   Kjell Wätjen\\nMF  43   Jamie Bynoe-Gittens        \\xa087\\'\\nFW  9    Sébastien Haller       \\xa080\\'\\nFW  18   Youssoufa Moukoko\\nFW  21   Donyell Malen      \\xa080\\'\\nManager:\\n Edin Terzić\\nGK  1    Thibaut Courtois\\nRB  2    Dani Carvajal\\nCB  22   Antonio Rüdiger\\nCB  6    Nacho (c)\\nLB  23   Ferland Mendy\\nDM  12   Eduardo Camavinga\\nCM  15   Federico Valverde\\nCM  8    Toni Kroos     \\xa085\\'\\nAM  5    Jude Bellingham        \\xa085\\'\\nCF  11   Rodrygo        \\xa090\\'\\nCF  7    Vinícius Júnior    \\xa035\\'    \\xa090+4\\'\\nSubstitutes:\\nGK  13   Andriy Lunin\\nGK  25   Kepa Arrizabalaga\\nDF  3    Éder Militão       \\xa090\\'\\nDF  4    David Alaba\\nDF  17   Lucas Vázquez      \\xa090+4\\'\\nDF  20   Fran García\\nMF  10   Luka Modrić        \\xa085\\'\\nMF  18   Aurélien Tchouaméni\\nMF  19   Dani Ceballos\\nMF  21   Brahim Díaz\\nMF  24   Arda Güler\\nFW  14   Joselu     \\xa085\\'\\nManager:\\n Carlo Ancelotti\\nMan of the Match:\\nDani Carvajal (Real Madrid)[1]\\nAssistant referees:[2]\\nTomaž Klančnik (Slovenia)\\nAndraž Kovačič (Slovenia)\\nFourth official:[2]\\nFrançois Letexier (France)\\nReserve assistant referee:[2]\\nCyril Mugnier (France)\\nVideo assistant referee:[2]\\nNejc Kajtazović (Slovenia)\\nAssistant video assistant referee:[2]\\nRade Obrenović (Slovenia)\\nSupport video assistant referee:[2]\\nMassimiliano Irrati (Italy)\\nMatch rules[56]\\n90 minutes\\n30 minutes of extra time if necessary\\nPenalty shoot-out if scores still level\\nMaximum of twelve named substitutes\\nMaximum of five substitutions, with a sixth allowed in extra time\\nMaximum of three substitution opportunities, with a fourth allowed in extra time\\nStatistics[edit]\\nFirst half[57]\\nStatistic   Borussia Dortmund   Real Madrid\\nGoals scored    0   0\\nTotal shots 8   2\\nShots on target 2   0\\nSaves   0   2\\nBall possession 40% 60%\\nCorner kicks    5   1\\nFouls committed 8   3\\nOffsides    0   0\\nYellow cards    2   1\\nRed cards   0   0\\nSecond half[57]\\nStatistic   Borussia Dortmund   Real Madrid\\nGoals scored    0   2\\nTotal shots 5   11\\nShots on target 1   6\\nSaves   4   1\\nBall possession 54% 46%\\nCorner kicks    4   7\\nFouls committed 4   5\\nOffsides    1   0\\nYellow cards    1   0\\nRed cards   0   0\\nOverall[57]\\nStatistic   Borussia Dortmund   Real Madrid\\nGoals scored    0   2\\nTotal shots 13  13\\nShots on target 3   6\\nSaves   4   3\\nBall possession 46% 54%\\nCorner kicks    9   8\\nFouls committed 12  8\\nOffsides    1   0\\nYellow cards    3   1\\nRed cards   0   0\\nPost-match[edit]\\nReal Madrid\\'s Carlo Ancelotti won his fifth Champions League title as a manager and seventh overall.\\nWith the win, Real Madrid secured their record-extending 15th European Cup/Champions League title, and their sixth in the previous eleven seasons. It maintained Madrid\\'s perfect final record in the Champions League era with nine wins, having last lost the final in 1981.[9] Madrid won the Champions League unbeaten for the first time, with nine wins and four draws.[7] They also completed their fifth European double (after 1956–57, 1957–58, 2016–17 and 2021–22), having won the 2023–24 La Liga.[58]\\nFour Madrid players (Dani Carvajal, Toni Kroos, Luka Modrić, and Nacho) equalled Paco Gento\\'s record of winning six European Cup/Champions League titles; all but Kroos have won all six of their titles with Real.[59] In addition, Carvajal joined Gento as the only players to start in six different winning finals in the competition. Madrid manager Carlo Ancelotti extended his record as the most successful manager in the competition\\'s history, with his fifth title, and his third in charge of Los Blancos.[60]\\nMeanwhile, Borussia Dortmund manager Edin Terzić stepped down from his role on 13 June 2024, nearly two weeks after losing the final. He stated that after the final, he asked for a meeting with the club\\'s senior management team because he felt that \"the club\\'s new era should begin with a new man on the touchline\", and wished Dortmund the very best.[61] The next day, Terzić\\'s assistant and former Dortmund player Nuri Şahin was appointed as head coach on a three-year contract.[62]\\nCrime[edit]\\nAfter the game, the Metropolitan Police said that over 2,000 officers had been on duty for the game. 53 arrests had been made, mainly for trying to enter the stadium without a ticket and five arrests for entering the field of play. The game had only just kicked off when pitch invaders approached a number of the players.[63]\\nThree people were later charged with entering the field of play contrary to Section 4 of the Football (Offences) Act 1991. Their court appearances were arranged for June and July 2024. The police said that most attempts to gain access to the ground without a ticket had been thwarted following an investment of £5\\xa0million, on new security lanes, improved fencing, additional stewards and ticket checks and their increased enforcement of the Public Space Protection Order, carried out after the mass unrest at the Euro 2020 final in July 2021.[64] A Russian vlogger, Andrey Burim, was later reported to have offered 30\\xa0million rubles to anyone who entered the pitch with his handle on their t-shirts.[65] On 3 June, a Ukrainian man pled guilty at Westminster Magistrates\\' Court to entering the field of play and admitted he was inspired by Andrey Burim. He was fined £1,000, which was cut to £660 following his guilty plea. He was also ordered to pay £85 costs and a £264 witness surcharge.[66]\\nBroadcasting[edit]\\nIn Spain, the final was broadcast by Televisión Española (TVE), with an average of 6.1\\xa0million viewers (48.8% of share) and a peak of 7.3\\xa0million (52.5% of share) at 22:44 CEST.[67] In total, at least 10.4\\xa0million unique viewers watched the match at some point.[67] In addition, public streaming service RTVE Play gathered almost 800,000 unique viewers, with a total of 1.5\\xa0million views.[67] Post-match celebrations were followed by 3.2\\xa0million people.[67] Likewise, the Movistar Plus+ subscription platform broadcast the match, gathering 655,000 viewers.[68]\\nSee also[edit]\\n2024 UEFA Europa League final\\n2024 UEFA Europa Conference League final\\n2024 UEFA Women\\'s Champions League final\\n2024 UEFA Super Cup\\n2024 FIFA Intercontinental Cup\\n2025 FIFA Club World Cup\\nBorussia Dortmund in European football\\nReal Madrid CF in international football\\nReferences[edit]\\n^ a b \"Official Champions League final PlayStation Player of the Match: Dani Carvajal\". UEFA. 1 June 2024. Archived from the original on 3 June 2024. Retrieved 1 June 2024.\\n^ a b c d e f g h i \"Referee teams for 2024 UEFA club competition finals announced\". UEFA. 13 May 2024. Archived from the original on 13 May 2024. Retrieved 13 May 2024.\\n^ a b \"Full Time Report Final – Borussia Dortmund v Real Madrid\" (PDF). UEFA.com. Union of European Football Associations. 1 June 2024. Archived (PDF) from the original on 3 June 2024. Retrieved 1 June 2024.\\n^ a b c \"Tactical Line-ups – Final – Saturday 1 June 2024\" (PDF). UEFA. 1 June 2024. Archived (PDF) from the original on 3 June 2024. Retrieved 1 June 2024.\\n^ \"International match calendar and access list for the 2023/24 season\". UEFA Circular Letter. No.\\xa065/2022. Union of European Football Associations. 26 September 2022. Archived from the original on 21 October 2022. Retrieved 27 September 2022.\\n^ a b \"UEFA competitions to resume in August\". UEFA.com. Union of European Football Associations. 17 June 2020. Archived from the original on 25 August 2020. Retrieved 17 June 2020.\\n^ a b Pettit, Mark (1 June 2024). \"Real Madrid win Champions League: Carvajal and Vinícius Júnior see off Dortmund\". UEFA. Archived from the original on 2 June 2024. Retrieved 2 June 2024.\\n^ \"FIFA Council confirms key details for FIFA Club World Cup 2025™\". www.fifa.com. Retrieved 16 March 2024.\\n^ a b c d Stokkermans, Karel (27 January 2023). \"European Champions\\' Cup/Champions League\". RSSSF. Archived from the original on 6 July 2009. Retrieved 10 June 2023.\\n^ a b Stokkermans, Karel (26 January 2000). \"European Cup Winners\\' Cup\". RSSSF. Archived from the original on 15 March 2023. Retrieved 2 June 2024.\\n^ a b Stokkermans, Karel (1 June 2023). \"UEFA Cup/Europa League\". RSSSF. Archived from the original on 3 March 2016. Retrieved 2 June 2024.\\n^ \"Champions League-winning coaches: Carlo Ancelotti leads the way\". UEFA. 1 June 2024. Archived from the original on 12 December 2023. Retrieved 2 June 2024.\\n^ \"Borussia Dortmund\\xa0» Record against Real Madrid\". WorldFootball.net. 2 June 2024. Archived from the original on 2 June 2024. Retrieved 2 June 2024.\\n^ \"CL-Finale gegen den BVB: Das sind die Gefahren für Real Madrid\". neunzigplus.de (in German). 1 June 2024. Archived from the original on 1 June 2024. Retrieved 1 June 2024.\\n^ \"Champions League final: Dortmund and Real Madrid\\'s previous European Cup final appearances\". UEFA. 1 June 2024. Archived from the original on 2 June 2024. Retrieved 2 June 2024.\\n^ \"UEFA Champions League Statistics Handbook 2013/14: Finals\" (PDF). UEFA.com. Union of European Football Associations. 2014. Archived (PDF) from the original on 16 July 2021. Retrieved 24 September 2019.\\n^ \"EURO 2020: host cities and stadiums\". UEFA. 23 April 2021. Archived from the original on 2 June 2024. Retrieved 2 June 2024.\\n^ \"9 associations bidding to host 2021 club finals\". UEFA.com. Union of European Football Associations. 22 February 2019. Archived from the original on 18 June 2020. Retrieved 14 September 2019.\\n^ a b \"London Mayor backs bid to host 2023 Champions League final at Wembley\". Reuters. 31 July 2019. Archived from the original on 19 September 2020. Retrieved 14 September 2019.\\n^ \"Champions League final hosts announced for 2021, 2022 and 2023\". UEFA.com. Union of European Football Associations. 24 September 2019. Archived from the original on 22 December 2019. Retrieved 24 September 2019.\\n^ \"UEFA Executive Committee agenda for Ljubljana meeting\". UEFA.com. Union of European Football Associations. 17 September 2019. Archived from the original on 18 September 2019. Retrieved 17 September 2019.\\n^ a b \"UEFA Champions League group stage draw | UEFA Champions League 2023/24\". UEFA.com. 31 August 2023. Archived from the original on 30 August 2023. Retrieved 8 May 2024.\\n^ \"Hummels seals Champions League final place for Dortmund as PSG crash out\". The Guardian. 7 May 2024. Archived from the original on 10 May 2024. Retrieved 8 May 2024.\\n^ \"\\'Group of death\\' delivers as PSG, Newcastle and Milan all stay in hunt\". Reuters. 29 November 2023. Archived from the original on 29 November 2023. Retrieved 8 May 2024.\\n^ \"Paris-Dortmund | UEFA Champions League 2023/24\". UEFA.com. Archived from the original on 29 September 2023. Retrieved 8 May 2024.\\n^ \"Dortmund-Milan | UEFA Champions League 2023/24\". UEFA.com. Archived from the original on 29 September 2023. Retrieved 8 May 2024.\\n^ \"Newcastle-Dortmund | UEFA Champions League 2023/24\". UEFA.com. Archived from the original on 10 May 2024. Retrieved 8 May 2024.\\n^ \"Dortmund-Newcastle | UEFA Champions League 2023/24\". UEFA.com. Archived from the original on 10 May 2024. Retrieved 8 May 2024.\\n^ \"Milan-Dortmund | UEFA Champions League 2023/24\". UEFA.com. Archived from the original on 29 September 2023. Retrieved 8 May 2024.\\n^ \"Dortmund-Paris | UEFA Champions League 2023/24\". UEFA.com. Archived from the original on 29 September 2023. Retrieved 8 May 2024.\\n^ \"PSV-Dortmund | UEFA Champions League 2023/24\". UEFA.com. Archived from the original on 18 December 2023. Retrieved 8 May 2024.\\n^ \"Dortmund-PSV | UEFA Champions League 2023/24\". UEFA.com. Archived from the original on 13 March 2024. Retrieved 8 May 2024.\\n^ \"Atlético de Madrid-Dortmund | UEFA Champions League 2023/24\". UEFA.com. Archived from the original on 15 March 2024. Retrieved 8 May 2024.\\n^ \"Dortmund-Atlético de Madrid | UEFA Champions League 2023/24\". UEFA.com. Archived from the original on 15 March 2024. Retrieved 8 May 2024.\\n^ \"Dortmund-Paris | UEFA Champions League 2023/24\". UEFA.com. Archived from the original on 10 May 2024. Retrieved 8 May 2024.\\n^ \"Paris-Dortmund | UEFA Champions League 2023/24\". UEFA.com. Archived from the original on 10 May 2024. Retrieved 8 May 2024.\\n^ \"Real Madrid-Union Berlin | UEFA Champions League 2023/24\". UEFA.com. Archived from the original on 22 September 2023. Retrieved 9 May 2024.\\n^ \"Napoli-Real Madrid | UEFA Champions League 2023/24\". UEFA.com. Archived from the original on 6 March 2024. Retrieved 9 May 2024.\\n^ \"Braga-Real Madrid | UEFA Champions League 2023/24\". UEFA.com. Archived from the original on 22 September 2023. Retrieved 9 May 2024.\\n^ \"Real Madrid-Braga | UEFA Champions League 2023/24\". UEFA.com. Archived from the original on 22 September 2023. Retrieved 9 May 2024.\\n^ \"Real Madrid-Napoli | UEFA Champions League 2023/24\". UEFA.com. Archived from the original on 22 September 2023. Retrieved 9 May 2024.\\n^ \"Union Berlin-Real Madrid | UEFA Champions League 2023/24\". UEFA.com. Archived from the original on 22 September 2023. Retrieved 9 May 2024.\\n^ \"Leipzig-Real Madrid | UEFA Champions League 2023/24\". UEFA.com. Archived from the original on 14 February 2024. Retrieved 9 May 2024.\\n^ \"Real Madrid-Leipzig | UEFA Champions League 2023/24\". UEFA.com. Archived from the original on 18 December 2023. Retrieved 9 May 2024.\\n^ \"Real Madrid-Man City | UEFA Champions League 2023/24\". UEFA.com. Archived from the original on 15 March 2024. Retrieved 9 May 2024.\\n^ \"Man City-Real Madrid | UEFA Champions League 2023/24\". UEFA.com. Archived from the original on 15 March 2024. Retrieved 9 May 2024.\\n^ \"Bayern-Real Madrid | UEFA Champions League 2023/24\". UEFA.com. Archived from the original on 17 April 2024. Retrieved 9 May 2024.\\n^ \"Real Madrid-Bayern | UEFA Champions League 2023/24\". UEFA.com. Archived from the original on 17 April 2024. Retrieved 9 May 2024.\\n^ \"Brand identity unveiled for the 2024 UEFA Champions League final in London\". UEFA.com. 31 August 2023. Archived from the original on 31 August 2023. Retrieved 31 August 2023.\\n^ \"Referee teams appointed for 2022 UEFA club competition finals\". UEFA.com. Union of European Football Associations. 11 May 2022. Archived from the original on 11 May 2022. Retrieved 14 May 2024.\\n^ \"Lenny Kravitz to headline UEFA Champions League Final Kick Off Show by Pepsi\". UEFA.com. 17 May 2024. Archived from the original on 17 May 2024. Retrieved 17 May 2024.\\n^ \"¡Brutal! Así fue el show de Lenny Kravitz en la final de la Champions League 2024\" [Brutal! This was Lenny Kravitz\\'s show in the 2024 Champions League final]. Esto.com.mx (in Spanish). 1 June 2024. Archived from the original on 2 June 2024. Retrieved 2 June 2024.\\n^ a b c d Cox, Brad (2 June 2024). \"Champions League final score: Dortmund vs. Real Madrid result, highlights as Vinicius seals 2024 UCL title\". Sporting News. Archived from the original on 2 June 2024. Retrieved 2 June 2024.\\n^ a b c d Murray, Scott (1 June 2024). \"Borussia Dortmund 0–2 Real Madrid: Champions League final 2024 – as it happened\". The Guardian. Archived from the original on 2 June 2024. Retrieved 2 June 2024.\\n^ \"Champions League quarter-final draw: Real Madrid vs Man City, Paris vs Barcelona\". UEFA. 15 March 2024. Archived from the original on 2 June 2024. Retrieved 15 March 2024.\\n^ \"Regulations of the UEFA Champions League, 2023/24 Season\". Nyon: UEFA. 2023. Archived from the original on 24 March 2024. Retrieved 28 June 2023.\\n^ a b c \"Team statistics\" (PDF). UEFA. 1 June 2024. Archived (PDF) from the original on 17 June 2024. Retrieved 1 June 2024.\\n^ \"Ancelotti: Real Madrid will be back with same winning \\'desire\\'\". theScore. Agence France-Presse. 1 June 2024. Archived from the original on 5 June 2024. Retrieved 2 June 2024.\\n^ Benge, James (1 June 2024). \"Real Madrid\\'s UCL hero Dani Carvajal eyes passing legendary Paco Gento: \\'Why not dream of getting another?\\'\". CBS Sports. Archived from the original on 2 June 2024. Retrieved 2 June 2024.\\n^ \"Champions League final records and statistics\". UEFA. 1 June 2024. Archived from the original on 5 June 2024. Retrieved 2 June 2024.\\n^ \"Edin Terzic leaves Borussia Dortmund\". Borussia Dortmund. 13 June 2024. Archived from the original on 13 June 2024. Retrieved 11 January 2025.\\n^ \"Sahin appointed as BVB head coach\". Borussia Dortmund. 14 June 2024. Archived from the original on 14 June 2024. Retrieved 11 January 2025.\\n^ Jones, Simon; Jackson, Liz (1 June 2024). \"Champions League: Police arrest 53 around Wembley final\". BBC News. Archived from the original on 1 June 2024. Retrieved 2 June 2024.\\n^ Howard, Jacqueline (3 June 2024). \"Three people charged after Champions League pitch invasion\". BBC News. Archived from the original on 3 June 2024. Retrieved 3 June 2024.\\n^ Neal, Will (2 June 2024). \"Russian vlogger \\'unmasked as instigator behind Champions League chaos\\'\". Metro. Archived from the original on 3 June 2024. Retrieved 3 June 2024.\\n^ Warren, Jess (3 June 2024). \"Champions League final: Man handed UK ban over pitch invasion bid\". BBC News. Archived from the original on 4 June 2024. Retrieved 4 June 2024.\\n^ a b c d RTVE, PRENSA (2 June 2024). \"El Madrid conquista su 15ª Champions ante más de 6,1 millones en La 1 (48,8%), lo más visto de la temporada\". RTVE.es (in Spanish). Archived from the original on 2 June 2024. Retrieved 2 June 2024.\\n^ Romero, Gabriel Arias (2 June 2024). \"TVE (48.8%) arrasa con la final de la Champions y la victoria del Real Madrid ante más de 6 millones de espectadores\". Vertele (in Spanish). Archived from the original on 2 June 2024. Retrieved 2 June 2024.\\nExternal links[edit]\\nOfficial website\\nvte\\nEuropean Cup and UEFA Champions League\\nEuropean Cup era, 1955–1992\\nSeasons \\n1955–561956–571957–581958–591959–601960–611961–621962–631963–641964–651965–661966–671967–681968–691969–701970–711971–721972–731973–741974–751975–761976–771977–781978–791979–801980–811981–821982–831983–841984–851985–861986–871987–881988–891989–901990–911991–92\\nFinals\\n1956195719581959196019611962196319641965196619671968196919701971197219731974197519761977197819791980198119821983198419851986198719881989199019911992\\nUEFA Champions League era, 1992–present\\nSeasons \\n1992–931993–941994–951995–961996–971997–981998–991999–20002000–012001–022002–032003–042004–052005–062006–072007–082008–092009–102010–112011–122012–132013–142014–152015–162016–172017–182018–192019–202020–212021–222022–232023–242024–252025–26\\nFinals\\n19931994199519961997199819992000200120022003200420052006200720082009201020112012201320142015201620172018201920202021202220232024202520262027\\nHistoryRecords and statistics Top scorersHat-tricksAppearancesWinning managersPerformance comparisonUEFA coefficientAnthemBroadcasters in the USVideo gamesTrophyExtra-sporting events 1985 Heysel Stadium disaster2007 Roma–Manchester United conflict2017 Turin stampede2022 Paris chaos\\nvte\\n2023–24 in European men\\'s football (UEFA)\\nDomestic leagues  \\nAlbaniaAndorraArmeniaAustriaAzerbaijanBelarus \\'23 \\'24BelgiumBosnia and HerzegovinaBulgariaCroatiaCyprusCzech RepublicDenmarkEnglandEstonia \\'23 \\'24Faroe Islands \\'23 \\'24Finland \\'23 \\'24FranceGeorgia \\'23 \\'24GermanyGibraltarGreeceHungaryIceland \\'23 \\'24IsraelItalyKazakhstan \\'23 \\'24KosovoLatvia \\'23 \\'24Lithuania \\'23 \\'24LuxembourgMaltaMoldovaMontenegroNetherlandsNorth MacedoniaNorthern IrelandNorway \\'23 \\'24PolandPortugalRepublic of Ireland \\'23 \\'24RomaniaRussiaSan MarinoScotlandSerbiaSlovakiaSloveniaSpainSweden \\'23 \\'24SwitzerlandTurkeyUkraineWales\\nDomestic cups \\nAlbaniaAndorraArmeniaAustriaAzerbaijanBelarusBelgiumBosnia and HerzegovinaBulgariaCroatiaCyprusCzech RepublicDenmarkEnglandEstoniaFaroe Islands \\'23 \\'24Finland \\'23 \\'24FranceGeorgia \\'23 \\'24GermanyGibraltarGreeceHungaryIceland \\'23 \\'24IsraelItalyKazakhstan \\'23 \\'24KosovoLatvia \\'23 \\'24LiechtensteinLithuania \\'23 \\'24LuxembourgMaltaMoldovaMontenegroNetherlandsNorth MacedoniaNorthern IrelandNorway \\'23 \\'24PolandPortugalRepublic of Ireland \\'23 \\'24RomaniaRussiaSan MarinoScotlandSerbiaSlovakiaSloveniaSpainSwedenSwitzerlandTurkeyUkraineWales\\nLeague cups \\nEnglandFinlandIcelandIsraelKazakhstan \\'24Northern IrelandPortugalScotlandWales\\nSupercups \\nAlbaniaAndorraArmeniaAzerbaijanBelarusBelgiumBulgariaCroatiaCyprusEnglandEstonia \\'23 \\'24Faroe IslandsFranceGeorgiaGermanyIcelandIsraelItalyKazakhstan \\'23 \\'24KosovoLatvia \\'24Lithuania \\'23 \\'24MaltaMoldovaNetherlandsNorthern IrelandPolandPortugalRepublic of Ireland \\'23 \\'24RomaniaRussiaSan MarinoSpainTurkeyUkraine\\nUEFA competitions \\nChampions League qualifying phase and play-off roundgroup stageknockout phaseFinalEuropa League qualifying phase and play-off roundgroup stageknockout phaseFinalEuropa Conference League qualifying phase and play-off round Champions PathMain Pathgroup stageknockout phaseFinalSuper CupUEFA–CONMEBOL Club ChallengeYouth League UEFA Champions League PathDomestic Champions Pathknockout phaseUnder-20 Intercontinental Cup\\nInternational competitions\\nUEFA Euro 2024 qualification2022–23 UEFA Nations League League C relegation play-outsFootball at the 2024 Summer Olympics (qualification)2023 FIFA U-20 World Cup2023 FIFA U-17 World Cup2025 Euro Under-21 qualification2024 Euro Under-19 qualification2024 Euro Under-17 qualification\\nvte\\nBorussia Dortmund matches\\nGerman football championship finals \\n19491956195719611963\\nDFB-Pokal finals  \\n1963196519892008201220142015201620172021\\nDFL-Supercup  \\n1989199519962008 (unofficial)201120122013201420162017201920202021\\nDFB-Ligapokal final \\n2003\\nUEFA Champions League finals  \\n199720132024\\nEuropean Cup Winners\\' Cup final \\n1966\\nUEFA Cup finals \\n19932002\\nUEFA Super Cup\\n1997\\nIntercontinental Cup  \\n1997\\nOther matches \\nBorussia Mönchengladbach 12–0 Borussia Dortmund (1978)\\nvte\\nReal Madrid CF matches\\nCategories: UEFA Champions League finals2023–24 UEFA Champions LeagueJune 2024 sports events in the United KingdomBorussia Dortmund matches2023–24 in German footballReal Madrid CF matches2023–24 in Spanish footballInternational club association football competitions hosted by LondonInternational club association football competitions hosted by England2020s in London2023–24 in English football2024 sports events in LondonSports events at Wembley Stadium\\nThis page was last edited on 11 January 2025, at 10:44\\xa0(UTC).\\nText is available under the Creative Commons Attribution-ShareAlike 4.0 License; additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.\\nPrivacy policy\\nAbout Wikipedia\\nDisclaimers\\nContact Wikipedia\\nCode of Conduct\\nDevelopers\\nStatistics\\nCookie statement\\nMobile view',\n",
              " \"2024/25 UEFA Champions League: Matches, draw, final, key dates | UEFA Champions League | UEFA.com\\nChampions League Official Live football scores & Fantasy\\nGet\\n\\nUEFA.com works better on other browsers\\nFor the best possible experience, we recommend using Chrome, Firefox or Microsoft Edge.\\nSkip to main content\\nUEFA Champions League\\nFavourite team\\nUEFA Champions League - 2024/25 UEFA Champions League: Matches, draw, final, key dates - News \\n2024/25 UEFA Champions League: Matches, draw, final, key dates\\nWednesday, February 5, 2025\\nArticle summary\\nWhat are the match dates? Where is the 2025 final? How will the competition work?\\nArticle top media content\\n\\nEyes on the prize: The Champions League trophy UEFA via Getty Images\\nArticle body\\nThis will be the 70th season of Europe's elite club competition and the 33rd since it was renamed the UEFA Champions League, as well as the first under the new format. It kicks off on 9 July 2024 and runs until the final on Saturday 31 May 2025.\\nPlease note that dates are subject to change.\\nWhat is the new Champions League format?\\nThe biggest change is to the group stage, which will become a single 36-team league stage. Each side faces eight different teams (four at home, four away). The top eight overall advance directly to the round of 16; sides finishing from ninth to 24th will contest the knockout phase play-offs, with the victors going through to the last 16. From then on it is a straight knockout.\\nNew format explainer\\nWhen are the 2024/25 Champions League qualifiers?\\nFirst qualifying round: 9/10 & 16/17 July 2024\\nSecond qualifying round: 23/24 & 30/31 July 2024\\n\\ufeffThird qualifying round: 6/7 & 13 August 2024\\nPlay-offs: 20/21 & 27/28 August 2024\\n\\nMan City won the 2022/23 UEFA Champions LeagueGetty Images\\nWhen are the 2024/25 Champions League league phase matches?\\nMatchday 1: 17–19 September 2024\\nMatchday 2: 1/2 October 2024\\nMatchday 3: 22/23 October 2024\\nMatchday 4: 5/6 November 2024\\nMatchday 5: 26/27 November 2024\\nMatchday 6: 10/11 December 2024\\nMatchday 7: 21/22 January 2025\\nMatchday 8: 29 January 2025\\nWhen is the 2024/25 Champions League knockout stage?\\nKnockout phase play-offs: 11/12 & 18/19 February 2025\\nRound of 16: 4/5 & 11/12 March 2025\\nQuarter-finals: 8/9 & 15/16 April 2025\\nSemi-finals: 29/30 April & 6/7 May 2025\\nFinal: 31 May 2025\\nWhen are the 2024/25 Champions League draws?\\nFirst qualifying round: 18 June 2024\\nSecond qualifying round: 19 June 2024\\nThird qualifying round: 22 July 2024\\nPlay-offs: 5 August 2024\\nLeague phase: 29 August 2024\\nKnockout phase play-offs: 31 January 2025\\nRound of 16, quarter-final, semi-final: 21 February 2025\\nWhere is the Champions League final in 2025?\\nThe 2024/25 UEFA Champions League season will conclude at the Munich Football Arena, the highlight of European football's club calendar returning to the German city for the first time since 2012.\\nCompleted on 30 April 2005, the stadium is located on Werner-Heisenberg-Allee and belongs to Bayern München. It staged four games at UEFA EURO 2020 and since it will also be a venue for UEFA EURO 2024, it will be the first stadium in history to host matches in consecutive UEFA European Championships. Its capacity for that tournament will be 67,000.\\nMunich hosts 2024/25 Champions League final\\nWhat do the Champions League winners get?\\nThe current UEFA Champions League trophy stands 73.5cm tall and weighs 7.5kg.\\nThe 2024/25 winners also gain a place in the League stage of the 2025/26 UEFA Champions League, if they have not qualified via their domestic competition. They will also earn the right to play against the winners of the 2024/25 UEFA Europa League in the 2025 UEFA Super Cup.\\n© 1998-2025 UEFA. All rights reserved. Last updated: Wednesday, February 5, 2025\\nSelected for you\\n Live 10/05/2022 Format, access list for 2024/25 approved ---------------------------------------- No more access granted based on club coefficients. Eight matches instead of ten in the new league phase.\\n Live 05/02/2025 Where is the 2025 final? ------------------------ The 2024/25 UEFA Champions League final will take place at the Munich Football Arena.\\nUEFA Champions League\\n\\nMatches\\nDraws\\nTable\\nVideo\\nGaming\\n\\nStats\\n\\n\\nTeams\\n\\nNew format\\nNews\\nHistory\\nAbout\\nStore\\n\\n\\nAlso visit\\n\\nUEFA.com\\nUEFA Foundation\\n\\n\\nChange language\\n\\nEnglish\\nFrançais\\nDeutsch\\nРусский\\nEspañol\\nItaliano\\nPortuguês\\n\\n\\nSocial and apps links\\n\\nFollow us on\\ntwitter\\nfacebook\\nyoutube\\n\\ninstagram\\n\\n\\n\\n\\n\\n\\n\\nServices links and disclaimer\\n\\nPrivacy\\nTerms and conditions\\nCookie policy\\nCookie Settings\\n\\n© 1998-2025 UEFA. All rights reserved.\\nThe UEFA word, the UEFA logo and all marks related to UEFA competitions, are protected by trademarks and/or copyright of UEFA. No use for commercial purposes may be made of such trademarks. Use of UEFA.com signifies your agreement to the Terms and Conditions and Privacy Policy.\\nTop\",\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " ' News\\n Life\\n Entertainment\\n Finance\\n  Sports\\nNew on Yahoo\\nYahoo Sports\\nChampions League final 2024: What time tomorrow and how to watch on TV\\nReal Madrid will face Borussia Dortmund in the Champions League final tomorrow night.\\nThe final pits two high-profile English players against each other. Jude Bellingham has been outstanding for Real Madrid this season and in the build-up to the final his team-mate Luka Modric explained the precise moment he realised that Bellingham was the club’s future.\\nMeanwhile for Dortmund, Jadon Sancho will be a goal threat. He too has enjoyed a productive season since being sent on loan by Manchester United, where he fell out badly with Erik ten Hag.\\nShould Madrid win, they will secure a double, having won La Liga for a 36th time. By contrast Borussia Dortmund finished fifth in the Bundesliga. The German side were also beaten in the round of 16 in the German Cup.\\nReal Madrid have won the European Cup 14 times, more than any other club. Dortmund were winners in 1997 when Lars Ricken’s famous chip from distance helped them beat Juventus.\\nNew security arrangements at Wembley will be put to the test, with millions of pounds spent to avoid a repeat of the mayhem that surrounded the Euro 2020 final.\\nWhen is the Champions League final?\\nThis year’s Champions League final is tomorrow: Saturday, June 1. Kick-off is 8pm UK time.\\nWhat channel is it being shown on TV in the UK?\\nTNT Sports have the UK rights to the Champions League and will be showing the final.\\nViewers in the UK will be able to watch for free on discovery+, which is available via an app or on a smart TV. You will, however, have to register for an account. EE customers and Sky customers can also get discovery+ as part of their package.\\nWhere is it being held?\\nThe 2024 Champions League final is being held at Wembley Stadium in London.\\nThe European Cup final returns to the famous venue for a record eighth time, and the third in the Champions League era following the 2011 and 2013 finals.\\nBayern Munich beat Borussia Dortmund 2-1 in an all-German affair in 2013, while in 2011 Manchester United lost 3-1 to a Lionel Messi-inspired Barcelona.\\nA young Pep Guardiola helped Barcelona win the 1992 European Cup final at the old Wembley in a 1-0 victory over Sampdoria.\\nHosting the showpiece match at Wembley will also be an opportunity for English football to put the disgrace of the Euro 2020 final at the same venue behind it.\\nHow can I watch in the US?\\nIn the United States, the Champions League is shown on CBS and CBS Sports Network.\\nWhat happened in the Champions League semi-finals?\\nIn the semi-final between Madrid and Bayern Munich, Joselu came off the substitute’s bench to score twice to end Bayern’s hopes of winning a seventh European Cup.\\nBorussia Dortmund secured their place when Mats Hummels scored the only goal of their second leg, securing a 2-0 aggregate win over Paris St-Germain.\\nFirst leg: Bayern Munich 2 Real Madrid 2\\xa0First leg: Borussia Dortmund 1 PSG 0\\nSecond leg: PSG 0 Borussia Dortmund 1; agg 0-2\\xa0Second leg: Real Madrid 2 Bayern Munich 1; agg 4-3\\nHow to buy tickets for the final\\nGood luck. But theoretically you can still apply to buy hospitality tickets for the final on Uefa’s official ticket website.\\nWho are the current champions?\\nManchester City won the Champions League last season, beating Inter Milan 1-0 in the final, to complete a Treble. City were knocked out by Real Madrid in the quarter-finals this year.\\nLatest news\\nFA promises no repeat of 2021 mayhem as it beefs up Wembley security\\nMulti-million pound security improvements at Wembley since mayhem at Euro 2020 will be put to the test at Saturday’s Champions League final.\\nThe Football Association has invested £5 million on measures including extra closed-circuit TV, reinforced doors, more fencing and a new “Zone X” control room.\\nChris Bryant, the FA’s director of tournaments and events, recognised “a lot of people” will be thinking of 2021 as he promised such scenes will be avoided this time. “We are doing all we can to ensure fans have a smooth arrival process and nice experience as they come to the stadium,” he said of a co-ordinated plan, which includes the now regular drinking ban on Wembley Way.\\nAn independent review by Baroness Casey identified more than 20 “near-misses” that could have resulted in serious injury or death as a result of ticketless individuals trying to gain entry, and in some cases succeeding, for the England v Italy match in July 2021.\\nEntrance to the stadium will be allowed four hours before kick-off instead of two, and Transport for London will run extra services to aid the flow of supporters to and from the ground.\\nBryant acknowledged the steward supply at the Euro 2020 final was at a low point off the back of the coronavirus pandemic, and said Saturday’s match would see “the highest ever stewarding deployment in Wembley Stadium history”.\\n“One thing in the Euros final was very much the supply of stewarding, which I can say was at a low point off the back of Covid,” he said. “We’re very confident the supply of stewarding which you’ve seen in the industry has bounced back.”\\nWhat is the prize money for the Champions League?\\nThe winner of the final will receive €20 million (£17.1 million) from Uefa. However, with the accumulative prize money on offer as a team progresses through the tournament, the winner could net up to €85.14 million (£72.69 million), depending on their results. Last year Man City earned around £85 million for winning the trophy for the first time.\\nWho have won the most European Cups?\\nReal Madrid have won the European Cup the most times (14), AC Milan (7) are second, with Liverpool and Bayern Munich tied for third with six wins. Barcelona have five wins, Ajax have four, Manchester United and Inter Milan have three apiece, while five teams have won it twice: Chelsea, Nottingham Forest, Juventus, Benfica and Porto. Ten teams have won the title once: Man City, Aston Villa, Celtic,\\xa0Borussia Dortmund, Hamburg,\\xa0Feyenoord, PSV Eindhoven, Marseille, Red Star Belgrade and Steaua Bucharest.\\nWhat are the latest odds?\\nBorussia Dortmund: 5/2\\nReal Madrid: 3/10\\nOdds correct as of May 31\\nBroaden your horizons with award-winning British journalism. Try The Telegraph free for 3 months with unlimited access to our award-winning website, exclusive app, money-saving offers and more.\\n',\n",
              " None]"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Agentic RAG components\n",
        "\n",
        "Here we will build the key components of our Agentic Corrective RAG System as per the workflow below:\n",
        "\n",
        "![](https://i.imgur.com/uhybMhT.png)\n",
        "\n"
      ],
      "metadata": {
        "id": "D2N5192vikJR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Graph State\n",
        "\n",
        "Used to store and represent the state of the agent graph as we traverse through various nodes"
      ],
      "metadata": {
        "id": "U5tUXzqPsbQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "class GraphState(TypedDict):\n",
        "    \"\"\"\n",
        "    Represents the state of our graph.\n",
        "\n",
        "    Attributes:\n",
        "        question: question\n",
        "        generation: LLM response generation\n",
        "        web_search_needed: flag of whether to add web search - yes or no\n",
        "        documents: list of context documents\n",
        "    \"\"\"\n",
        "\n",
        "    question: str\n",
        "    generation: str\n",
        "    web_search_needed: str\n",
        "    documents: List[str]"
      ],
      "metadata": {
        "id": "_B2EFrwTpuXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retrieve function for retrieval from Vector DB\n",
        "\n",
        "This will be used to get relevant context documents from the vector database"
      ],
      "metadata": {
        "id": "qXfVLhOWtHJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve(state):\n",
        "    \"\"\"\n",
        "    Retrieve documents\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): New key added to state, documents - that contains retrieved context documents\n",
        "    \"\"\"\n",
        "    print(\"---RETRIEVAL FROM VECTOR DB---\")\n",
        "    question = state[\"question\"]\n",
        "\n",
        "    # Retrieval\n",
        "    documents = similarity_threshold_retriever.invoke(question)\n",
        "    return {\"documents\": documents, \"question\": question}"
      ],
      "metadata": {
        "id": "W0rVVBGDpuYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Grade documents\n",
        "\n",
        "This will be used to determine whether the retrieved documents are relevant to the question by using an LLM Grader\n",
        "\n",
        "Sets the `web_search_needed` flag as `Yes` if at least one document is not contextually relevant and sets it as `No` if all documents are contextually relevant to the given user query"
      ],
      "metadata": {
        "id": "lpOsUnzn6Yo1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def grade_documents(state):\n",
        "    \"\"\"\n",
        "    Determines whether the retrieved documents are relevant to the question\n",
        "    by using an LLM Grader.\n",
        "\n",
        "    If any document are not relevant to question or documents are empty - Web Search needs to be done\n",
        "    If all documents are relevant to question - Web Search is not needed\n",
        "    Helps filtering out irrelevant documents\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): Updates documents key with only filtered relevant documents\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "\n",
        "    # Score each doc\n",
        "    filtered_docs = []\n",
        "    web_search_needed = \"No\"\n",
        "    if documents:\n",
        "        for d in documents:\n",
        "            score = doc_grader.invoke(\n",
        "                {\"question\": question, \"document\": d.page_content}\n",
        "            )\n",
        "            grade = score.binary_score\n",
        "            if grade == \"yes\":\n",
        "                print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
        "                filtered_docs.append(d)\n",
        "            else:\n",
        "                print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
        "                web_search_needed = \"Yes\"\n",
        "                continue\n",
        "    else:\n",
        "        print(\"---NO DOCUMENTS RETRIEVED---\")\n",
        "        web_search_needed = \"Yes\"\n",
        "\n",
        "    return {\"documents\": filtered_docs, \"question\": question, \"web_search_needed\": web_search_needed}"
      ],
      "metadata": {
        "id": "NI20nh1DtTwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rewrite query\n",
        "\n",
        "This will be used to rewrite the input query to produce a better question optimized for web search using an LLM"
      ],
      "metadata": {
        "id": "fj1jk8C16hhE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rewrite_query(state):\n",
        "    \"\"\"\n",
        "    Rewrite the query to produce a better question.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): Updates question key with a re-phrased or re-written question\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---REWRITE QUERY---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "\n",
        "    # Re-write question\n",
        "    better_question = question_rewriter.invoke({\"question\": question})\n",
        "    return {\"documents\": documents, \"question\": better_question}"
      ],
      "metadata": {
        "id": "Xw_iVhvWuSG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Web Search\n",
        "\n",
        "This will be used to search the web using the web search tool for the given query and retrieve some information which can be used as the context in RAG"
      ],
      "metadata": {
        "id": "HMogEnhT7Icn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import Document\n",
        "\n",
        "def web_search(state):\n",
        "    \"\"\"\n",
        "    Web search based on the re-written question.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): Updates documents key with appended web results\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---WEB SEARCH---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "\n",
        "    # Web search\n",
        "    docs = search_web.invoke(question)\n",
        "    docs = list(filter(lambda x: x is not None, docs))\n",
        "    web_results = \"\\n\\n\".join([d for d in docs])\n",
        "    web_results = Document(page_content=web_results)\n",
        "    documents.append(web_results)\n",
        "\n",
        "    return {\"documents\": documents, \"question\": question}"
      ],
      "metadata": {
        "id": "YM7f6AyCvUP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate Answer\n",
        "\n",
        "Standard LLM Response generation from query and context documents in a RAG system"
      ],
      "metadata": {
        "id": "ruTBxSkm7R2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_answer(state):\n",
        "    \"\"\"\n",
        "    Generate answer from context document using LLM\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): New key added to state, generation, that contains LLM generation\n",
        "    \"\"\"\n",
        "    print(\"---GENERATE ANSWER---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "\n",
        "    # RAG generation\n",
        "    generation = qa_rag_chain.invoke({\"context\": documents, \"question\": question})\n",
        "    return {\"documents\": documents, \"question\": question, \"generation\": generation}"
      ],
      "metadata": {
        "id": "MemqMTolwLhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decide to Generate\n",
        "\n",
        "This will be used as a conditional function which will check the `web_search_needed` flag and decide if a web search is needed or a response should be generated and return the function name to be called"
      ],
      "metadata": {
        "id": "-9zcEgiu8HRY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decide_to_generate(state):\n",
        "    \"\"\"\n",
        "    Determines whether to generate an answer, or re-generate a question.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        str: Binary decision for next node to call\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---ASSESS GRADED DOCUMENTS---\")\n",
        "    web_search_needed = state[\"web_search_needed\"]\n",
        "\n",
        "    if web_search_needed == \"Yes\":\n",
        "        # All documents have been filtered check_relevance\n",
        "        # We will re-generate a new query\n",
        "        print(\"---DECISION: SOME or ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, REWRITE QUERY---\")\n",
        "        return \"rewrite_query\"\n",
        "    else:\n",
        "        # We have relevant documents, so generate answer\n",
        "        print(\"---DECISION: GENERATE RESPONSE---\")\n",
        "        return \"generate_answer\""
      ],
      "metadata": {
        "id": "Zi3GzDLRv3Nf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build the Agent Graph\n",
        "\n",
        "Here we will use LangGraph and build the agent as a graph"
      ],
      "metadata": {
        "id": "EpjPx4v89BVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import END, StateGraph\n",
        "\n",
        "agentic_rag = StateGraph(GraphState)\n",
        "\n",
        "# Define the nodes\n",
        "agentic_rag.add_node(\"retrieve\", retrieve)  # retrieve\n",
        "agentic_rag.add_node(\"grade_documents\", grade_documents)  # grade documents\n",
        "agentic_rag.add_node(\"rewrite_query\", rewrite_query)  # transform_query\n",
        "agentic_rag.add_node(\"web_search\", web_search)  # web search\n",
        "agentic_rag.add_node(\"generate_answer\", generate_answer)  # generate answer\n",
        "\n",
        "# Build graph\n",
        "agentic_rag.set_entry_point(\"retrieve\")\n",
        "agentic_rag.add_edge(\"retrieve\", \"grade_documents\")\n",
        "agentic_rag.add_conditional_edges(\n",
        "    \"grade_documents\",\n",
        "    decide_to_generate,\n",
        "    {\"rewrite_query\": \"rewrite_query\", \"generate_answer\": \"generate_answer\"},\n",
        ")\n",
        "agentic_rag.add_edge(\"rewrite_query\", \"web_search\")\n",
        "agentic_rag.add_edge(\"web_search\", \"generate_answer\")\n",
        "agentic_rag.add_edge(\"generate_answer\", END)\n",
        "\n",
        "# Compile\n",
        "agentic_rag = agentic_rag.compile()"
      ],
      "metadata": {
        "id": "F24b6qm_yhnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display, Markdown\n",
        "\n",
        "display(Image(agentic_rag.get_graph().draw_mermaid_png()))"
      ],
      "metadata": {
        "id": "X3D6GCcN0ElZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "outputId": "be21959f-5013-4b2a-f840-b6242ee9993c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAANIAAAJ2CAIAAACl6UvEAAAAAXNSR0IArs4c6QAAIABJREFUeJztnXdck8cfxy+ThCRASCAsERQHKk5cqCgCDgQH4qjirBtX1VoHba1VrNu6J1rFBSoi7oELJw6s1onKnpmMDLJ+fzz8UqrI0PBcxr3/4JU86z558uHu+1zuvkfQarUAgcAXImwBCHME2Q4BAWQ7BASQ7RAQQLZDQADZDgEBMmwBhoggT1EqVklL1AqZplyugS2nVljQiEQywZJFsmSRHN3psOXUAAH12+nIelv24bn044syJ3eaXKaxZJFs7CgaNWxZtYNKJ4oLy6UlarVKm/FK6t6K4d6K4dmJRSAQYEurAmQ7AADISZPdSeRzHKl2zhburRgsNgW2om/lw/PSjy/KMl5J2/nZtPNjw5bzKch2IOl4oaRI6RPC4TWkwdaiZ7Qa7Z1EweuU4n7jHFyaWMKW8y9mbbtiofLomswBkxxdPAzoK9E7slL15Zh8N09Gm542sLVUYL62k5WqYzdkfbfQlUozi8f5W/FFHEdqyy7WsIUA87WdIE9xbl/e2Eg32EJw5caJQjKF2H0QF7YQc+23O7oma8zShrBV4E2vMHtZqfp1SjFsIWZpu4t/5Y36qYFh9izUN4GjeZmvpUU5CrgyzM52rx4WkylEWwcL2EKg0bKrdXI8H64Gs7Pd3USBTwgHtgqYOHvQSRRCxqsyiBrMy3b/3JO06WltyTL3nwS7DeK8ghrhmZft3jwqwe33SrVanZqaCuv06uE4WBRkKIoFynq6fo2Yke0UMjU/t9y5MU62+/3336OiomCdXiPurRgfX0BrZ83IdhmvpC06s3ArTqH4yqdFrCf1q0+vJY3bMAoy5fVaRDWYUZQjzC+3sCTVx5WTk5O3bNmSnZ3t5OQUFhY2YsSIZcuWXblyBQDg7e0NADhz5oyTk9OZM2diY2PT0tIsLS27du26YMECNpsNALh69eqiRYvWrVt36NChf/75Z9y4cQUFBZ+frl/NVmxK7gdku/pHWqzmuem/30Qqlf7000+NGjWKjIxMS0srKioCAEycOLGgoCAnJ2f58uUAAC6XCwB4/vy5m5tbUFCQUCg8duxYWVnZpk2bdNdZvXp1RETE9OnTXV1d5XL556frF4YVuaxYpffL1hIzsl1ZsYphxdD7ZYVCoUKh6N27d//+/XUbXV1dbWxsBAJB27ZtdRuXLFmi66Mmk8nR0dEKhcLCouI/YcSIEcHBwbqDPz9dvxBJBAs6UVaqpjPrpQWoHjOyHYlMIJH1/8uEs7Nz69at9+3bR6fTQ0NDqVTql45UKpXHjh07f/58fn4+jUbTaDQikcjBwQHb26lTJ71rqx5LFlmt0gAAwXZm9EhBpRFLxfpvVggEwubNm4ODgzdt2hQaGvrkyZMqD9NqtXPnzo2Ojh44cODWrVuDgoIAABrNvyPmLS3xHnwlzC9n2sAZ0GpGtrO0IkmL62WIOpPJXLRo0cmTJ5lM5rx586RSKba98uieJ0+ePHz4cNGiRaNGjWrVqpWHh0eNl63XwUFlxSpLFoR6DsOMbMe2p6pV9TIfB+vscHZ2HjlyZGlpaW5uLgCATqcLBAJdfSYWiwEAzZs3r/y2cm33CZ+crnekxWqXptBm+pCWLVsGq2ycoTNIN04Uteul54kFSqUyNDS0qKiIz+cfP35coVDMmDGDTCaXlJRcunSpqKiouLg4Pz+/ZcuWcXFxeXl5DAYjKSlp7969SqXS29vbzc3tw4cPV69eHT58uI3Nv6N/Pzm9YUM9D9N6niyxZJFx6zz/BDOyHZVGfJNSwnOjMaz0+SBVVlaWmZl5/fr1pKQkOzu7ZcuWubi4AAA8PDwkEsnFixefPHliY2Pj5+fXqFGjxMTExMRElUq1YsWKwsLC1NTU4ODgKm33yel6f+C4fZrfwZ9tqddbUXvMa3Tx0+siIpnQpoehTCmARalYeT2uKGSynruga48ZdaAAANr5sbf+kFaN7VJSUn788cfPt7NYrJKSkipPmTNnzpAhQ/Qq81NKS0srd+lVpnXr1n///ffn2ydNmhQeHv6lC94/L/Row9SrxrphXrUdAODxNZFCqvYJqbrfXy6XC4XCOl3Q2tqawdB/L3RlNBpNfn5+nU6xsrJiMqs2lqig/Fx0XvhimGP6zc52AICEnTn9xztQadC6D+By61SRa3NLtxb1+69SPWbUgaKj1zD7Y2uzYKuAQ8plIZVGhOs5M7WdNYfSfTA3YUcObCF48+KOuDBL0SUI/ph+c2xkMQqz5PfOCgZNd4YtBCee35UI8xQ9h9rDFgLMtLbDsG9Aa+1rc+C3dCm88T+4cTu+qCjTUDxn1rUdRolImXS80MaO6hPCoVBN8J/w1cPiu4mCjn3ZrbsbUG+ludsO4+/b4ruJgg4BbKdGdGcPQ89JWBskfOXHF2XvUkvY9lSfEI6hTZZDtvuX58nitNSywmx5Kx9rbPytlS0ZEI0jeQCZTCgWKMuKVeUKTdYbmUqpcW/FaNHFimOQE9GR7T6lXK7JfFNWLFCVFatU5VppiZ7HSonFYj6fX5uBT3WCxSar1VqGFZlpTeI1pHEcDdFtOpDt8ObGjRuJiYnr16+HLQQmJhhEIwwfZDsEBJDt8IZCofB4PNgqIINshzdKpbKgoAC2Csgg2+ENkUik0UwtJXxdQbbDG41GI5dDywJhICDb4Q2ZTLa2Noh06RBBtsMblUolkUhgq4AMsh3eUCgUXQIKswXZDm+USmVdJ0aYHsh2CAgg2+ENkUjEP8uOoYFshzcajUaXm8dsQbbDGxKJVN/zag0fZDu8UavVZWUwlyIxBJDtEBBAtsMbMpnM4cCfqQoXZDu8UalUAoEAtgrIINshIIBshzdomCeyHQTQME9kOwQckO3whkKhODo6wlYBGWQ7vFEqlXl5ebBVQAbZDgEBZDu8QU+yyHYQQE+yyHYIOCDb4Q2aJ4tsBwE0TxbZDgIUCqU+FmE3LpDt8EapVPL5fNgqIINsh4AAsh3ekEgkFosFWwVkkO3wRq1Wf2mxRvMB2Q5vUDIKZDsIoGQUyHYQIJPJ6DdZZDu8UalU6DdZZDu8IZPJNjYGtPwXFNByKDgRFhamUCgAADKZrLy8HEvoKZfLr1y5AlsaBAxrBTQTpkuXLseOHdO9xbLvNGnSBKooaKBGFifGjBnj5ORUeYuFhcWQIUPgKYIJsh1O8Hg8X1/fylucnZ1DQ0PhKYIJsh1+jBkzRjdnzMLCIiwsjEw20yAH2Q4/eDyen58f9gzn4uJiti0ssh3ejBw50snJiUajhYaGUigU2HKgYaaVPEaxUCkqUKrVeHYhWffu8t2LFy86eAZ9eIFfckUC0DJtKLYOVBLZIBYDN9N+u/wM+YOLQlF+uasno1Skgi2n3qFaEISF5VotaNaB5R3Ahi3HLG3Hz1NcPFDQZ5wTnWF2lX3KxUKaJcknBHJeR7OL7UrFqjM7cgbNcDVDzwEAOvazl8s0KZeFcGWYne0eXhb6DDTrASAd+9ql/yOVlcEMLczOdtlvZSyO+T5CVkAAonwlxPLNy3ZarZZEBiwbKmwhkOE40kqEqLbDCwKBIC5Smt0z1GeUK9QaqI+S5mU7hIGAbIeAALIdAgLIdggIINshIIBsh4AAsh0CAsh2CAgg2yEggGyHgACyHQICyHZ6prS09O2719Uf8+FD2sBBfsl3buAlyuBAttMzk6aMvHAhofpjyGQyk8kik8xxnCmG+X7yr0Or1RII1c2CKS8vr/F0V1e3I4fP1IM6owHVdjVw4+ZVP3/v5OQbs+Z8H9i3y/4DO7GUOVu3rR8yNHBAiO+06WOSrl/GDh45KlgkEp5OiPPz9x45KhgAIJGI/fy9j8ceWhEV2X9A9zk/TL54KdHP39vP3/vR4wfYWXn5uT//siAouMfg0ICFP818/eYlAODY8YN+/t5ZWRk6JT/Mmzpt+hjs9dPURzNmju/b32fkqODVa34TCIws9TuyXa34c8vq4KAha1ZvDQkeqtFolkb+cO/erdGjJvwwd4mHR7PfVyw5fyEBALDs1zUsllWP7n6bN+1d9usa3ekxMfsceI7r1+2MmDG/XduOUybP0u0SCPizZk8sLpHMjFgwdcpspVI5Z+6kjx/f9+sbQiaTr167gB1WUJCf+uxxSMhQAMDjJw8X/jTTrWGjBfN/Hh4W/vffT+YtmKZSGdP8N9TI1oohg0f07RuMvb5x8+rfz58ePZzI5doBAAL8+8lk0pOnjgb1H9S8WQsymczhcL282lY+vUULr0nfR+jetmndXvf6UMxeto3t+rU7sMQUgQFB4WMHnz0fPytiQfduva5evTBh/DQAwNVrF5hMpn/vfgCALVvXhgSHzp61ELuCt3eXcRPCsrMz3dwa4XU/vhVku1rRvn0n3ev795NVKtWo8IG6LWq1msFg1vL0T3jw4E5hUUFQcA/dFqVSWVRYAAAIDg5d8OOMFy+etWrV5vKVc4GBA2g0Wn5+XkbGx5ycrLPn4itfRyrFb7L3t4NsVyss6Za61yKRgMPhbli3s/IBpGqT6NBo9C/tEooEXbv2mDJpVuWNmInbt+vo7Nzg6rULZAolMzP9t1/XYKUDAMaNneLbo3flUxwcnD67tuGCbFdnWCwrsVjE4zlaWFhUeUCdZryzWFYSidjV1e3zXQQCYUDQ4GPHD2q12tat22FtKJPJAgAoFPIqTzEW0CNFnWnfvpNarT6TeEK3RSaT6V7TafQ6PVe2b9/pxYtnb96+qvJq/fsNlErLEs+eGhgShm1xcXHl8RwuXDyjO0ylUimVMGcffgWotqszgQFBiWdP7dz1Z15+btMmzdPS3ibfuX4g+gS2SqyXV7trSRePHD3AYlm1bNGaw6lhMcVxY6fcv5/848KI4cPC2Wzbhw/vqjXqFcvXY3ttbNjdu/V6mvpI16QSCISIGfN/+fXHiFnjB4aEadTqS5fPBgYGhQ0dVf8fXW8g29UZCoWydvW2PXu3JCVdOnv2lIuL68CQfxMkTp0yWyjkH4rZa2PNnjFjXo22c3Zy2bo5eseuTYePRBMIhCZNmg8ZPKLyAcHBoY6OzpWzkvXo7rdq5ab9B3Zu276ewWC29mrXutKjsVFgdql3ts1PC4/0IJp3cHEnoaBhc7pnJytYAsz79iMggWyHgACyHQICyHYICCDbISCAbIeAALIdAgLIdggIINshIIBsh4AAsh0CAsh2CAgg2yEgYHa2c3CjazXmNejmcywsSVQLmF+92dlOo9YK8uSwVUAm602ZrSPMxTnMznaN2zCKsszadqUSpZUthW2PbIcj7f3Yue+lac+KYQuBxvWjeT2G1DDmub4xu9HFGCf+zHbysLTiULlOFgAYxMq+9QqBoC0WqoqF5ffPFoUvbmjNhbzqmpnaDgDw4q4k45VUqwX8HAWe5WrUarVGg/OK7TQGiUIlODWmd+5nSyTB/zczX9vB4saNG4mJievXr4ctBCZmF9shDAFkOwQEkO3whkKhODg4wFYBGWQ7vFEqlfn5+bBVQAbZDm8oFAqXC7nbDDrIdnijVCr5fCPL+ap3kO3whkKh2Nvbw1YBGWQ7vFEqlYWFhbBVQAbZDm/IZDKHw4GtAjLIdnijUqkEAgFsFZBBtkNAANkOb8hksp2dHWwVkEG2wxuVSlVUVARbBWSQ7RAQQLbDGyKRiPNgOwME2Q5vNBqN0eXz1zvIdnhDJBKxpQTMGWQ7vNFoNHK5WU9dQ7ZDwAHZDm/IZLKNjQ1sFZBBtsMblUolFothq4AMsh0CAsh2eINGFyPbQQCNLka2Q8AB2Q5v0IRFZDsIoAmLyHYIOCDb4Q16kkW2gwB6kkW2gwCRSKTT6bBVQAbZDm80Go1MJoOtAjLIdggIINvhDYVC4fF4sFVABtkOb5RKZUFBAWwVkEG2wxtU2yHbQQDVdsh2ECCTySjRGLId3qhUKpRoDNkOb1Bsh5ZDwY/x48drNBqNRiORSEpLSxs0aKDRaMrKyuLj42FLgwAZtgBzgcfjXblyhUisaF5evnwJAGjQoAFsXXBAjSxOTJw40dbW9pONffr0gSQHMsh2ONGsWbMuXbpU3tKgQYPhw4fDUwQTZDv8GDt2bOWuk4CAALNNYoxshx9Nmzbt0KED9gzXsGFDs63qkO3wZvTo0Q4ODlqttlevXuacStZAn2TVKq20RA1bhf5x5nl4t+3x8uXLQQNGlohUsOXoHwIBMG1qNpXB9du9vF/8922xmK+kWZJga0HUGVtHamGGvGkHlm9odXW5YdnuwUWhsEDZ2pdtZUuFrQXxlcil6sJM2d0zhRN+dSNTq47iDMh2d88KpKWazv3NN+IxJYqFyssHsif85l7lXkN5pBDkK8SFSuQ5k8HKltK6p23KFWGVew3GdjnlsCUg9AyLTcl+W/VkJUOxXalYzXUx90TSJoaNgwXhC/4ylA6UcoVapSLAVoHQKxogyK26ETOU2g5hViDbISCAbIeAALIdAgLIdggIINshIIBsh4AAsh0CAsh2CAgg2yEggGyHgACy3X8YNqL/ho1Rhnk1fCgtLX377nV9l4Jsh/gPk6aMvHAhob5LMR3bZWdnfr7RcMZOGwvl5XgMfDSUgU9fgUDA37J17ePHD8gUSocOnW/durZrR4y7e+MJ3w93d2vs5tb4VPwxhUIed/zix49ph2L2Pn+RCgBo3qzltGlzmzX1xC6iVqsPHtpz9ly8XC5r29ZbIZfrrp+Xn7t9+4bHTx5QqRZNmzSfOHFG82YtqpdUzdVevnqxc9emN29e0mh0n66+06f/YMWywnY9f57618HdL189BwC0adNhwvhpjdw9Avt2mTxp5qjvxmPHLF46VyIRb9964F3am7k/TP55adSefVszM9N59g6jR08UCgVnEk+Ulpa0a9dxwbxIGxs2dlbCmROxcTF8fqGDg5N/734jho+xsLB4l/Zm1uyJf0Rt3r13y/v3b3k8x6mTZ3fr1hMAMHJUsEgkPJ0QdzohjsdzOHbkLADgyNEDpxNiS0qKPTyaTRg/rX27jt/+3Rmr7dRq9ZKlc4UiwZw5i4RC/p69W9u19XZ3b4ztTUm5J1fIo1ZslMqkTCYzPz9XUa4YEz6JSCQmJMQtWjz76OFEGo0GAPhz8+rEs6f69xvYpnX7hyl3S0pLsCsIBPxZsyc6OzeYGbGAQCBcvnxuztxJO7cf0hVRJV+6Wnr6h/kLprm5NV74468SsWj/gZ2Fhfnr1+0AAKQ8ur94yZzGjZpMmzpXo9Hcu3dLraphIqNUKt20+Y+5sxdRLSy2blu3Zu1yL6+2Py+NKijMX79hxbYdG5Yu/h0AcOCv3XEnYkKHjGzYsFFWVvrx2IPZOZlLFi0HACgUit9+XzRr5o+ODk77D+xcEbX02JGz1tY2y35ds/CnmW3bdBgWNppCpQIAHj95uGfvVn//fp07+jxMuSuTSvXy9Rmr7V69evH23etff/mjV88AAEBmZvqFi2fKy8upVCoAgEQm/7w0SrfqSEBA/8DAIOx1s2Yt5s2f9vxFakfvLm/fvU48eyp89MTvJ84AAPTtG5z67DF22KGYvWwb2/Vrd5DJZABAYEBQ+NjBZ8/Hz4pY8CVJ1Vwt5vA+IpG4ZvVWFpMFAGCxrKL++OXZsydt2rTfum2dg4PTls3RmPLBg4ZhqRer//jTps7t0qU7AGD4sPDVa377Yc5id/fGrUCbx48fPHh4BwDA5xcdPhIduXRlT19/7BQOx27jplUz/69/1swfe/v1AQBMmjRz6rTwZ38/8e3Ru3mzFmQymcPhenm1xQ7Lz88FAAwZNLxly9a6e/jtGKvtCosKAABOTi7YWxcXV41GI5NJsS/P07NV5ZVuCATC7eTrsXExGRkfLS0tAQAioQAAcPt2EgAgLGy07khdIrAHD+4UFhUEBffQ7VIqlUWF1eUcruZqqc8et2vXEfMcAKBjx64AgDdvX9rzHDIz0yd9H4HJrj0WVAvsBYVCBQBQ/n+6nZ29RCIGADx+/EClUq2MilwZFYntwsJcflFFIlE6reL+8HiOmE2rLKhL5+4sllXUqp9nzfwRM7peMFbbOTs3wKKipk2aY5Ufl2tnbW2D7dXdU4yDh/buP7BzaOh3UybNEgj5vy1fpNFqAAAFhflMJtPayvrz6wtFgq5de0yZNKvyRgaDWY2kaq5WVlZqY83WvWWxrLBvWiwSAgDs7fSW3JNAqJiBKhDyAQBRKzd9cnEnJ5eP6e8rb6GQKQAAjabqHAwcDnfr5uhtOzYsXjq3Vas2v0SusrPTQ+JlY7Vds6aeHb277N6zuaAgTywR3bl7M3LpyiqPVCgUR47uHxA0eGbEfABAYaUay8aaXVpaqmuaK8NiWUkkYldXt9pLquZqXK59cbFE91YkEgIAmEwW5mOhSPDJ8QTCt04rYf3/eaVOHwHjk8d/V1e31as2P3ma8suvC9auW75m9dZv1GbcHSizZv7o4uKalZ1hY83eumU/FuR9jlwuUygUTf//6CopFmMLfwEAsI3Xki5+flb79p1evHj25u0r3ZYaFwqr5motW7ZOffZY/v8H21u3rgEAvLzaNmjQ0M7O/tLls7pgTqvVajQaEonEYlnxBUW6jYWFdVv5uF27jgQCIf708drrx6DT6ALBfxaAxLpU2rfr2KVLj3dpb+ok40sYa22nUqlmzBw3LCzc2bkBgUAoKSkuLS1lMqtoBK2tbRo18jgVf8zWllNWWvrXwd1EIvHDhzQAgF+vwEMxezdsjPr48X0Tj2b/vPxbF+KMGzvl/v3kHxdGDB8WzmbbPnx4V61Rr1i+vhpJ1VwtfNTEpKRLPy2eFRI8tLAw/6+Du9u19W7bpgOBQJgyefbKqMiImeP79g0hEomXr5wbMmh4YGBQp45dr1w+175dR1s2JzYuJjMzvUmT5rW/Py7ODUKHjDx56uiSyB+6d+slEPBPJ8SuivqzaU0X8fJqdy3p4pGjB1gsq5YtWivKFb8t/2nwoOF0uuXDh3c9PVvVXkM1GKvtyGSyd4cuh2L26uoJFpO1+c99bm6NPj/456VRq9csW/77YhcX1+nTf3j//u3Jk0enTplNoVBWr9ry55bVZxJPMBjMnr7+uujQ2cll6+boHbs2HT4STSAQmjRpPmTwiOolkUikL13NxcV1zR9bd+/dsmbtb3S6ZWBA0LSpc7GWNMC/H41GO3hwz46dG62tbZo29XR2cQUARMyYr1Ao/lj9K4PBHBgSJlfIKzfTtSFixjx7e158/PGUlHscDrdHdz87bs1h2dQps4VC/qGYvTbW7Bkz5jk5ujR0dT9yZL9Wq23TtsPsmQvrpOFLGEoOlPvnBSoVoU3PT7P7VoNarSaRSFgblJuXM2nyyOHDwieMn1afMhF1QFaqTtyZ+f3vVaRBMdbaTqFQzJg5zt7eoU3r9hQK9fnzp3K5vHHjpvVd7uy5kz5+TPt8u49Pz8U//VbfpZsMxmo7AoHQJ3BAUtKl/Qd2UqlUd3ePX3/5w7dH7/ou95fIVUqV8vPtn3TZIKrHWG1HpVJHDB8zYvgYnMvlclFOKj1gxB0oCOMF2Q4BAWQ7BASQ7RAQQLZDQADZDgEBZDsEBJDtEBBAtkNAANkOAQFD+XHMgk4koUztpgWBAOxcLKrcZSi1HdOGXJAhr8WBCKNBkKfQaqoeVmcotrNvYAGAQYz8Q+iLYmG5a3PLKncZiu2suVRHd1pyfN1mDCAMlrx06dtHknZ+7Cr3GsroYozndyQfXpR59bC15VmQyCjUM0ok/PKibPk/d0SjFrkSiVV/iYZlOwDAh+elz26JCzIVX1IMBY1WQyAQCMCAJGGo1GoyyYDWe7Z3sSiRqJq0Y3bpz6nmMIOznQ6FTANbQgUlJSXLli1bv766aWOwuHfvnkAgCA4Ohi2kAiIRUCxqjtwM13YGAp/PLy4ubtSoiglpBsI///zTsmVL2CrqhqE8UhgmN27cyMrKMmTPAQAwzy1evBi2kDqAbPdFysvLExIS2rVrB1tIrejTp8/Nmzdhq6gtqJH9IlVmMzFk8vLyHB0dYauoFai2q4KrV69GRkYal+cAAI6Ojnfu3Jk9ezZsITWDartPSU9Pz8jI6NmzJ2whX0lmZmZaWlrv3vU+ZfhbQLb7D1qtVqvV6tIhIuoJdH//5c6dO3PmzDENzx0+fHjz5s2wVXwRVNtVIBAI3rx54+PjA1uI3khNTbW0tGzatN7zwnwFyHYAS+QjFAqN5TGw9sjlcjKZjGX9NihMoUH5RgoLCwcPHmx6ngMA0Gi0wYMH5+XlwRbyKch24N69excuXICtor6Ii4s7duwYbBWfYu6NLJ/Pt7W1NY3HCCPCrG/31KlT09PTzcFz0dHRly5dgq3iX8y3tnvy5ImVlZWHhwdsITixcOHCn376icOpbhgcbpip7VC3MFzM8b6npaWNHDnSDD1369atR48ewVYBzNR2CQkJBw8ehK0CAr6+vgsXLpRI6rbQQH1gpo2s2VJSUiKRSFxcXODKMK/aLiUl5cCBA7BVwITFYtnZ2anVVS9shxtmZDuVSrV48eLx48fDFgKZV69eTZkyBa4G1MiaI3v27PH19W3WrBksAeZiu8LCwrS0NFMaYGLUmEsjO2/ePDa76sQI5smpU6fy86Gl/jAL22VnZ0+dOtXT0xO2EAOCTqdv3aqHBYm/DnNpZBGfc+XKFT8/Pyij8Uy/tsvOzl69ejVsFYZIYGAgrBGgpm+7I0eOuLm5wVZhiGRlZUVHR0Mp2vQbWbFYbGNjA1uFgRISErJr1y4nJyecyzV92yGqQSQSEYlEa2trnMs1cdvt3buXSqWOHTsWthDEfzDx2O7hw4dt2rSBrcJw0Wq1UPIfmLjtdu/ejWxXDQQCoWXLlqmpqXiXa8KNrEqlKi4utrW1hS0E8SmmXNvduXNnxYoVsFUYOmq1WqFQ4FyoKdsuPz+/YcOGsFUYOiKRaODAgTgXanBpCvTIiBEjYEtRWvQ3AAAgAElEQVQwArhcLolEEggEeE4qM+XYjs/n02g0JpMJWwjiU0y5kV2/fv3du3dhqzAC5HK5UqnEs0RTtp1KpaLRaLBVGAFnzpzZsGEDniWacmy3du1a2BKMg6ZNm7548QLPEk0wtuvfv39RUZFGoyESibq/3bp127JlC2xpiApMsJH19vbG3AYAwP7a29tPnDgRti6DJj09Hc/iTNB2Y8eOrZwjUavVtmjRwlhWNYHF5MmThUIhbsWZoO2aNGni7e2te8vlcsPDw6EqMgK8vLzEYjFuxZmg7QAAo0aN0g1dbNWqVfv27WErMnQ2bNiA59Jqpmm7Zs2adenSBQDA4XBGjx4NW44RIBaLpVIpbsWZpu0AAMOGDePxeJ6enqiqqw0HDhw4efIkbsXV0G9XlKN4miQuyJTLSiEna6k7pAEtNxKJxN2LP8BWUjfsXCxUSq1rc3rnfvj9SGpvb19WVoZbcdX126W/LLubKGjd09bGjkpnmnLHsmFBBOJ8hUSgfHpNMP5XNxLZ4FaK/3a+aLvXKcUvH5YEhjvjLglRQYmoPHFn9tQ/8Ij0ZTJZWVkZl8vFoawvxnZyqfrlA+Q5yLDY1G6D7JMTinAo6+nTp7/99hsOBWFUbbu8D3KTrNuNDq6zxbuneIRcXC7Xzs4Oh4Iwqm5kn90Uy6SgpQ+a1QyfpCO5fcJ5dBYJthB9UnVtp5BrVOUa3MUgqkCQp8BhtIZCoXj9+nW9F/N/TLbfDlEnRCLR/PnzcSsO2Q4BAAAMBgPP/H/IdgiAZXBft24dbsUh2yEANjwsJSUFt+KQ7RAAy0oxffp03IpDtkNU0LlzZ40Gp+4L9EsrooJt27bhVhaq7RAVPH36FLfaDtkOUcGcOXNkMhk+ZSHbISpo1aoVbmvsotgOUcH27dtxKwvVdogK0tLScFvw05hs9+FD2sBBfsl3bmBv1Wr18+d4Zz81YaZNm1ZSUoJPWcZkOzKZzGSyyKSKwGDt+t83bIqCLcp0aNCgAYmE0/CqeonttFotgaDPUaLYBV1d3Y4cPqPbWI576tO6ovf7UK/s378ft7L0VttN+H748t8XHzy0d3BoQFBwj9LSUgDA09RHM2aO79vfZ+So4NVrfhMI+ACAnxbPHj1msO7EmMPRd+7c1L0dNyHsjzXLJBKxn7/38dhDK6Ii+w/oPueHyRcvJfr5e/v5ez96/AAA8MeaZddvXElP/4BtzMvPxU5POHNi9JjBffv7jJsQdvDQ3tpk5U04c2Ls+KF9+/tMjxgXGxcTGtYHS1Lm5+995Oi/K7wvXjp3xsyKlbflcvnWbeuHDA0cEOI7bfqYpOuXse03bl718/dOTr4xa873gX277Nm7NWRgrx07N+kukpOb7efvfenSWX3ccj2Tn59vlL9SpKTckyvkUSs2SmVSJpP5+MnDRYtnBwYEDRk8oqRYcvLU0XkLpu3aEdOrZ8Catcs/fnzv7t4YAHDxUmKDBg27deuJRW+ZmenTp87FLhgTs2/QoGHr1+0kkUg21uwpk2ft3lORtSl81MSiwoK8vJzFi5YDADi2XADAgb92x52ICR0ysmHDRllZ6cdjD2bnZC5ZtLwazX8d3HPgr12dO3f7buQ4sVgUczi6xtXfNBrN0sgf8vNzR4+aYGNjm5r66PcVS+RyWVD/QdgBf25ZPWlixMQJ012cXaXSsmtJF6dMnoW1XzdvXrWwsOje3U9Pt1yfhIeHx8XF4bPqrj5tRyKTf14aRafTsbdbtq4NCQ6dPWsh9tbbu8u4CWEpj+5169aLvDHqzt2b7u6Nnz17kpOTlZeXU1CQz+M53Lx1lclgdujQWSotAwC0aOE16fsI3fXbtP53orWLi6u1tY1QJPDyaott4fOLDh+Jjly6sqevP7aFw7HbuGnVzIgFViyrKgVLJOLDR6K7dOm+amVFhVRYmH/z1rXqP+at20l/P3969HAil2sHAAjw7yeTSU+eOqqz3ZDBI/r2DcZe9+0bknDmRMqj+106d8Ns17VLDwaD8VU3uH7Bc5lnfdrO07OVznP5+XkZGR9zcrLOnouvfExhYYEVy6p9u4537twIHz3xwqUzbdt0EIoEFy6eGT9uyo2bV7t170WhULCD27fvVPvSHz9+oFKpVkZFroyKxLZg00T4RYVfst3zF6lKpXJg8NA6fcz795NVKtWo8H+zm6vVagbj3wzJlWV7Nm/p5tbo8uWzXTp3y83Lefvu9Zgxk+pUHG7ExcXhVpY+bUen0XWvRSIBAGDc2Cm+PXpXPsbWlgsA6NkzYO263zMz02/evLrwx1+FAn7siZge3f0qt7AAAFqlC9aIQMgHAESt3GRvx6u83cnJ5UunFBdLAABcO/val4J9NA6Hu2HdzsobSZWaZku6ZeVd/fsN3Be9vaS05ObNq0wGs3OnbnUqDjckEomVlRU+z0D19SsFk8kCACgUclfXKtZy7dat14aNUatW/0qnW/bo7ieTy/bs27phUxTWwta+lMrT3lj/r9KqLLFKOBw7AICAX9TEo9knu6q5+yyWlVgs4vEcLSwsalNKYEDQ7j1brl+/fPPmVV9ff11dbmgMHz788OHD+MzQrq9+OxcXVx7P4cLFM7pfl1UqlS4duLWVdft2HV+//ieo/yAymcxisvx69Xn58nnlFrZGaDS6UCjQPXy1a9eRQCDEnz6uO6DGH7YbN2pCJpPPnT/9+S4SicRiWfEFFVOjtVptYWE+9rp9+05qtfpM4olaFsRm23bp0v147KE3b1/5+/er5afDH2tra9x+k62vYggEQsSM+QIBP2LW+NMJcadOHYuYOT7hzL/RQ8+eAQQCIXhAKPZ24MAwAEAv34DaF9GmdfuSkuING6MuXTp79+4tF+cGoUNG3r17a0nkD+cvJByK2Rc+dvDbd9VNwuNy7QYEDU6+c2Px0rnnzp8+HnvodvJ13d5OHbteuXwu+c6Nly+f/7Z8UWZmRZrVwICg5s1b7tz15+atay9eSty6bf2E74fJ5fJqCvLv3S83N5vD4bZt06H2HxBnYmNjcVufrR6HAvTo7rdq5ab9B3Zu276ewWC29mrXutKjaPduve7fT3ZwqMj26tm8Zft2HevUwgYGBr15+/LylXP37t/u1zfEx8c3YsY8e3tefPzxlJR7HA63R3c/O24NcduM6fPIZMq1pItPn6a4u3s4OblkZ2diuyJmzFcoFH+s/pXBYA4MCZMr5FgsSKFQ1q7etmfvlqSkS2fPnnJxcR0YElZ9t0sLTy8AgF+vPrhVJ18BnrFd1VkBHl4SlstBm15mtzbhn5tX37x17dSJy/q97Pv37yZN+W7H9oPNm7Wo67lx6z+OXOBqaVXvP1v17dsXt9jO9Ac+3b+fvHJVZJW7tm7e37Che72WXlCQn3Am7vyFhHZtvb/Cc3iCZ2xn+rZr29Z7964jVe6qsQn+djKz0i9fOefv3+/7CTPqu6xvJDY2FreyUCNr6ODWyOIZ2xluhIvAmeHDhwsEAnzKQrZDVIBiOwQE8IztUG2HqEAikeC27iGyHaICFNshIIBiOwQEUGyHgACK7RAQwDO2q7qRJVOIGpNbzN1IseZS8Pku4Md2DGtS/t/4LXyG+BJKhYafo2Ba4xGCw4/tOA5UrQbVdvARF5W7e+E0zQx+bMd1tmDakJ/dwm/xeESV3D6Z37EPTgMyDKLfrudQu3KZ+vFVvkqJluOBQKlYmbAto/9ER7Y9FZ8S8YztqltPFgCQcln44q6ETCHSWcbXw6fRaAgEghFlIcGw5lDS/yl1akTv2Jdt34AGW069UIPtAAAajVbCV0qLjW71bLB169aePXt6eXnBFlI3CESCLY9CY+C9tp1hzZMlEglseyq73sfh6h8ZyGFwFc4edZjjbc6YwjxZhNEBv9/ONKDT6UYX2EEEfr+daSCTyXDriDIB4PfbmQY8Hq/GZHUIHQbRb2cCFBQUqFQq2CqMBhTb6Qcul4tqu9qDYjv9wOfzUW1Xe1Bsh4AAiu30A+pAqRMottMPqAOlTqDYTj/Y29vjtqyMCYBiO/1QWFiI29ptJgCK7RAQQLGdfnB0dET9drUHxXb6IS8vD/Xb1R4U2yEggGI7/WBnZ4eeZGsPiu30Q1FREXqSrT0otkNAAMV2+gHPVsMEQLGdfpBIJLgtB20CoNgOAQEU2+kHGo2GGtnag2I7/SCXy1EjW3tQbKcf0Hi7OoFiO/2AxtvVCRTbISCAYjv9gObJ1gkU2+kHNE+2TqDYDgEBFNvpBzQ9u06g2E4/oOnZdQLFdvoBjberEyi20w9ovF2dQLGdfkA/yNYJFNvpB/SDbJ1AsR0CAii2Q0AAxXb6wdbWFj3J1h4U2+kHoVCInmRrD/z1ZI2aDh066IbZJScnAwC0Wm2zZs2OHDkCW5pBg2dsZ4K1XdeuXT9pLBgMxoQJE+ApMg5iY2NtbXFazdEEbTd27FgrK6vKWxo1ahQYGAhPkXGAYrtvolOnTi1bttS9tbS0DA8Ph6rIOED9dt/KuHHjdBWeu7t7QEAAbEVGAIrtvpWOHTu2aNECq+rGjh0LW45xgGI7PTBx4kRbW1t3d3d/f3/YWowDPGO7mpcx/hIZL8uy3soUco2Er9S3Kv2QnZ1tbW3NYrFgC6kaSxbJzoXawR+nCqZG+vbti9t6sl/Zb3f9eKFKDVhsikMjBjDUOYGtgaF8o1UiK1WL+IqtP6R992MDjpMFbDm4xnZfU9vdTuCrlaBDIB7/FubApb+yewzm8lxpsIXgR53d/fZJiaJMgzynR/xGOF6PLdRoILcaBt1v9/ZJqWNjy/oRY6ZQaSQqjZT9TgZXhkH325XLNRxHM2oO8MHBjS7MK4erwaDH2wnzFWQKymejZ7RaglwKebAMGm+HgIBBx3YIU8WgYzuEqWLQsR3CVEGxHQICKLZDQADFdggIoNgOAQEU2yEggGI7BARQbIeAAIrtEBBAsd2/RP4yf+o0Q59uaBQiawTFdggIoNjOEDH5daRMZ56sUCjw8/e+cvUC9lYul8+bP023N+n6ZT9/79y8HABAXn7uz78sCAruMTg0YOFPM1+/eak7rExa9uuyhSGDeg0d1nf7jo0KhaL6QrOyMubNn9Z/QPfhI4M2bIzS5fRMOHNi9JjBffv7jJsQdvDQXuw65eXle/dtGzV6YECfziO+G7AversuSdSfm1eHhvW5e/dW+Nghfv7eT56mAACeP09d8OOMoOAeQcE9Fi+d+/bda125B/7aPXRY38GhAZv+/KO8HPKYza8Az3my9ftIYWvL4fEc7ty5ERjQHwBw+3bS09RHr9+8bN6sBQDg5s2rzZp6Ojk6CwT8WbMnOjs3mBmxgEAgXL58bs7cSTu3H3J3bwwAKCjI69qlR8SM+Skp9+JOHM7JzVr5+4ZqCl27/vfMzPSIGfOl0rKnqY+w/+ADf+2OOxETOmRkw4aNsrLSj8cezM7JXLJoOYlEevz4QVcfXydHl7S0NzGHo1ksq+HDKgK1srLSffu3z52zSC6XtW/XMeXR/cVL5jRu1GTa1LkajebevVvq/y9A8Pbdawsaberk2e/S3pw4ecTWljt2zKR6vbd6RyKRWFlZ4bMmZb0/yfb0DUg8e7K8vJxKpV64eAYAcPbsqebNWshksocpd8eOmQwAOBSzl21ju37tDmz1ksCAoPCxg8+ej58VsQAA0MjdI2LGPABAv74hXK59bFzMs2dP2rRp/6US8/NzmzZpHjxgCAAAMxCfX3T4SHTk0pU9fSumanM4dhs3rZoZscCKZbV921+6e52bl33rdpLOduXl5QvmRXp6tsLebt22zsHBacvmaCqVCgAYPGiYrlAnJ5eN63eRSKQ+fQZkZn68cfOK0dlu+PDhhj5Ptvb06hkQGxfz5MlD14buT1MfDQwZeuXq+RnT5z14eEcul/fsGQAAePDgTmFRQVBwD91ZSqWyqLDg86sNGTwiNi7maeqjamwXGBB05OiBzVvWjAmfxGbbAgAeP36gUqlWRkWujIrEjsECNX5RoRXLSiQSHjy0J+XR/ZKSYgAAi/nvdG4ajabzXF5+bmZm+qTvIzDPfQKTwdRlDnVza/zy1fNvuGdw8PLywm353Xq3nadnKx7P4c7dm69ev3B1dZsZseDW7aSk65cePbqPtbAAAKFI0LVrjymTZlU+kcFgfn41LtcOa/uqKXHS9xFstm3M4egLF89MmTx7yODhAiEfABC1cpO9Ha/ykU5OLkKhYMq00XS65cQJ052cXKKjt2dlZ+gOoNP/nSMnFgkBAJ9coUpIJJIxrv6zbt063MrCo7vYt4f/taSLZDJ5+LAxFAolqP+g+NPHc3OzsRYWAMBiWUkkYldXtxovJRaLAABYHfYlCARC2NBR/fsN2rgpavOWNR6Nm7JYFdmfPi/iTOJJkUi4bcsBHs8BAGBv71DZdpXB/g2EIpy6GPBHrVbjluoZjwfmXj0DhEJBcbGkb59gAEBwcOjHj+91LSwAoH37Ti9ePHvz9pXuFJms6kmjN29exY6vpjjsEZXBYIwfPw0L9tu160ggEOJPH//8+sXFYhsbNuY5AICkWPyljpIGDRra2dlfunxWV5NptVpTWvqib9++YrEYn7LwqO08PVvZ2/O8O3RhMpkAAEcHp06dfMQiIdbCAgDGjZ1y/37yjwsjhg8LZ7NtHz68q9aoVyxfj+19/+Hdtu0bGjdu8ubNy8Szp3r6+mMPwl9i2fKfmAymd4cu9x8kAwCaNfV0cW4QOmTkyVNHl0T+0L1bL4GAfzohdlXUn02bNG/b1jv+dGz0/h0tW7a5fTvpwYM7Go1GIhFbW9t8clkCgTBl8uyVUZERM8f37RtCJBIvXzk3ZNDwwMCg+rpxpgsetiMQCL49/P39++m2DAoJS8/4oHvr7OSydXP0jl2bDh+JJhAITZo0HzJ4hG7vdyPHvXjx7Oy5UwwGc1jY6Anjp31Wwn/wbN7q0uWzt24ncbn28+ctbdWqDQAgYsY8e3tefPzxlJR7HA63R3c/O649AMC3R++xYybFn449fTq2q4/vtq0HVv3xS/zp4+PHTf38ygH+/Wg02sGDe3bs3GhtbdO0qaezi6uebhJ8zp8/X+XTUn1Q59Q7eyM/DI5oaGGJ1nvQJ3/fEpFImi5BHNhCcMJYR6DMnjvp48e0z7f7+PRc/NNvMBQZPaGhoQcOHPgk23g9Yay2+yVylVJVRTpHOo0OQ44pIBKJcCvLWG2HdeAh9EhsbCxumU+N1XYIvWNnh99/Mhr4hKggLCysxtE9+gLZDlFBdna2iYy3QxgRJ06coFAo+JSFbIeowMXFBbeykO0QAACgUqmGDRtWiwP1A7IdAmADWvPz83ErDtkOAbABrceOHcOtOGQ7BAAAEIlEZ2dn/Iqr6wkUKkmL19Bn84FABEQizLual5f3/fff41ZcnW1HpRGkEgNd2854KRUpLa1gDuopLS0tKyvDrbg6287BjVYsML5JoAaOtETJdcJprFuVNGrUKDo6Grfi6mw770D2o8smO58ACllvykgkgoMbzLEzJBLJ0hK/Nb3qbDsWm9J/gsP5vVlqtYknZ8CHjJelL++Lgic5wpVx7dq1hQsX4lbc14xAcWhI6xrMuXY4R60Ezh6WcpnpTGPBE3mZqkSotLIlh83G7+eBL6FUKjkc/MY2f/3q2VqNNj9DLipUlssN1Hbx8fFt2rRp1KgRbCFVw7Qic5yobB7MkA4WXz/ejkAkOLrTHd0NdzTvgfhndh4ebXt8OgcMAR3UXYwAAIBVq1adOHECt+KQ7RAAm0jBZrNxK86UB7XT6XTccskYOytXrsTSbeGDKduOTCYj29US3AZ4YphyI1tWVmaMmZeg0LNnTzzvlSnbjsFg6DLCIqpBJBLR6XQ8G1lTth2JRMLz523jhc1mX7x4Ec8STdl2TCaztLS6BIwIjPLy8pKSEjxLNGXbOTo6oka2Nhw6dOjQoUN4lmjKtmMymR8+fKjFgeZOYWFhs2bN8CzRlDtQHBwc7ty5A1uFEbB48WKcSzTl2s7Z2fnNmzewVRgBX0rZW3+Ysu1cXFzy8/NR1131vHnzBs9ZFBimbDsAQK9evTIzM2GrMGjS0tK8vb1xLtSUYzsAgJWVVWpqqsEOuTMEBgwYMGDAAJwLNfHarm3btqmpqbBVGDTZ2dn4xyGmbzu5XA5bheGSnZ0dERGB589iGCZuO2dn54yMjLS0KpJrIwAAGRkZY8aMwb/cr59LYSzs3LmTRCJNnjwZthDEv5h4bQcACAgISE9Ph63CEFGr1ZcuXYJStOnbzsPDIy8v79mzZ7CFGBzx8fFPnjyBUrTp2w4AMGzYsLi4ONgqDA65XD5+/HgoRZuF7fr37y+RSHAe22P4hIeHOzrCyUZgFrYDAPTu3fvPP/+ErcKAuHjx4vPn0Jb4NhfbDRky5NGjR1lZWbCFGAQikWjdunVeXl6wBJh+B4qOu3fvJicn45lgxmApKioik8l4Toz9BHOp7QAAPj4+IpHo8uXLsIVARqvVUqlUiJ4zr9oOAKDRaDp37pySkgJbCEwiIyO7devWv39/iBrMqLbDEkOvXr36jz/+gC0EGhkZGSwWC67nzK62w4iKimrWrNnQoUNhCzFfzKu2w1iyZElcXFx2djZsIXjz+PHj27dvw1YBzLS2AwBIJJIhQ4YkJSXBFoIf2BinhIQE2EKA+doOAPDo0aM9e/bs2rULthCckMvlVCoVt6U7q8d8bQcAOH36tEAgwH8CC/68fv2aTqc3bNgQtpAKDML7sBg8eHBxcXFMTAxsIfXL+fPnDx8+bDieM/faDmP58uXdu3fv3bs3bCH1glQqffXqVYcOHWAL+Q/IdgAAMHXq1MmTJ+M/bw8HXr165enpCVvFp5h1I6tj165dGzZsML0UAn369LG3t4etogpQbfcvYWFhGzZscHV1hS1EP6Slpbm4uNBoNNhCqgDZ7j9MnTp1ypQphhYJfQXv3793dHTEcxmxOoEa2f+wa9euVatW6fJXDB48ODg4GLaomlmwYEHXrl11b8ePHy+VSg3Wc8h2VXDixIlt27a9f/8+ODg4OztbIBDExsbCFlUdRUVF79+/VyqVvXr1woZw7tmzB+IQztqAbFcFq1ev/u677/Lz8wEACoXixo0bsBVVx/379wUCAbYUcdeuXdlsNs7Z/r8CZLsqCAoK0mgq1u8jEonZ2dkZGRmwRX2RmzdvSqVS7LVSqfT394etqGaQ7T4lKCiosLCw8hY+n3///n14iqojNzf3/fv3lbdIJBLD7/pGtvsUNpvN4/GwocjYFoVCcfPmTdi6qubBgwcFBQW6t1qtlkQiWVhYQBVVMyae3+4rOHz48MuXL5OTk2/cuCEUCouKirBRQx8+fDDAPHk3btwoLy/XarU0Gs3a2rpNmzZ9+vTx8/ODrasGDLTfTqPWfvynTFyklJbAzPAvEolycnKys7NLS0ubN2/eqlUriGKq5PTp01hycFdXVx6PRyKRYCmhWRItrUj2DSzsnGvuoDZE2xVkyi8fLLC2p/Jc6QAtVWckUC2IhVlyjUZjbUv2CeFWf7DB2a4wS5GcwPcb6UimoLjTKHl4oYhpQ+rcz7aaYwzuq43dkBU4xhl5znjp1N9OmF/+6mFxNccY1rf77JbIs4s1bBWIb6WFD/vZLXE1BxiW7QR5So6jIY6YQNQJW55FsUCp1XwxfjMs20klKguaYUlCfB1kClFWqvnSXvQdIyCAbIeAALIdAgLIdggIINshIIBsh4AAsh0CAsh2CAgg2yEggGyHgACyHQICyHYICCDb6R+1Wv38OVopvjqQ7fTP2vW/b9gUBVuFQWNSttNqtTm59Z5/vcZpAOUKRX1rgIIe5z8Y/YTFl69ebNu+/sOHdxxbrpt747S0NwcPnKJSqXK5fO++bdeSLpaXKxq4NBw+fExvvz4AgBMnjyRdvzwsbPS+fdsEQn6TJs0XzIt0dXXDrvY09dGevVvfv3/LZtu2a9tx0vcRHA4XADDh++Hubo3d3Bqfij+mUMjjjl/8+DHtUMze5y9SAQDNm7WcNm1us6aeAIA/1iy7fuMKAMDP3xsAcOTwGUcHJwBAwpkTsXExfH6hg4OTf+9+I4aPqX4264WLZ06fjv3wMY1Ot+zUsevMiAU2Nuzq9d+/n7x775bc3GwHB6eBIWEhwaGhQwN79gxYMD8Su+bipXMXLVxmbW0DABAI+MNG9F/44y/9+oZ86V79uXn1zVvXFsyL3L5zY05O1vZtf3k2b6mXb824bVdQkL/gx+lNmjRfunjFg4d3zp6LnzxpJpVK1Wg0SyN/yM/PHT1qgo2NbWrqo99XLJHLZUH9BwEAXr16ERt7aP78SJVKtWHDylWrf92x7S8AwOMnDxctnh0YEDRk8IiSYsnJU0fnLZi2a0cMliIuJeWeXCGPWrFRKpMymcz8/FxFuWJM+CQikZiQELdo8eyjhxNpNFr4qIlFhQV5eTmLFy0HAHBsuQCAA3/tjjsREzpkZMOGjbKy0o/HHszOyVyyaHk1H+3ly+eurm6BgUEikfBU/LEyadmqlZuwXVXql0qly5b/5Naw0fx5kR8/pgkERRQKxadbz7v3bmk0GiKRWFCQ/+DBnYuXEkcMHwMAuHnrGolE8vHpWf29Kisr3bd/+9w5i+RyWfNmLfT1xRm37a5cPS+TyX79+Q9bW063bj2f/f3k/oPkUd+Nv3U76e/nT48eTuRy7QAAAf79ZDLpyVNHsVsJAFi5YqOtLQcAEBo6cvuOjZJiibWV9Zata0OCQ2fPqliC0du7y7gJYSmP7vXo7gcAIJHJPy+NotPp2N6AgP6BgUHY62bNWsybP+35i9SO3l1cXFytrW2EIoGXV1tsL59fdPhIdOTSlT19K7KTcDh2GzetmhmxwIpl9aWPNu+HJQRCxWxNMpkcczhaoVDoKsjP9ZeWligUih49egcG/LuwU+5/zIEAAA70SURBVC/fgMuXz718+bxVqzYXLyVqtdqz5+L/b7ur7dt3smJZ3bh5tZp7VV5evmBepKennicIG7ftiooKGAwG9gUQCAQnJ5eCgjysuVGpVKPCB+qOVKvVDAZT95ZGq3APj+cIABDwi2RSaUbGx5ycrLPn4isXUVhYkerB07OVznNYcbeTr8fGxWRkfMQyyYmEgipFPn78QKVSrYyKXBlV0dhhQRK/qLAa2ymVylPxx65cPV9YmG9hQdNoNGKxiMdz+JJ+d/fGLVu2jjm8j0ajhwSHUqlU7D+HyWQm37nRsmXrS5cSBwQNvnDxTGrq4wYNGj5/nrrwx19qvFc0Gk3vnjN62zk7NygrK/vwIa1RIw+lUpmW9qZtW28AgEgk4HC4G9btrHwwiVzFh6WQKQAAtUYtEgkAAOPGTvHt8Z+8Nba2FTON6TR65e0HD+3df2Dn0NDvpkyaJRDyf1u+SKOteuqAQMgHAESt3GRvx6u83cnJ5UufS6vVLlk6983bl+PGTmnRovXt20nHjh+s8vo6/QQC4Y+ozXv3bd25a1PciZjFPy1v06Y9hULp2tX3zt2bnTr5FBYVjBs7RSIRnzsf36JFa6yFrfFe0en1kpvRuG3Xt09w3InDSyLn9gkckPrssUqlGj92CgCAxbISi0U8nmPtk9AwmSwAgEIh1z1eVINCoThydP+AoMEzI+ZXrhF1VH7oY/2/SqvNlTGePXvy+MnDpUtWBPj3AwDkZGfW7iMw585ZNHz4mJ9/mR/587zjx85bWlr28g24cuX8nr1bfbr62tnZh4QMjfx5XkbGR6yF/bp79e0YdweKtbXNzIgFFha0jx/fe3fosmfXERcXVwBA+/ad1Gr1mcQTuiNlMln1l3JxceXxHC5cPKM7UqVSKZXKKg+Wy2UKhaJp04rE+5JiceUMUTQaXSgU6N62a9eRQCDEnz5eezHYBZs2aV7l9b+EQqEAADg5OocOGVlaVpqfn4u1swwG4/Xrf0JChgIAOnp3sbfjvUt749crEDvrK+7Vt2Pctd2r1/+sWfvb7JkLyRQKkUjMy8uxteWQSKTAgKDEs6d27vozLz+3aZPmaWlvk+9cPxB9opq05QQCIWLG/F9+/TFi1viBIWEatfrS5bOBgUFhQ0d9frC1tU2jRh6n4o/Z2nLKSkv/OribSCR++JCG7W3Tuv2Fi2c2bIzyatWWxbLy8fENHTLy5KmjSyJ/6N6tl0DAP50QuyrqT52rPqeFpxeVSt2zd+uAAUM+fHh35Oh+AMDHD2nOX26XlUrluAlDe/UMdHdrnJAQx2QwsUacSqV27er78uVz7w6dsY8ZHBy6L3o71sICAL7iXn07xm07B56jo6Pz6rW/6Rq1Jh7NNv+5j0ajrV29bc/eLUlJl86ePeXi4jowJIxcVWxXmR7d/Vat3LT/wM5t29czGMzWXu1at27/pYN/Xhq1es2y5b8vdnFxnT79h/fv3548eXTqlNkUCiUwMOjN25eXr5y7d/92v74hPj6+ETPm2dvz4uOPp6Tc43C4Pbr72XGrWy7Czs4+cunKbdvXL/ttYcsWrTes37X/wM5T8ce6d+/1pVNkclm7th2vXrtQVlbq7u4RtXKTzje9fAM8GjfVPRf37zfwn3/+1j3NUCiUr7hX34hhpd45uzu3cVtrl2aM2p+iVqux7Fpqtfp28vXfli9av25H+3Yd61Mmombi1n8cucDV0qrqxGfGXdtlZqbP+WFy1y49PBo3VZQrbt26RqPRXJyNYz2T+/eTV66KrHLX1s37GzZ0x10Rfhi37RgMpn/vfvfv375y9TyTyfJq1Xbu3MX29rxanAqftm29d+86UuWu6ptgE8C4bcfhcGdGzMd6MYwOGo2G/Vxrhhh3BwrCSEG2Q0AA2Q4BAWQ7BASQ7RAQQLZDQADZDgEBZDsEBJDtEBBAtkNAwLBsx7AhlytrGMyIMAqIZIIF/YvuMizb2dhT+dly2CoQ34qoQEG1IJIoX1yn0LBs5+Vj9e5JdWtVIYyC1ylirx7VLeJlWLYjU4kDpzpdjcmBLQTx9Ty5yqczSV4+1dnOsEYXY+S8l10+VODgRue50olktKCscUAiE4qy5SqlmmpB7BVmV/3Bhmg7AIBarX37uERUqCwTq2Br0TNiiVggEDRu1Bi2ED1jaUW2tCLyXGlOjeg1HmygtjNhbty4kZiYuH79ethCYGJYsR3CTEC2Q0AA2Q5vKBQKl8uFrQIyyHZ4o1Qq+Xw+bBWQQbbDGwKBUN9z7g0fZDu80Wq1KpWp9QrVFWQ7vCGRSFgaRnMG2Q5v1Gq1VCqFrQIyyHZ4Q6FQHBwcYKuADLId3iiVyvz8fNgqIINsh4AAsh3eEAgELI26OYNshzdarba8vBy2Csgg2+ENmUy2sbGBrQIyyHZ4o1KpxGIxbBWQQbZDQADZDm8oFIq9vYnniK0RZDu8USqVhYWFsFVABtkOAQFkO7xBP44h20EA/TiGbIeAA7Id3qBGFtkOAqiRRbZDwAHZDm/QhEVkOwigCYvIdgg4INvhDZoni2wHATRPFtkOAmgECrIdBNAIFGQ7BByQ7fCGSCTSaDTYKiCDbIc3Go1GLjf3tTeQ7fAGPVIg20EAPVIg20GATCbzeDzYKiCDbIc3KpWqoKAAtgrIINvhDYlEYjKZsFVABi2HghOhoaEajUar1crlcrlczmaztVqtVCq9cuUKbGkQMPffpHHD19f30KFDBELFEmplZWUAgCZNmsDWBQfUyOLEmDFjnJycKm+xsLAYNmwYPEUwQbbDCQ6HExAQUHmLs7NzaGgoPEUwQbbDjzFjxri6umKvLSwsRowYAVsRNJDt8MPW1lZX4Tk5OQ0dOhS2Imgg2+FKWFiYq6urhYXFyJEjYWuBCXqSrYGyYpWsRC0tUStkGrXq2zub6AGdxz179qyla5/XKSXfeC0CAVAsCJYssqUVicUm6x6TDR/Ub1c1uR9kH1+UpT0rI1OJynIt1YJkybZQSA1rMDqZQiiXqZUKtVKmJlsQ7JwtPNowGnkxyBRDb8SQ7T4l41XZ7QS+Vkuksy1ZXEsLhnFkVddotCWFZVKRlKBVN2pl2amvLWxF1YFs9y8KmfrM7nyFHHDdbWks43BblfA/CovSi/2G2zX3toKtpWqQ7SrIeS9L3J3XoA2PwTaFob9qlUacLebYg15D7WBrqQJkOwAAyE6TXo8TNGjrVItjjQlxtoSokQ+canCfC9kOvH1SknKt2LmVaSb/EmVLSKB84GTD+nSG/shT3xTlKO6dE5mq5wAAbBdrDZF640QRbCH/waxtp1JpLh8qbOjtDFtI/WLjZC0SgFcPJbCF/ItZ2+5GbJEl1yxGXNq4sJOOG1CFZ762k/CVGa9lbGcD7WLQLwQigefBvptoKAnOzNd2j66J7D04sFXgB9fNJv21XCFTwxYCzNd2GrX29YNilp0lbCFVwBdkLfi589O/L+v9ykQKOe1Zqd4v+xWYqe0+/lPGdjREz9UrlmzLtGdlsFUA87VdxiupJcfsbGdlzyjKVmg18HtqzXTgU366gt2wvp5h7z48efPOEUlxoS3bqV3rPr26hVMoFjm5b7bunfz9mI3nL2/PzX/LtnEc0GdmK09f7JTSMlHC+Y3/vL5FIVs0du9QT8IAAEQSUVhQznG0qL8iaiUDbvGwkJaqyBak+rjy5aQ95y5tbesVOHxwZOuW/jdux5xIWIXtUioVMceX+vqMnD5xB9vG4Ujcz2VlYgCAUlW+68Csf17d9PUZNaDvTKEotz6EYVAsSNIS+E8VZlrbyUvV9WE7SXHRtVsHRof93rpVb2yLNYt7MnH1oKB52NvBA+a39QoEAAQFzti0Y9z79KetW/rduR+Xl/9uyrgtTT06AQDcGnit2Vxf0yxIVFJZMfxRg+Zou3KFhsWh1sdY3HfvH6rVqsMnfjl84pf/b9MCACQlFbl2qBQ69oJt4wgAKC4pAgC8eHXTkeeBeQ4AQCTWSzWMQaKSNXoYI/2tmKPtqBZEeYlKrVSTKHr+gotL+ACA78M32Fj/J5UYx9Ylv+B95S1kEgUAoNGoAQBiSb6zYzP9KvkSSpmSxqDjU1Y1mKPtAAA0Jkmp0L/t6PSK3zzs7dxqfxaTwS4tE+lXyZdQK9QMK/hfupk+UvAa0tRK/UfWTRp5EwiE5Aexui2KclmNZzk7NsvKeVlYlKF3PZ9DY5IsreqxEa8lZmo7OxdqSaFU75flchp07zLi5evb0THzHzw+c/VG9B8bh2bnvq7+LL8eYwkE4vboaUm3/nr09Nyps2v1LgxDXlKuKFOx2JR6un7tgV/fQqGxFyP1ei4A+v9NdmD/uTbW9sn3496k3bdicVu16GVtVUPKWC7HZfLYP89e2nwpaY+NNc/Ls9fbtAd6FwYAKCmSNm5tEJ3k5ju6+MTmHJYzx8IS/r8+buS/Kug11NahIfzJImZa2wEAWnVlPU0WOTb/YlV0IuGP1BdVJJ+zseKJi6tIx8mgWy+ed0qPCs9f2X734cnPt1PIFkqVospTfvnxHJVatatKBTISSWsInjPr2g4AcHBlhn1Texqz6rmJZWViRXkV8Z9KpSSTq6gjCQQi20afg+PLpBKFoopf7r8kAOsO/FJ/ZPqjnKBx9vauyHawyXhV9uBqqb2H6S8qXFwotaTKAr4zlIUJzPRJFqOhJ4PnTBJmimELqV9UCnXBG77heM7cbQcA6BnKBUp5cYFBDH6sJz48zBm9uAFsFf/BrBtZHeeiC5Ramo2TqU3n0Wi06Q9zRi5wtmQZ1rOjudd2GAMm8shaqSBdCFuIPpEVK14lpYfOdDQ0z6Ha7j88vCh89ajEtqEti2sQfapfjUqhFqQLGUxt8CRH2FqqBtnuPwjyFMmnBcVijZUDi2VnSSQZWWsgFcvlxTJBZkn3QRzPToY7FxPZrgpy3ktTbxZnvCxjcSzobEsiiUixIFFoZGBg6TK1AGjKVUqFWqVQq5UqcW6pNZfS0sfKy8catrQaQLarjqy30oIMuahQWSZRUyyI4qJy2Ir+A41B0mgAw4rEsiFznaluLRh0JvzRJbUB2Q4BASOLXRCmAbIdAgLIdggIINshIIBsh4AAsh0CAv8D7luKhWQ8BP8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the Agentic CRAG System"
      ],
      "metadata": {
        "id": "pXW3yX7s9MMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"what is the capital of India?\"\n",
        "response = agentic_rag.invoke({\"question\": query})"
      ],
      "metadata": {
        "id": "tgny4kCM0OrS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee870d79-b2b1-4d2b-f03b-59a8145121f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---RETRIEVAL FROM VECTOR DB---\n",
            "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
            "---GRADE: DOCUMENT RELEVANT---\n",
            "---GRADE: DOCUMENT RELEVANT---\n",
            "---GRADE: DOCUMENT RELEVANT---\n",
            "---ASSESS GRADED DOCUMENTS---\n",
            "---DECISION: GENERATE RESPONSE---\n",
            "---GENERATE ANSWER---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGKmZCW2T4-a",
        "outputId": "38cced49-dac3-41ee-d7c7-199975587d1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'what is the capital of India?',\n",
              " 'generation': 'The capital of India is New Delhi.',\n",
              " 'web_search_needed': 'No',\n",
              " 'documents': [Document(id='a1363031-c896-47e5-9bad-6a3726443180', metadata={'article_id': '5117', 'title': 'New Delhi'}, page_content='New Delhi () is the capital of India and a union territory of the megacity of Delhi. It has a very old history and is home to several monuments where the city is expensive to live in. In traditional Indian geography it falls under the North Indian zone. The city has an area of about 42.7\\xa0km. New Delhi has a population of about 9.4 Million people.'),\n",
              "  Document(id='85a45b0b-01b8-43b4-a018-ba22c665347e', metadata={'article_id': '1968', 'title': 'Capital city'}, page_content=\"A capital city (or capital town or just capital) is a city or town, specified by law or constitution, by the government of a country, or part of a country, such as a state, province or county. It usually serves as the location of the government's central meeting place and offices. Most of the country's leaders and officials work in the capital city. Capitals are usually among the largest cities in their regions; often they are the biggest. For example, Montevideo is Uruguay's capital as well as its biggest city. The capital city may also be the most important center of commerce, as in London or Bangkok. However, a capital is not always the largest city in a country. For example, the capital of the India is New Delhi, which is smaller than Mumbai; and the capital of Pakistan is Islamabad, which is smaller than Karachi. Also, in countries with subdivisions like the United States, the capital cities or towns of the federated states are often not the largest or most populated town. For example, New York City is the biggest city in the United States and in New York but is not the capital of either.\"),\n",
              "  Document(id='4e829e82-9a03-4a86-8fbd-5ba6cf7938ee', metadata={'article_id': '22106', 'title': 'Delhi'}, page_content='Delhi (; \"Dillī\"; \"Dillī\"; \"Dēhlī\"), officially the National Capital Territory of Delhi (NCT), is a territory in India. It includes the country\\'s capital New Delhi. It covers an area of . It is bigger than the Faroe Islands but smaller than Guadeloupe. Delhi is a part of the National Capital Region, which has 12.5 million residents. The governance of Delhi is like that of a state in India. It has its own legislature, high court and a council of executive ministers. Delhi is on the banks of the Yamuna River. Historians have evidence that people have been living in this region since at least the 6th century BC. People also believe that the legendary city of Indraprastha was here. This city has many remains and monuments of historic importance. The India Gate is a war memorial in Delhi. On the India gate there are names of some of the people who fought for India during 1914 until 1921.')]}"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(response['generation']))"
      ],
      "metadata": {
        "id": "9Y7Q-KAF2oqA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "outputId": "d777a1cb-14b3-41ae-e93f-5d3e7d87ea1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The capital of India is New Delhi."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Explain to me what are the key design patterns to build Agentic AI Systems?\"\n",
        "response = agentic_rag.invoke({\"question\": query})"
      ],
      "metadata": {
        "id": "aAm5ERMM2fFL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9415314-a0c7-4bd0-fd2e-ab3cd479622a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.vectorstores.base:No relevant docs were retrieved using the relevance score threshold 0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---RETRIEVAL FROM VECTOR DB---\n",
            "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
            "---NO DOCUMENTS RETRIEVED---\n",
            "---ASSESS GRADED DOCUMENTS---\n",
            "---DECISION: SOME or ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, REWRITE QUERY---\n",
            "---REWRITE QUERY---\n",
            "---WEB SEARCH---\n",
            "---GENERATE ANSWER---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k87Z7BWYUG-q",
        "outputId": "83af1f37-ca40-4715-ec80-6f9df134b3ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'Key design patterns for building agentic AI systems',\n",
              " 'generation': 'The key design patterns for building agentic AI systems are:\\n\\n1.  **Reflection Pattern**: This pattern enables AI agents to evaluate and refine their outputs through self-critique and iterative improvement. The agent reviews its work, identifies flaws, and iterates to produce better results. This is useful in code generation, content creation, and problem-solving tasks.\\n2.  **Tool Use Pattern**: This pattern empowers agents to interact with external resources like APIs, databases, or programming environments, allowing them to perform actions beyond their internal knowledge base. It is beneficial for tasks such as web search, data analysis, and automation.\\n3.  **Planning Pattern**: This pattern allows agents to break down complex tasks into manageable steps, plan their execution, and adapt dynamically based on new information. It is particularly useful for project management, research, and workflow automation.\\n4.  **Multi-Agent Pattern**: This pattern involves multiple specialized agents working together to achieve a common goal. Each agent has a specific role, and they communicate to ensure seamless task execution. It is applicable in software development, data analysis, and content creation.',\n",
              " 'web_search_needed': 'Yes',\n",
              " 'documents': [Document(metadata={}, page_content='Agentic AI Design Patterns\\nAgree & Join LinkedIn\\nBy clicking Continue to join or sign in, you agree to LinkedIn’s User Agreement, Privacy Policy, and Cookie Policy.\\n\\nSign in to view more content\\nCreate your free account or sign in to continue your search\\nSign in\\nWelcome back\\nEmail or phone\\nPassword\\nShow\\nForgot password?  Sign in\\nor\\nBy clicking Continue to join or sign in, you agree to LinkedIn’s User Agreement, Privacy Policy, and Cookie Policy.\\nNew to LinkedIn? Join now\\nor\\nNew to LinkedIn? Join now\\nBy clicking Continue to join or sign in, you agree to LinkedIn’s User Agreement, Privacy Policy, and Cookie Policy.\\nLinkedIn\\nLinkedIn is better on the app\\nDon’t have the app? Get it in the Microsoft Store.\\nOpen the app\\n    [Skip to main content](https://www.linkedin.com/pulse/agentic-ai-design-patterns-satyam-mittal-wamrc#main-content)\\n\\nLinkedIn\\n\\nArticles\\nPeople\\nLearning\\nJobs\\nGames\\nGet the app\\n\\nJoin now Sign in \\n\\nAgentic AI Design Patterns\\n\\nReport this article\\n\\nSatyam Mittal \\nSatyam Mittal\\nAI-ML Software Engineer | GenAI & MLOps | Google Dev Student Club\\nPublished Feb 9, 2025\\n+ Follow\\nThe evolution of large language models(LLMs) has opened doors to building autonomous AI systems capable of reasoning, decision-making and collaboration. Tradition AI workflows often rely on zero-shot prompting, where a model generates output in one go. However, this approach has limitations in handling complex tasks requiring iteration, planning and refinement. This is where Agentic Design Pateern come into play.\\nAgentic Design Patterns allow LLMs to operate more autonomously by introducing iterative workflows, enabling self-evalution, planning, tool integration, and collaboration among multiple agents. These patterns enhance the model\\'s efficiency and reliability, mirroring human problem-solving processes.\\nWhat is Agentic AI?\\nAgentic AI is a methodology that enables LLMs to act as autonomous agents, making decisions, breaking down tasks, and improving their outputs iteratively. Instead of treating the LLM as a static entity, the agentic approach transforms it into a dynamic problem solver.\\n\\nFor instance, imagine writing a code snippet using a traditional LLM:\\n\\n\\nYou provide a prompt.\\nThe model generates a response.\\nIf there’s an issue, you manually revise the prompt or output.\\n\\n\\nIn an agentic workflow:\\n\\n\\nThe LLM outlines a plan for the task.\\nIt researches libraries, algorithms, or solutions autonomously.\\nIt drafts the code, critiques its own output, and revises iteratively.\\nThe process repeats until the solution meets quality standards.\\n\\nThis step-by-step refinement mirrors human workflows, making agentic AI more effective in handling complex challenges.\\nAgentic Design Patterns\\nAgentic AI systems employ specific design patterns to structure workflows. These patterns define how agents operate, interact, and improve their performance.\\n\\nCredit: Author\\n\\nThe four key patterns are:\\n\\n1. Reflection Pattern\\nKey Concept: Self-evaluation and iterative improvement.\\nThe Reflection Pattern enables AI agents to review and refine their outputs. Instead of providing a one-time response, the agent critiques its work, identifies flaws, and iterates to produce a better result.\\nHow It Works:\\n\\nStep 1: The user provides a query.\\nStep 2: The LLM generates an initial output.\\nStep 3: The LLM reflects on its output, critiquing its correctness, coherence, and relevance.\\nStep 4: Based on self-critique, the LLM refines its response.\\nStep 5: The process repeats until the output is polished.\\n\\n Image1 src: Self-Refine: Iterative Refinement with Self-Feedback(\\nApplications:\\n\\nCode Generation: Writing and debugging code iteratively.\\nContent Creation: Refining articles, essays, or summaries.\\nProblem Solving: Improving accuracy in mathematical or logical tasks.\\n\\n2. Tool Use Pattern\\nKey Concept: Expanding capabilities by integrating external tools.\\nThe Tool Use Pattern empowers agents to interact with external resources, such as APIs, databases, or programming environments. This allows the agent to perform actions beyond its internal knowledge base.\\nHow It Works:\\n\\nStep 1: The user submits a query.\\nStep 2: The LLM identifies the tools required to complete the task.\\nStep 3: The agent calls the tools (e.g., web search, database queries, Python execution).\\nStep 4: Results from the tools are integrated into the response.\\n\\n Image2 src: Efficient Tool Use with Chain-of-Abstraction Reasoning(\\nImage 2: is am illustration of gold data re-writing for finetuning data construction. Given a pair of domain question (green scroll) and gold answer (yellow scroll), an LLMis prompted to re-write the gold answer as a reasoning chain with abstract variables (purple bubble). Then, domain specialized tools validate the correctness of the re-writing by checking whether the abstract chain can be reified to get the final answer (orange label).\\n Image3 src:\\nApplications:\\n\\nWeb Search: Fetching real-time information.\\nData Analysis: Running statistical computations or database queries.\\nAutomation: Sending emails, managing calendars, or executing scripts.\\n\\n3. Planning Pattern\\nKey Concept: Breaking down complex tasks into manageable steps.\\nThe Planning Pattern allows agents to decompose tasks into sub-tasks, plan their execution, and adapt dynamically based on new information. This pattern is particularly useful for workflows requiring multiple steps.\\nHow It Works:\\n\\nStep 1: The LLM receives a complex query.\\nStep 2: It generates a roadmap, outlining sub-tasks.\\nStep 3: Tasks are executed sequentially or concurrently.\\nStep 4: The agent evaluates progress and adjusts the plan as needed.\\n\\n Image4 src: HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face(\\nImage 4: In this image, Language serves as an interface for LLMs (e.g., ChatGPT) to connect numerous AI models (e.g., those in Hugging Face) for solving complicated AI tasks. In this concept, an LLM acts as a controller, managing and organizing the cooperation of expert models. The LLM first plans a list of tasks based on the user request and then assigns expert models to each task. After the experts execute the tasks, the LLM collects the results and responds to the user.\\nThe following image represents TaxonomyonLLM-Agent planning.\\n Image5 src: Understanding the planning of LLM agents:A survey(\\nApplications:\\n\\nProject Management: Structuring multi-phase projects.\\nResearch: Synthesizing information from multiple sources.\\nWorkflow Automation: Handling sequential operations with dependencies.\\n\\n4. Multi-Agent Pattern\\nKey Concept: Collaboration among specialized agents.\\nThe Multi-Agent Pattern involves multiple agents working together to achieve a common goal. Each agent has a specific role, and they communicate to ensure seamless task execution.\\nHow It Works:\\n\\nStep 1: A central agent delegates tasks to specialized agents.\\nStep 2: Each agent completes its task and shares results.\\nStep 3: Results are aggregated and refined collaboratively.\\n\\n Image6 src: ChatDev: Communicative Agents for Software Development(\\nIn Image6: Upon receiving a preliminary task requirement (e.g., “develop a Gomoku game”), these software agents engage in multi-turn communication and perform instruction-following along a chain-structured workflow, collaborating to execute a series of subtasks autonomously to craft a comprehensive solution\\nApplications:\\n\\nSoftware Development: Separate agents handle coding, testing, and deployment.\\nData Analysis: Different agents process, visualize, and interpret data.\\nContent Creation: Collaborative editing and fact-checking.\\n\\nAdvantages of Agentic AI\\n\\nAutonomy: Reduces reliance on human intervention.\\nEfficiency: Handles complex tasks iteratively and collaboratively.\\nScalability: Multi-agent frameworks distribute workloads effectively.\\nAccuracy: Self-reflection and tool integration enhance output quality.\\n\\nConclusion\\nAgentic AI represents a paradigm shift in leveraging LLMs for autonomous, intelligent systems. By adopting design patterns like Reflection, Tool Use, Planning, and Multi-Agent Collaboration, developers can unlock unprecedented capabilities in AI systems.\\nA detailed post on What is Agent?\\n\\nReference\\n\\n\\nAndrew Ng, DeepLearning.ai: Letters on Agentic AI\\n5 Agenitc AI Design Patterns [Link]\\n\\n\\n\\nThank you for reading! 😊 ✍️ Connect with me: Satyam\\'s LinkedIn , Satyam\\'s Github\\nVisit my blogs where I share my work implementations: Satyam\\'s Blogs\\nLike\\n Like\\n Celebrate\\n Support\\n Love\\n Insightful\\n Funny\\nComment\\n\\nCopy\\nLinkedIn\\nFacebook\\nTwitter\\n\\nShare\\n  35 4 Comments\\n\\nJohn ThorstadHusband | Father | Musician (with new music out now!) | Nerd Stuff | Duality\\n1d\\n\\nReport this comment\\n\\nthis is a great breakdown. Scott Silvi (and the rest of us) has been deep in agentic AI building Nigel. it automates backlog triage, issue resolution, and sprint planning so engineering teams can focus on shipping instead of getting buried in workflow chaos. a lot of what you’re doing with agentic RAG at toyota lines up with what we’ve been tackling. using AI not just to process info but to actually shape priorities and decision-making as work moves forward. where do you see the biggest challenge as more teams lean into AI-driven workflows? getting buy-in? making agents work together smoothly? something else?\\nLikeReply1 Reaction 2\\xa0Reactions\\n\\nVijay VishnuTransforming Experienced Tech Professionals (7-20 YOE) into Cloud & AI Experts | Scalable Systems Specialist |Tech Stack Simplifier\\n2d\\n\\nReport this comment\\n\\nInteresting\\nLikeReply1 Reaction 2\\xa0Reactions\\nSee more comments\\nTo view or add a comment, sign in\\nMore articles by Satyam Mittal\\n\\n\\nWhat Are AI Agents?\\n \\nJan 7, 2025\\nWhat Are AI Agents?\\nAI agents are systems that leverage advanced algorithms, massive data processing, and machine learning to interpret…\\n  38\\n\\n\\nAI Architectures: LLMs, LAMs, LCMs, and LFMs\\n \\nDec 14, 2024\\nAI Architectures: LLMs, LAMs, LCMs, and LFMs\\nArtificial Intelligence (AI) has seen a rapid evolution, giving rise to a variety of architectures tailored to address…\\n   98\\n2 Comments\\n\\n\\nPydantic AI : Agent Framework\\n \\nDec 7, 2024\\nPydantic AI : Agent Framework\\nThe Pydantic AI Agent Framework is a powerful tool for building agentic AI systems with robust data validation…\\n  42\\n1 Comment\\n\\n\\nWorld : A New Identity and Financial Network\\n \\nOct 19, 2024\\nWorld : A New Identity and Financial Network\\nThe Worldcoin project envisions creating a globally inclusive identity and financial network, accessible to the…\\n  15\\n3 Comments\\n\\n\\n🌟Evaluating fairness in ChatGPT\\n \\nOct 17, 2024\\n🌟Evaluating fairness in ChatGPT\\nThis article from OpenAI is interesting where they have talked about nature of #bias in AI 🌟𝐖𝐡𝐚𝐭 𝐢𝐬 𝐁𝐢𝐚𝐬…\\n  6\\n\\n\\nSelf-Taught Optimizer (STOP): Recursive Self-Improvement in Code Generation\\n \\nOct 14, 2024\\nSelf-Taught Optimizer (STOP): Recursive Self-Improvement in Code Generation\\nPublished at COLM 2024, the Self-Taught Optimizer (STOP) represents a leap forward in recursive code optimization…\\n  12\\n4 Comments\\n\\n\\nCombining Insights from Chroma and Anthropic: A Unified Approach to Advanced Retrieval Systems\\n \\nOct 4, 2024\\nCombining Insights from Chroma and Anthropic: A Unified Approach to Advanced Retrieval Systems\\nBoth Chroma and Anthropic’s research illustrate the evolving landscape of retrieval systems and how chunking plays a…\\n 5\\n3 Comments\\n\\n\\nMulti-Agent AI Query System\\n \\nSep 1, 2024\\nMulti-Agent AI Query System\\nIntroduction Recently, I set out to build a tool that could help me learn from both LlamaIndex and LangChain…\\n   29\\n8 Comments\\n\\n\\nOpensearch-Vectorestore\\n \\nJul 31, 2024\\nOpensearch-Vectorestore\\nOpensearch is an open-source search and analytics suite derived from Elasticsearch and Kibana and offers a robust…\\n   12\\n\\n\\nRetrieval-Augmented Generation (RAG)-Evaluation\\n \\nJul 15, 2024\\nRetrieval-Augmented Generation (RAG)-Evaluation\\nRAG is a approach for enhancing the performance of generative models by providing related external knowledge during the…\\n 9\\n\\n\\nShow more\\nSee all articles\\nSign in\\nStay updated on your professional world\\nSign in\\nBy clicking Continue to join or sign in, you agree to LinkedIn’s User Agreement, Privacy Policy, and Cookie Policy.\\nNew to LinkedIn? Join now\\nExplore topics\\n\\nSales\\nMarketing\\nIT Services\\nBusiness Administration\\nHR Management\\nEngineering\\nSoft Skills\\n\\nSee All\\n\\n\\nLinkedIn © 2025\\n\\nAbout\\nAccessibility\\nUser Agreement\\nPrivacy Policy\\nYour California Privacy Choices\\nCookie Policy\\nCopyright Policy\\nBrand Policy\\nGuest Controls\\nCommunity Guidelines\\n\\n\\nالعربية (Arabic)\\nবাংলা (Bangla)\\nČeština (Czech)\\nDansk (Danish)\\nDeutsch (German)\\nΕλληνικά (Greek)\\nEnglish (English)\\nEspañol (Spanish)\\nفارسی (Persian)\\nSuomi (Finnish)\\nFrançais (French)\\nहिंदी (Hindi)\\nMagyar (Hungarian)\\nBahasa Indonesia (Indonesian)\\nItaliano (Italian)\\nעברית (Hebrew)\\n日本語 (Japanese)\\n한국어 (Korean)\\nमराठी (Marathi)\\nBahasa Malaysia (Malay)\\nNederlands (Dutch)\\nNorsk (Norwegian)\\nਪੰਜਾਬੀ (Punjabi)\\nPolski (Polish)\\nPortuguês (Portuguese)\\nRomână (Romanian)\\nРусский (Russian)\\nSvenska (Swedish)\\nతెలుగు (Telugu)\\nภาษาไทย (Thai)\\nTagalog (Tagalog)\\nTürkçe (Turkish)\\nУкраїнська (Ukrainian)\\nTiếng Việt (Vietnamese)\\n简体中文 (Chinese (Simplified))\\n正體中文 (Chinese (Traditional))\\n\\nLanguage\\n\\n\\n\\n5 Agentic AI Design Patterns - by Avi Chawla\\n\\nDaily Dose of Data Science\\nSubscribeSign in\\nShare this post\\n  Daily Dose of Data Science 5 Agentic AI Design Patterns\\nCopy link\\nFacebook\\nEmail\\nNotes\\nMore\\n5 Agentic AI Design Patterns\\n...explained visually\\n\\nAvi Chawla\\nJan 23, 2025\\n27\\nShare this post\\n  Daily Dose of Data Science 5 Agentic AI Design Patterns\\nCopy link\\nFacebook\\nEmail\\nNotes\\nMore\\n\\n1\\nShare\\nWeb scraping in pure English with Firecrawl Extract\\nWith simple English prompts, you can now effortlessly extract clean, structured data from the web.\\nFirecrawl Extract does this as follows:\\n\\n\\n\\nProvide the website URL and specify what you want to extract as a prompt.\\n\\n\\nFireCrawl Extract automatically generates the request parameters and a schema (all editable).\\n\\n\\nClick “Run” and get clean, structured data in seconds.\\n\\n\\nIn the above image, I asked it to extract the authors of this newsletter, and it returned the correct output—Avi Chawla and Akshay Pachaar.\\nFireCrawl also generates code snippets to run the same job programmatically.\\nStart scrapping with FireCrawl\\nThanks to FireCrawl for showing us their powerful scraping capabilities and partnering today!\\n\\n5 Agentic AI Design Patterns\\nAgentic behaviors allow LLMs to refine their output by incorporating self-evaluation, planning, and collaboration!\\nThe following visual depicts the 5 most popular design patterns employed in building AI agents.\\n\\nLet\\'s understand them below!\\n\\nOn a side note, we started a beginner-friendly crash course on RAGs recently with implementations, which covers:\\n\\n\\n\\u200b\\u200bRAG fundamentals\\u200b\\u200b\\u200b\\u200b\\u200b\\n\\n\\n\\u200bRAG evaluation\\u200b\\n\\n\\n\\u200b\\u200b\\u200b\\u200b\\u200bRAG optimization\\u200b\\u200b\\u200b\\u200b\\u200b\\n\\n\\n\\u200bMultimodal RAG\\u200b\\n\\n\\n\\u200b\\u200b\\u200b\\u200b\\u200bGraph RAG\\u200b\\u200b\\n\\n\\n\\u200b\\u200bMultivector retrieval using ColBERT\\u200b\\n\\n\\n\\u200b\\u200b\\u200b\\u200b\\u200bRAG over complex real word docs ft. ColPali\\u200b\\n\\n\\n\\n\\n\\n1) Reflection pattern\\n\\nThe AI reviews its work to spot mistakes and iterate until it produces the final response.\\n2) Tool use pattern\\n\\nTools allow LLMs to gather more information by:\\n\\n\\nQuerying a vector database\\n\\n\\nExecuting Python scripts\\n\\n\\nInvoking APIs, etc.\\n\\n\\nThis is helpful since the LLM is not solely reliant on its internal knowledge.\\n3) ReAct (Reason and Act) pattern\\n\\nReAct combines the above two patterns:\\n\\n\\nThe Agent can reflect on the generated outputs.\\n\\n\\nIt can interact with the world using tools.\\n\\n\\nThis makes it one of the most powerful patterns used today.\\n4) Planning pattern\\n\\nInstead of solving a request in one go, the AI creates a roadmap by:\\n\\n\\nSubdividing tasks\\n\\n\\nOutlining objectives\\n\\n\\nThis strategic thinking can solve tasks more effectively.\\n5) Multi-agent pattern\\n\\nIn this setup:\\n\\n\\nWe have several agents.\\n\\n\\nEach Agent is assigned a dedicated role and task.\\n\\n\\nEach Agent can also access tools.\\n\\n\\nAll agents work together to deliver the final outcome while delegating tasks to other agents if needed.\\n\\nWe\\'ll soon dive deep into each of these patterns, showcasing real-world use cases and code implementations.\\nIn the meantime, make sure you are fully equipped with everything we have covered so far like:\\n\\n\\n\\u200bRAG fundamentals\\u200b\\n\\n\\n\\u200bRAG evaluation\\u200b\\n\\n\\n\\u200bRAG optimization\\u200b\\n\\n\\n\\u200bMultimodal RAG\\u200b\\n\\n\\n\\u200bGraph RAG\\u200b\\n\\n\\n\\u200bMultivector retrieval using ColBERT\\u200b\\n\\n\\n\\u200bRAG over complex real word docs ft. ColPali\\u200b\\n\\n\\nThanks for reading Daily Dose of Data Science! Subscribe below and receive a free data science PDF (530+ pages) with 150+ core data science and machine learning lessons.\\nSubscribe\\n\\nP.S. For those wanting to develop “Industry ML” expertise:\\n\\nAt the end of the day, all businesses care about impact. That’s it!\\n\\n\\nCan you reduce costs?\\n\\n\\nDrive revenue?\\n\\n\\nCan you scale ML models?\\n\\n\\nPredict trends before they happen?\\n\\n\\nWe have discussed several other topics (with implementations) in the past that align with such topics.\\nDevelop \"Industry ML\" Skills\\nHere are some of them:\\n\\n\\nLearn sophisticated graph architectures and how to train them on graph data: A Crash Course on Graph Neural Networks – Part 1.\\n\\n\\nSo many real-world NLP systems rely on pairwise context scoring. Learn scalable approaches here: Bi-encoders and Cross-encoders for Sentence Pair Similarity Scoring – Part 1.\\n\\n\\nLearn techniques to run large models on small devices: Quantization: Optimize ML Models to Run Them on Tiny Hardware.\\n\\n\\nLearn how to generate prediction intervals or sets with strong statistical guarantees for increasing trust: Conformal Predictions: Build Confidence in Your ML Model’s Predictions.\\n\\n\\nLearn how to identify causal relationships and answer business questions: A Crash Course on Causality – Part 1\\n\\n\\nLearn how to scale ML model training: A Practical Guide to Scaling ML Model Training.\\n\\n\\nLearn techniques to reliably roll out new models in production: 5 Must-Know Ways to Test ML Models in Production (Implementation Included)\\n\\n\\nLearn how to build privacy-first ML systems: Federated Learning: A Critical Step Towards Privacy-Preserving Machine Learning.\\n\\n\\nLearn how to compress ML models and reduce costs: Model Compression: A Critical Step Towards Efficient Machine Learning.\\n\\n\\nAll these resources will help you cultivate key skills that businesses and companies care about the most.\\n27\\nShare this post\\n  Daily Dose of Data Science 5 Agentic AI Design Patterns\\nCopy link\\nFacebook\\nEmail\\nNotes\\nMore\\n\\n1\\nShare\\nPreviousNext\\nDiscussion about this post\\nCommentsRestacks\\n\\nTopLatestDiscussions\\nNo posts\\nReady for more?\\nSubscribe\\n© 2025 Avi Chawla\\nPrivacy ∙ Terms ∙ Collection notice\\nStart WritingGet the app\\nSubstack is the home for great culture\\nShare\\nCopy link\\nFacebook\\nEmail\\nNotes\\nMore\\n\\nTop 4 Agentic AI Design Patterns\\n\\n\\n\\nDeepSeek\\nLearning Paths\\nGenAI Pinnacle Program\\n\\nAgentic AI Pioneer Program New\\n\\n\\n\\n\\n\\nLogin\\nSwitch Mode\\nLogout\\n\\n\\n\\nInterview Prep\\nCareer\\nGenAI\\nPrompt Engg\\nChatGPT\\nLLM\\nLangchain\\nRAG\\nAI Agents\\nMachine Learning\\nDeep Learning\\nGenAI Tools\\nLLMOps\\nPython\\nNLP\\nSQL\\nAIML Projects\\n\\n\\nHome\\nAI Agents\\nTop 4 Agentic AI Design Patterns for Architecting AI Systems\\n\\nTop 4 Agentic AI Design Patterns for Architecting AI Systems\\n\\nPankaj Singh Last Updated : 06 Jan, 2025\\n10 min read\\n0\\nLearning is a continuous journey, whether you’re human or an AI model. However, one question that often comes up is, can these AI models learn themselves just like humans do? As per the recent developments – They can. To understand this in a better way, let’s go back to our college days when C++, Java, and Python were the primary languages we needed to master to excel in computer science. Learning these languages requires understanding syntax, semantics, practical application, and problem-solving. So, to get a strong hold on these languages, we practised continuously (or you can say get trained). Also, we learned a lot from our classmates and professors. Right? Similarly, just like humans can learn from their own thinking, expertise and other mediums, perhaps LLMs can, too.\\nHowever, gaining expertise or becoming a subject matter expert is quite a rigorous journey for both humans and LLMs. We know about the human learning process and reasoning capabilities for making decisions and completing tasks, but what does LLM training look like?\\nCan I say?\\n\\nFirstly, pre-training of LLM: In this step, you help the model learn patterns, such as grammar, sentence structure, and even relationships between words and concepts.\\nInstruction-tuning (or Fine-Tuning): To fine-tune the model, a curated dataset containing examples of instructions and desired responses is used.\\nReinforcement Learning with Human Feedback (RLHF): Human evaluators rank model responses, which is used further to improve the model’s alignment with user expectations.\\n\\nThat makes sense, right? But what if we build an agentic workflow to make the model learn and give the output while doing all the checks independently? It would be like having your own assistant who can do all the work without any human intervention. Further, in this article we will talk about the 4 Agentic AI Design Patterns for Architecting AI Systems.\\n\\nWhat is Agentic AI Reflection Pattern?\\nWhat is Agentic AI Tool Use Pattern?\\nWhat is Agentic AI Planning Pattern?\\nWhat is Agentic AI Multi-Agent Pattern?\\n\\n\\nSource: Author\\nOverview\\n\\nThe article discusses how AI models, particularly large language models (LLMs) like GPT, can learn autonomously by adopting agentic workflows, which mimic human-like iterative problem-solving.\\nAgentic workflows enhance AI performance by refining tasks step-by-step, similar to how humans review and improve their work repeatedly for better results.\\nFour key Agentic Design Patterns—Reflection, Tool Use, Planning, and Multi-Agent Collaboration—are introduced as strategies that make AI systems more autonomous and capable.\\n\\nTable of contents\\n\\nOverview\\nWhat is Agentic Design Patterns?\\nAgentic Design Patterns: Evaluations\\n4 Types of Agentic Design Patterns that You Must Know\\nReflection Pattern\\nTool Use Pattern\\nPlanning Pattern\\nMulti-Agent Pattern\\n\\n\\nConclusion\\nFrequently Asked Questions\\n\\nWhat is Agentic Design Patterns?\\nThe agentic design pattern is introduced as a solution for making LLMs more autonomous. Instead of just giving the model one prompt and expecting a final answer (like writing an essay in one go), an agent-like approach involves prompting the LLM multiple times, step by step. Each step refines the task, with the model improving its output iteratively.\\nTo understand this better, let’s look at it like this:  \\nWhen we prompt an LLM in zero-shot mode, it’s like asking someone to write a story in one go without revising. LLMs do well at this, but they can do even better. By using an agent-like workflow, we can prompt the LLM multiple times in steps. Each step builds on the previous one, refining the response. Think of it like asking the LLM to go over the essay multiple times, improving it with each pass.\\nBy each step, I meant:\\nLet’s take the example of writing a code using Agentic workflow:\\n\\nPlan an outline for the code: Break down the task into smaller modules or functions.\\nGather information and content: Research libraries, algorithms, or existing solutions. Do web searches or check the documentation if needed.\\nWrite the first draft of the code: Implement the basic functionality, focusing on structure over perfection.\\nReview the code for inefficiencies or errors: Check for unnecessary code, bugs, or logic flaws.\\nRevise the code: Refactor, optimise, or add comments for clarity.\\n\\nRinse and repeat until the code is efficient and clean.\\nBy allowing the model to work through these steps independently, the agentic design pattern enhances both human-like reasoning and efficiency. This is similar to how humans break down complex tasks, gather information, make improvements, and iterate until the final result is satisfactory. Now, let us understand the Agentic design pattern in detail.\\nAgentic Design Patterns: Evaluations\\n\\nSource:\\xa0 Andrew Ng | Deeplearning.ai\\nAndrew Ng’s analysis, shared in a letter on\\xa0Deeplearning.ai, noted advancements in AI-driven code generation, particularly focusing on the performance of models like GPT-3.5 and GPT-4. The evaluation was centred on these models’ capabilities to perform on the widely recognized HumanEval coding benchmark, a common standard for assessing an algorithm’s proficiency in writing code.\\nThe data presented shows the evolution in AI coding abilities using AI agents. GPT-3.5, when tested in a zero-shot setting (i.e., without any prior examples), achieved a correctness rate of 48.1%. GPT-4, also evaluated in a zero-shot manner, demonstrated a significant improvement, with a 67.0% success rate. However, what stood out in the analysis was how integrating these models into an iterative agent workflow (Agentic workflow) drastically boosted their performance. When GPT-3.5 was wrapped in such an agent loop, its accuracy soared to an impressive 95.1%, far surpassing its baseline and even approaching human-level coding proficiency.\\nThis finding underscores the transformative potential of iterative workflows (Agentic workflow) in enhancing AI model performance, suggesting that the future of AI-assisted coding may heavily rely on these more advanced, adaptive frameworks rather than on model size or architecture improvements alone.\\nBut what are Agentic design patterns that complete the delegation of autonomy to AI systems, enabling them to act more independently and effectively? These patterns structure AI agents to perform tasks, make decisions, and communicate with other systems in a more human-like and autonomous manner, ultimately creating both savvy and dependable applications.\\x7f\\n4 Types of Agentic Design Patterns that You Must Know\\nIn Agentic AI and the key design patterns, it’s essential to understand how each pattern empowers large language models (LLMs) like GPT to behave more autonomously and effectively. These design patterns push the boundaries of what AI can do by encouraging self-evaluation, tool integration, strategic thinking, and collaboration. Let’s explore four vital agentic design patterns that shape how these models operate and perform complex tasks.\\nHere are the types of agentic design patterns:\\n1. Reflection Pattern\\n\\nSource: Author\\nThe Reflection Pattern focuses on improving AI’s ability to evaluate and refine its own outputs. Imagine an LLM reviewing its generated content or code as if it were a human reviewer, identifying errors, gaps, or areas that need improvement and then offering suggestions for how to improve.\\nThis self-critique loop is not limited to a single iteration. The AI can repeat the reflection process as many times as necessary to achieve a refined, polished result. For example, if tasked with writing software, the LLM can generate an initial version, critique its own logic and structure, and revise the code. The iterative nature of reflection leads to stronger, more reliable outputs over time.\\nThis pattern is particularly useful in tasks that require precision, such as content creation, problem-solving, or code generation. Employing this approach can enhance the model’s accuracy and reliability through self-guided corrections.\\nOne interesting example is Self-Reflective RAG. SELF-RAG is a framework designed to improve language models’ quality and factual accuracy by integrating retrieval and self-reflection into the text generation process. Traditional Retrieval-Augmented Generation (RAG) models enhance responses by incorporating relevant retrieved passages but often retrieve a fixed number of documents regardless of their relevance, which can introduce noise or irrelevant content. SELF-RAG addresses these limitations through an adaptive approach that retrieves information on demand and uses reflection tokens to assess the generation’s quality.\\nHow SELF-RAG Uses Reflection?\\nSELF-RAG incorporates self-reflection mechanisms via “reflection tokens,” which serve to evaluate various aspects of the text generation, such as relevance, support, and overall utility. During the generation process, the model evaluates whether retrieval is necessary and assesses the quality of the generated content by critiquing itself at different stages.\\nHere’s the diagram for better understanding:\\n\\nSource: SELF-RAG\\n\\nTraditional RAG retrieves a fixed number of documents first, while Self-RAG performs retrieval dynamically based on the content being generated.\\nSelf-RAG evaluates multiple generated segments, critiques their quality, and selectively combines the most accurate information.\\nSelf-RAG’s iterative process enables refining the generation step by step, improving the accuracy and relevance of the output.\\n\\nIn a nutshell, Self-RAG adds an extra layer of self-reflection and refinement, leading to more reliable and precise answers.\\n2. Tool Use Pattern\\n\\nSource: Author\\nThe Tool Use Pattern significantly broadens an LLM’s capability by allowing it to interact with external tools and resources to enhance its problem-solving abilities. Instead of relying solely on internal computations or knowledge, an AI following this pattern can access databases, search the web, or even execute complex functions via programming languages like Python.\\nFor instance, an LLM could be prompted to retrieve data from the web for a specific query, analyze it, and integrate it into its output. Alternatively, it might be tasked with calculating statistical results, generating images, or manipulating spreadsheets—actions that go beyond simple text generation. By incorporating the use of tools, LLMs evolve from static knowledge banks into dynamic agents capable of interacting with external systems to achieve goals.\\nThis pattern is powerful because it allows AI systems to tackle more complex, multifaceted tasks where internal knowledge alone isn’t sufficient, expanding their utility into real-world applications.\\n3. Planning Pattern\\n\\nSource: Author\\nThe Planning Pattern enables an LLM to break down large, complicated tasks into smaller, more manageable components. Planning equips an agent with the ability to react to requests and strategically structure the steps needed to achieve a goal.\\nInstead of tackling a problem linearly, ad hocly, an LLM using the Planning Pattern will create a roadmap of subtasks, determining the most efficient path to completion. For example, when coding, the LLM would first outline the overall structure before implementing individual functions. This avoids confusion or meandering logic and keeps the AI focused on the main objective.\\nReAct (Reasoning and Acting) and ReWOO (Reasoning With Open Ontology) further extend this approach by integrating decision-making and contextual reasoning into the planning process. ReAct enables the LLM to dynamically alternate between reasoning (thinking through the problem) and acting (performing specific tasks), allowing for more adaptive and flexible planning. By combining these two steps, the LLM can refine its approach iteratively, addressing unexpected challenges as they arise.\\nReWOO, on the other hand, enhances the planning pattern by using an open-world ontology to guide reasoning. This means the LLM can incorporate broader contextual information and knowledge from various domains, leading to more informed decision-making. With ReWOO, the AI can adjust the plan in real-time based on newly acquired information or changing requirements, ensuring a more robust and comprehensive problem-solving approach.\\nTogether, the Planning Pattern, ReAct, and ReWOO enable an LLM to handle complex tasks in a structured yet adaptive manner, resulting in efficient and goal-oriented execution.\\nMoreover, generating a structured plan (or a “user_request_summary”) ensures that the AI keeps track of all steps and doesn’t lose sight of the broader task. This method ensures higher quality and consistency in the results, especially in complex problem-solving or multi-phase projects.\\n4. Multi-Agent Pattern\\n\\nSource: Author\\nThe Multi-Agent Pattern builds upon the concept of delegation, akin to project management in human teams. This pattern involves assigning different agents (which are instances of an LLM with specific roles or functions) to handle various subtasks. These agents can work independently on their assignments while also communicating and collaborating to achieve a unified outcome.\\nThere are several types of multi-agent patterns:\\n\\nCollaborative Agents: Multiple agents work together on different parts of a task, sharing progress and building toward a unified result. Each agent may specialize in a different domain.\\nSupervised Agents: A central supervisor agent manages other agents, coordinating their activities and verifying results to ensure quality.\\nHierarchical Teams: A structured system where higher-level agents oversee lower-level agents, with decision-making cascaded through levels to accomplish complex tasks.\\n\\nFor more details on this, explore: Multi-agent Collaboration.\\nFor instance, in a scenario requiring both text analysis and numerical computation, two separate agents can handle each task, sharing their results to form a comprehensive solution. One agent might focus on understanding the context, while another processes data, and together they deliver a holistic response. This pattern is particularly powerful for tackling large-scale or complex problems that require diverse skill sets.\\nIn short, the Multiagent Pattern mirrors how humans collaborate across specialities, ensuring that each agent focuses on its strengths while contributing to a greater, coordinated effort.\\nBy mastering these four agentic design patterns, developers and users alike can unlock the full potential of AI systems. The Reflection Pattern improves accuracy and quality through self-evaluation, Tool Use enables dynamic, real-world interactions, Planning provides a roadmap for solving complex tasks, and Multiagent Collaboration ensures that multiple agents work together effectively. Together, these patterns create a foundation for building more intelligent, autonomous AI systems capable of addressing real-world challenges.\\nConclusion\\nAgentic Design Patterns emphasize the transformative potential of agentic workflows in making AI models, particularly large language models (LLMs), more autonomous and efficient. It explains that while models like GPT-3.5 and GPT-4 perform well in zero-shot tasks, their accuracy and effectiveness significantly improve when adopting an iterative, agentic workflow. This method allows the model to break down tasks, self-evaluate, leverage external tools, plan strategically, and collaborate with other agents, enhancing their problem-solving capabilities.\\nThe article introduces four key design patterns—Reflection, Tool Use, Planning, and Multiagent—that form the foundation of these agentic workflows. These patterns push the boundaries of what AI can do and enable AI systems to behave more independently and intelligently, much like humans handling complex tasks. This signals that future AI advancements will depend on increasing model size and developing more adaptive and strategic workflows.\\nIn this series on Agentic Design Patterns, we will further explore each design pattern in detail: Reflection, Tool Use, Planning, and Multiagent, uncovering how they empower AI systems to become even more autonomous and capable.\\nStay tuned!!!!\\nExplore the The Agentic AI Pioneer Program to deepen your understanding of Agent AI and unlock its full potential. Join us on this journey to discover innovative insights and applications!\\nFrequently Asked Questions\\nQ1. What are Agentic Design Patterns in AI?****Ans. Agentic Design Patterns are strategies used to make AI systems, especially large language models (LLMs), more autonomous and effective. These patterns allow AI to perform tasks, make decisions, and interact with other systems more independently by simulating human-like problem-solving and reasoning processes. The key patterns include Reflection, Tool Use, Planning, and Multi-Agent collaboration.\\nQ2. How does the Reflection Pattern improve AI performance?****Ans. The Reflection Pattern enhances AI’s ability to self-evaluate and refine its output. By repeatedly reviewing its own work, the AI identifies errors, gaps, or areas for improvement and makes corrections in an iterative loop. This pattern proves particularly useful for tasks requiring precision, such as code generation or content creation, as it helps produce more accurate and reliable results.\\nQ3. What is the benefit of using the Tool Use Pattern in AI workflows?****Ans. The Tool Use Pattern expands an AI’s capabilities by allowing it to interact with external tools and resources. Instead of solely relying on internal knowledge, the AI can access databases, perform web searches, or execute functions using programming languages like Python. This makes the AI more versatile and able to tackle complex tasks that require information or computations beyond its pre-existing data.\\nQ4. How does the Planning Pattern help LLMs handle complex tasks?****Ans. The Planning Pattern enables an AI model to break down complicated tasks into smaller, manageable steps, creating a roadmap for solving the problem. This approach helps maintain focus on the main objective and ensures efficient task execution. Variations like ReAct (Reasoning and Acting) and ReWOO (Reasoning With Open Ontology) incorporate decision-making and adaptive strategies, allowing the AI to refine its approach dynamically as new information becomes available.\\n\\nPankaj Singh\\nHi, I am Pankaj Singh Negi - Senior Content Editor | Passionate about storytelling and crafting compelling narratives that transform ideas into impactful content. I love reading about technology revolutionizing our lifestyle.\\nAdvancedAI AgentsArtificial IntelligenceLarge Language Models\\nFree Courses\\n 4.7 #### Generative AI - A Way of Life Explore Generative AI for beginners: create text and images, use top AI tools, learn practical skills, and ethics.\\n 4.5 #### Getting Started with Large Language Models Master Large Language Models (LLMs) with this course, offering clear guidance in NLP and model training made simple.\\n 4.6 #### Building LLM Applications using Prompt Engineering This free course guides you on building LLM apps, mastering prompt engineering, and developing chatbots with enterprise data.\\n 4.8 #### Improving Real World RAG Systems: Key Challenges & Practical Solutions Explore practical solutions, advanced retrieval strategies, and agentic RAG systems to improve context, relevance, and accuracy in AI-driven applications.\\n 4.7 #### Microsoft Excel: Formulas & Functions Master MS Excel for data analysis with key formulas, functions, and LookUp tools in this comprehensive course.\\n\\nResponses From Readers\\nCancel reply\\nClearSubmit reply\\nΔ\\nWrite for us ------------ Write, captivate, and earn accolades and rewards for your work* Reach a Global Audience * Get Expert Feedback * Build Your Brand & Audience * Cash In on Your Knowledge * Join a Thriving Community * Level Up Your Data Science Game\\n\\nWe use cookies essential for this site to function well. Please click to help us improve its usefulness with additional cookies. Learn about our use of cookies in our Privacy Policy & Cookies Policy.\\nShow details\\nAccept all cookies\\nUse necessary cookies\\nPowered By \\n\\nConsent\\nDetails\\nAbout\\n\\nCookies\\nThis site uses cookies to ensure that you get the best experience possible. To learn more about how we use cookies, please refer to our Privacy Policy & Cookies Policy.\\nNecessary (2)\\nNecessary cookies help make a website usable by enabling basic functions like page navigation and access to secure areas of the website. The website cannot function properly without these cookies.\\n\\nAnalytics Vidhya (4)\\nlearn more about analytics vidhya privacy\\nbrahmaid\\nIt is needed for personalizing the website.\\nExpiry: Session\\nType: HTTP\\ncsrftoken\\nThis cookie is used to prevent Cross-site request forgery (often abbreviated as CSRF) attacks of the website\\nExpiry: Session\\nType: HTTPS\\nIdentityid\\nPreserves the login/logout state of users across the whole site.\\nExpiry: Session\\nType: HTTPS\\nsessionid\\nPreserves users\\' states across page requests.\\nExpiry: Session\\nType: HTTPS\\nGoogle (1)\\nlearn more about google privacy\\ng_state\\nGoogle One-Tap login adds this g_state cookie to set the user status on how they interact with the One-Tap modal.\\nExpiry: 365 days\\nType: HTTP\\nStatistics (4)\\nStatistic cookies help website owners to understand how visitors interact with websites by collecting and reporting information anonymously.\\n\\nMicrosoft (7)\\nlearn more about microsoft policy\\nMUID\\nUsed by Microsoft Clarity, to store and track visits across websites.\\nExpiry: 1 Year\\nType: HTTP\\n_clck\\nUsed by Microsoft Clarity, Persists the Clarity User ID and preferences, unique to that site, on the browser. This ensures that behavior in subsequent visits to the same site will be attributed to the same user ID.\\nExpiry: 1 Year\\nType: HTTP\\n_clsk\\nUsed by Microsoft Clarity, Connects multiple page views by a user into a single Clarity session recording.\\nExpiry: 1 Day\\nType: HTTP\\nSRM_I\\nCollects user data is specifically adapted to the user or device. The user can also be followed outside of the loaded website, creating a picture of the visitor\\'s behavior.\\nExpiry: 2 Years\\nType: HTTP\\nSM\\nUse to measure the use of the website for internal analytics\\nExpiry: 1 Years\\nType: HTTP\\nCLID\\nThe cookie is set by embedded Microsoft Clarity scripts. The purpose of this cookie is for heatmap and session recording.\\nExpiry: 1 Year\\nType: HTTP\\nSRM_B\\nCollected user data is specifically adapted to the user or device. The user can also be followed outside of the loaded website, creating a picture of the visitor\\'s behavior.\\nExpiry: 2 Months\\nType: HTTP\\nGoogle (7)\\nlearn more about google privacy\\n_gid\\nThis cookie is installed by Google Analytics. The cookie is used to store information of how visitors use a website and helps in creating an analytics report of how the website is doing. The data collected includes the number of visitors, the source where they have come from, and the pages visited in an anonymous form.\\nExpiry: 399 Days\\nType: HTTP\\n_ga_\\nUsed by Google Analytics, to store and count pageviews.\\nExpiry: 399 Days\\nType: HTTP\\n_gat_\\nUsed by Google Analytics to collect data on the number of times a user has visited the website as well as dates for the first and most recent visit.\\nExpiry: 1 Day\\nType: HTTP\\ncollect\\nUsed to send data to Google Analytics about the visitor\\'s device and behavior. Tracks the visitor across devices and marketing channels.\\nExpiry: Session\\nType: PIXEL\\nAEC\\ncookies ensure that requests within a browsing session are made by the user, and not by other sites.\\nExpiry: 6 Months\\nType: HTTP\\nG_ENABLED_IDPS\\nuse the cookie when customers want to make a referral from their gmail contacts; it helps auth the gmail account.\\nExpiry: 2 Years\\nType: HTTP\\ntest_cookie\\nThis cookie is set by DoubleClick (which is owned by Google) to determine if the website visitor\\'s browser supports cookies.\\nExpiry: 1 Year\\nType: HTTP\\nWebengage (2)\\nLearn more about webengage privacy\\n_we_us\\nthis is used to send push notification using webengage.\\nExpiry: 1 Year\\nType: HTTP\\nWebKlipperAuth\\nused by webenage to track auth of webenagage.\\nExpiry: Session\\nType: HTTP\\nLinkedIn (16)\\nlearn more about linkedin privacy\\nln_or\\nLinkedin sets this cookie to registers statistical data on users\\' behavior on the website for internal analytics.\\nExpiry: 1 Day\\nType: HTTP\\nJSESSIONID\\nUse to maintain an anonymous user session by the server.\\nExpiry: 1 Year\\nType: HTTP\\nli_rm\\nUsed as part of the LinkedIn Remember Me feature and is set when a user clicks Remember Me on the device to make it easier for him or her to sign in to that device.\\nExpiry: 1 Year\\nType: HTTP\\nAnalyticsSyncHistory\\nUsed to store information about the time a sync with the lms_analytics cookie took place for users in the Designated Countries.\\nExpiry: 6 Months\\nType: HTTP\\nlms_analytics\\nUsed to store information about the time a sync with the AnalyticsSyncHistory cookie took place for users in the Designated Countries.\\nExpiry: 6 Months\\nType: HTTP\\nliap\\nCookie used for Sign-in with Linkedin and/or to allow for the Linkedin follow feature.\\nExpiry: 6 Months\\nType: HTTP\\nvisit\\nallow for the Linkedin follow feature.\\nExpiry: 1 Year\\nType: HTTP\\nli_at\\noften used to identify you, including your name, interests, and previous activity.\\nExpiry: 2 Months\\nType: HTTP\\ns_plt\\nTracks the time that the previous page took to load\\nExpiry: Session\\nType: HTTP\\nlang\\nUsed to remember a user\\'s language setting to ensure LinkedIn.com displays in the language selected by the user in their settings\\nExpiry: Session\\nType: HTTP\\ns_tp\\nTracks percent of page viewed\\nExpiry: Session\\nType: HTTP\\nAMCV_14215E3D5995C57C0A495C55%40AdobeOrg\\nIndicates the start of a session for Adobe Experience Cloud\\nExpiry: Session\\nType: HTTP\\ns_pltp\\nProvides page name value (URL) for use by Adobe Analytics\\nExpiry: Session\\nType: HTTP\\ns_tslv\\nUsed to retain and fetch time since last visit in Adobe Analytics\\nExpiry: 6 Months\\nType: HTTP\\nli_theme\\nRemembers a user\\'s display preference/theme setting\\nExpiry: 6 Months\\nType: HTTP\\nli_theme_set\\nRemembers which users have updated their display / theme preferences\\nExpiry: 6 Months\\nType: HTTP\\nPreferences (0)\\nPreference cookies enable a website to remember information that changes the way the website behaves or looks, like your preferred language or the region that you are in.\\n\\nWe do not use cookies of this type.\\nMarketing (4)\\nMarketing cookies are used to track visitors across websites. The intention is to display ads that are relevant and engaging for the individual user and thereby more valuable for publishers and third party advertisers.\\n\\nGoogle (11)\\nlearn more about google privacy\\n_gcl_au\\nUsed by Google Adsense, to store and track conversions.\\nExpiry: 3 Months\\nType: HTTP\\nSID\\nSave certain preferences, for example the number of search results per page or activation of the SafeSearch Filter. Adjusts the ads that appear in Google Search.\\nExpiry: 2 Years\\nType: HTTP\\nSAPISID\\nSave certain preferences, for example the number of search results per page or activation of the SafeSearch Filter. Adjusts the ads that appear in Google Search.\\nExpiry: 2 Years\\nType: HTTP\\n__Secure-\\nSave certain preferences, for example the number of search results per page or activation of the SafeSearch Filter. Adjusts the ads that appear in Google Search.\\nExpiry: 2 Years\\nType: HTTP\\nAPISID\\nSave certain preferences, for example the number of search results per page or activation of the SafeSearch Filter. Adjusts the ads that appear in Google Search.\\nExpiry: 2 Years\\nType: HTTP\\nSSID\\nSave certain preferences, for example the number of search results per page or activation of the SafeSearch Filter. Adjusts the ads that appear in Google Search.\\nExpiry: 2 Years\\nType: HTTP\\nHSID\\nSave certain preferences, for example the number of search results per page or activation of the SafeSearch Filter. Adjusts the ads that appear in Google Search.\\nExpiry: 2 Years\\nType: HTTP\\nDV\\nThese cookies are used for the purpose of targeted advertising.\\nExpiry: 6 Hours\\nType: HTTP\\nNID\\nThese cookies are used for the purpose of targeted advertising.\\nExpiry: 1 Month\\nType: HTTP\\n1P_JAR\\nThese cookies are used to gather website statistics, and track conversion rates.\\nExpiry: 1 Month\\nType: HTTP\\nOTZ\\nAggregate analysis of website visitors\\nExpiry: 6 Months\\nType: HTTP\\nFacebook (2)\\nlearn more about facebook privacy\\n_fbp\\nThis cookie is set by Facebook to deliver advertisements when they are on Facebook or a digital platform powered by Facebook advertising after visiting this website.\\nExpiry: 4 Months\\nType: HTTP\\nfr\\nContains a unique browser and user ID, used for targeted advertising.\\nExpiry: 2 Months\\nType: HTTP\\nLinkedIn (6)\\nLearn about linkedin policy\\nbscookie\\nUsed by LinkedIn to track the use of embedded services.\\nExpiry: 1 Year\\nType: HTTP\\nlidc\\nUsed by LinkedIn for tracking the use of embedded services.\\nExpiry: 1 Day\\nType: HTTP\\nbcookie\\nUsed by LinkedIn to track the use of embedded services.\\nExpiry: 6 Months\\nType: HTTP\\naam_uuid\\nUse these cookies to assign a unique ID when users visit a website.\\nExpiry: 6 Months\\nType: HTTP\\nUserMatchHistory\\nThese cookies are set by LinkedIn for advertising purposes, including: tracking visitors so that more relevant ads can be presented, allowing users to use the \\'Apply with LinkedIn\\' or the \\'Sign-in with LinkedIn\\' functions, collecting information about how visitors use the site, etc.\\nExpiry: 6 Months\\nType: HTTP\\nli_sugr\\nUsed to make a probabilistic match of a user\\'s identity outside the Designated Countries\\nExpiry: 90 Days\\nType: HTTP\\nMicrosoft (2)\\nLearn more about microsoft privacy.\\nMR\\nUsed to collect information for analytics purposes.\\nExpiry: 1 year\\nType: HTTP\\nANONCHK\\nUsed to store session ID for a users session to ensure that clicks from adverts on the Bing search engine are verified for reporting purposes and for personalisation\\nExpiry: 1 Day\\nType: HTTP\\nUnclassNameified (0)\\nUnclassNameified cookies are cookies that we are in the process of classNameifying, together with the providers of individual cookies.\\n\\nWe do not use cookies of this type.\\nCookie declaration last updated on 24/03/2023 by Analytics Vidhya.\\nCookies are small text files that can be used by websites to make a user\\'s experience more efficient. The law states that we can store cookies on your device if they are strictly necessary for the operation of this site. For all other types of cookies, we need your permission. This site uses different types of cookies. Some cookies are placed by third-party services that appear on our pages. Learn more about who we are, how you can contact us, and how we process personal data in our Privacy Policy.\\nAccept all cookies Use necessary cookies\\nFlagship Courses\\nGenAI Pinnacle Program| AI/ML BlackBelt Courses\\nFree Courses\\nGenerative AI| Large Language Models| Building LLM Applications using Prompt Engineering| Building Your first RAG System using LlamaIndex| Stability.AI| MidJourney| Building Production Ready RAG systems using LlamaIndex| Building LLMs for Code| Deep Learning| Python| Microsoft Excel| Machine Learning| Decision Trees| Pandas for Data Analysis| Ensemble Learning| NLP| NLP using Deep Learning| Neural Networks| Loan Prediction Practice Problem| Time Series Forecasting| Tableau| Business Analytics\\nPopular Categories\\nGenerative AI| Prompt Engineering| Generative AI Application| News| Technical Guides| AI Tools| Interview Preparation| Research Papers| Success Stories| Quiz| Use Cases| Listicles\\nGenerative AI Tools and Techniques\\nGANs| VAEs| Transformers| StyleGAN| Pix2Pix| Autoencoders| GPT| BERT| Word2Vec| LSTM| Attention Mechanisms| Diffusion Models| LLMs| SLMs| StyleGAN| Encoder Decoder Models| Prompt Engineering| LangChain| LlamaIndex| RAG| Fine-tuning| LangChain AI Agent| Multimodal Models| RNNs| DCGAN| ProGAN| Text-to-Image Models| DDPM| Document Question Answering| Imagen| T5 (Text-to-Text Transfer Transformer)| Seq2seq Models| WaveNet| Attention Is All You Need (Transformer Architecture)\\nPopular GenAI Models\\nLlama 3.1| Llama 3| Llama 2| GPT 4o Mini| GPT 4o| GPT 3| Claude 3 Haiku| Claude 3.5 Sonnet| Phi 3.5| Phi 3| Mistral Large 2| Mistral NeMo| Mistral-7b| Gemini 1.5 Pro| Gemini Flash 1.5| Bedrock| Vertex AI| DALL.E| Midjourney| Stable Diffusion\\nData Science Tools and Techniques\\nPython| R| SQL| Jupyter Notebooks| TensorFlow| Scikit-learn| PyTorch| Tableau| Apache Spark| Matplotlib| Seaborn| Pandas| Hadoop| Docker| Git| Keras| Apache Kafka| AWS| NLP| Random Forest| Computer Vision| Data Visualization| Data Exploration| Big Data| Common Machine Learning Algorithms| Machine Learning\\nCompany\\n\\nAbout Us\\nContact Us\\nCareers\\n\\nDiscover\\n\\nBlogs\\nExpert Sessions\\nLearning Paths\\nComprehensive Guides\\n\\nLearn\\n\\nFree Courses\\nAI&ML Program\\nGenAI Program\\nAgentic AI Program\\n\\nEngage\\n\\nCommunity\\nHackathons\\nEvents\\nPodcasts\\n\\nContribute\\n\\nBecome an Author\\nBecome a Speaker\\nBecome a Mentor\\nBecome an Instructor\\n\\nEnterprise\\n\\nOur Offerings\\nTrainings\\nData Culture\\nAI Newsletter\\n\\nTerms & conditions Refund Policy Privacy Policy Cookies Policy © Analytics Vidhya 2025.All rights reserved.\\n SKIP\\nContinue your learning for FREE\\nLogin with Google Login with Email Forgot your password?\\nI accept the Terms and Conditions\\nReceive updates on WhatsApp\\n\\nEnter email address to continue\\nEmail address \\nGet OTP\\n\\nEnter OTP sent to\\nEdit\\nEnter the OTP\\nResend OTP\\nResend OTP in 45s\\nVerify OTP\\n![Image 23](https://pixel.wp.com/g.gif?v=ext&blog=180026056&post=197906&tz=5.5&srv=www.analyticsvidhya.com&j=1%3A13.9.1&host=www.analyticsvidhya.com&ref=&fcp=1011&rand=0.4858963063571544)\\n\\n\\nAgree & Join LinkedIn\\nBy clicking Continue, you agree to LinkedInâ€™s User Agreement, Privacy Policy, and Cookie Policy.\\nAndrew Ngâ€™s Post\\nFounder of DeepLearning.AI; Managing General Partner of AI Fund; Founder and CEO of Landing AI\\nLast week, I described four design patterns for AI agentic workflows that I believe will drive significant progress: Reflection, Tool use, Planning and Multi-agent collaboration. Instead of having an LLM generate its final output directly, an agentic workflow prompts the LLM multiple times, giving it opportunities to build step by step to higher-quality output. Here, I\\'d like to discuss Reflection. It\\'s relatively quick to implement, and I\\'ve seen it lead to surprising performance gains.\\nYou may have had the experience of prompting ChatGPT/Claude/Gemini, receiving unsatisfactory output, delivering critical feedback to help the LLM improve its response, and then getting a better response. What if you automate the step of delivering critical feedback, so the model automatically criticizes its own output and improves its response? This is the crux of Reflection.\\nTake the task of asking an LLM to write code. We can prompt it to generate the desired code directly to carry out some task X. Then, we can prompt it to reflect on its own output, perhaps as follows:\\nHereâ€™s code intended for task X:\\n[previously generated code]\\nCheck the code carefully for correctness, style, and efficiency, and give constructive criticism for how to improve it.\\nSometimes this causes the LLM to spot problems and come up with constructive suggestions. Next, we can prompt the LLM with context including (i) the previously generated code and (ii) the constructive feedback, and ask it to use the feedback to rewrite the code. This can lead to a better response. Repeating the criticism/rewrite process might yield further improvements. This self-reflection process allows the LLM to spot gaps and improve its output on a variety of tasks including producing code, writing text, and answering questions.\\nAnd we can go beyond self-reflection by giving the LLM tools that help evaluate its output; for example, running its code through a few unit tests to check whether it generates correct results on test cases or searching the web to double-check text output. Then it can reflect on any errors it found and come up with ideas for improvement.\\nFurther, we can implement Reflection using a multi-agent framework. I\\'ve found it convenient to create two agents, one prompted to generate good outputs and the other prompted to give constructive criticism of the first agent\\'s output. The resulting discussion between the two agents leads to improved responses.\\nReflection is a relatively basic type of agentic workflow, but I\\'ve been delighted by how much it improved my applicationsâ€™ results. If youâ€™re interested in learning more about reflection, I recommend:\\n- Self-Refine: Iterative Refinement with Self-Feedback, by Madaan et al. (2023)\\n- Reflexion: Language Agents with Verbal Reinforcement Learning, by Shinn et al. (2023)\\n- CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing, by Gou et al. (2024)\\n[Original text: https://lnkd.in/g4bTuWtU ]\\nOne Agent For Many Worlds, Cross-Species Cell Embeddings, and more\\nSr. Software Engineer â€¢ Typescript â€¢ NextJS â€¢ React Native â€¢ AWS CDK\\nHere are my custom instructions:\\nâ€œFirst: Ensure responses delve into the implications of the userâ€™s findings, using them as a springboard for deeper insights rather than summarizing what has already been stated.\\nSecond: Tell me all the assumptions you are making and how they may be wrong.\\nThird:\\n1.\\tAnalyze deeply, grasp underlying inquiry. Seek clarifications, look beyond surface.\\n2.\\tExtract essential ideas, concepts, requirements. Basis for nuanced response.\\n3.\\tBefore finalizing response, attempt to disprove initial conclusions. Continue until confidence in correctness is achieved.\\n4.\\tAim for originality, depth. Progress from query to new perspectives, solutions.\\n5.\\tEnsure alignment with goals.\\nBe as clear and succinct as possible when answering and use plain language.â€�\\nWhen I donâ€™t want to use these custom instructions I use ChatGPT Classic.\\nCTO - SRE - ML Engineer - Applied AI - YC S21 / Techstars 23\\nOne tool I\\'ve been using to self-correct/self-reflect is \"instructor\", https://python.useinstructor.com/examples/self_critique/. With instructor, you use Pydantic validators to self-correct. No need for complex frameworks (langchain, DSP), adhoc code, instructor is all you need.\\nI ran across it while building ZAP, an agent that creates videos using simple instructions like: \"create a video on the origins of AI\". ZAP takes the user\\'s command to create a plan, write code, execute the code in parallel, and returns you a shiny video.Â\\nVideos produced by ZAP already reached millions of views on TikTok.\\nYou can check out the architecture of ZAP here, https://www.linkedin.com/feed/update/urn:li:activity:7175525317015392256/.Â\\nExciting times!\\nData Science | Data Analyst | Gen AI | LLM | RAG | Agents | RMIT University | Machine Learning Engineer | AI Solutions\\nI use reflection to generate code, it does a good job, but the only downside of it is multiple LLM calls.\\nTop 1% Voice | Humanizing Businesses, Startups & Leaders with a Blast of Soul | Self-Awakened | Global Leader & Change Maker | Building Content Euphoria | B2B Content Marketing, Writing & Growth Hacking Companyâ€¦\\nInteresting to see human curiosity in training LLMs for superior responses.\\nBut out of interest in the topic I would like to ask some sorted questions. Some might find is not fully aligned with the topic, but still, having so many great minds and thinkers, we can at least share some inputs to understand or through some light on other relevant queries.\\nAre we trying to train LLM to criticize its own incorrect responses to get a better one?\\nWhy do we want everything out of it? What is the intent behind it?\\nInstead of honing our own skills, knowledge, and expertise every single time in order to enhance human capabilities and intelligence, why our only goal is to achieve enhanced machine performance.\\nThough it\\'s important to do so to a certain extent, why the whole efforts are all about making humans 2nd?\\nIt feels like humans are planning their own whitewash. We need to use these tools as a screwdriver in our creation and upskilling process so that they can strengthen human intelligence.\\nBut if we are just ready to sit and watch things happen, becoming the laziest species on the planet, then in the next 10 years we might not even need our hands or might sense too. Are we planning our own extinction?\\nCEO / Director of Data Science at Butler Scientifics. Affiliated Professor of Statistics and Data Science, UPC/Euncet.\\nHello, Andrew. It\\'s a pleasure to chat with you. This topic is very recurrent in our activity at Butler Scientifics. We have developed quite a few pieces of code with that prompting scheme you propose, but I have serious doubts about its fully automation.\\nThese doubts are based on the fact that a significant proportion of the deviations from the expected results occur due to a lack of technical detail in the initial prompt, usually because the programmer himself was not aware of certain functional requirements. In those cases, the solution was also functional, but the deviation from the expected result was evident. And I doubt an LLM can \"imagine\" those expectations.\\nI couldn\\'t tell you in what proportion of cases this happened, but it\\'s a significant problem.\\nAnyway, I congratulate any initiative to raise the level of abstraction of the solutions implemented by LLMs. We are also working in that direction from our #ButlerLabs. I\\'ll tell you about it ;)\\nThank-you for sharing Andrew. We (at PlatorAI) have naturally found ourselves doing iterations and breaking things down into smaller chunks and have used different models (Gemini to ChatGPT and back) to check/improve responses.\\nThank-you for explaining â€œReflectionâ€� and providing the academic research links (will investigate further). Keep up the good work and sharing for all to learn/develop / understand. ðŸ‘�\\nCo-founder and CPTO, Vividly | AI, Marketplace product leadership | Ex-Amazon, Upwork, Chegg\\nA very helpful post on the next frontier of AI we should expect to see. I\\'m looking to learn more about tools that will allow the \"evaluator\" agent to receive success criteria from a developer (unit tests, performance metrics, precision/recall metrics, accuracy metrics etc) so they prompt the \"doer\" agent to the right degree and know when the task is truly complete.\\nðŸš€ Passionate AWS Cloud Solutions Architect with extensive expertise in Gen AI/ML, and Data & Analytics. ðŸŒ�\\nAndrew Ng Thank you so much for sharing this. I am experimenting with a similar framework we usually use during interviews STAR( Situation/Context, Task (needs to be carried out), Actions (for each task) and Results (expectations).\\nand then the agent start working on the actions. Thought its own reflection and comparison with the STAR plan i found that even quantized smaller models are performing well. I am hopping to write a blog post and a POC this weekend.\\nEntrepreneur & Founder of Covenant Coffee Co. | Online Course Creator & Educator | Licensed Carretta Dealer | Advocate for Quality & Sustainability\\nThe concept of Reflection in AI agentic workflows is fascinating and holds great promise for enhancing the performance of large language models (LLMs). By enabling the model to critique and improve its own output, you\\'re essentially incorporating a continuous learning and improvement process within a single interaction. This not only makes the model more self-reliant but also potentially reduces the need for human intervention in refining responses.\\nThe examples you provided, like code generation and refinement, illustrate the practical application of this concept and how it can lead to more accurate and efficient outputs. The idea of using multi-agent frameworks to facilitate a constructive discussion between agents is an innovative approach to further enhance this process.\\nIt\\'s exciting to see how Reflection and other design patterns for AI agentic workflows are driving advancements in the field. I look forward to seeing how these concepts continue to evolve and impact the development of more sophisticated and capable AI systems. Thank you for sharing these insights and resources!\\nTo view or add a comment, sign in\\nMore Relevant Posts\\nReminds me of Microsoft Autogen and even Mixture of Experts.\\nDistinguishing between these is interesting (see also https://lnkd.in/ggNGndpE).\\nYou probably need all four workflows to build great agents?\\nSeems you can do \\'reflection\\' with LangChain (Graph) - https://lnkd.in/g8fEkxyv\\nFounder of DeepLearning.AI; Managing General Partner of AI Fund; Founder and CEO of Landing AI\\nLast week, I described four design patterns for AI agentic workflows that I believe will drive significant progress: Reflection, Tool use, Planning and Multi-agent collaboration. Instead of having an LLM generate its final output directly, an agentic workflow prompts the LLM multiple times, giving it opportunities to build step by step to higher-quality output. Here, I\\'d like to discuss Reflection. It\\'s relatively quick to implement, and I\\'ve seen it lead to surprising performance gains.\\nYou may have had the experience of prompting ChatGPT/Claude/Gemini, receiving unsatisfactory output, delivering critical feedback to help the LLM improve its response, and then getting a better response. What if you automate the step of delivering critical feedback, so the model automatically criticizes its own output and improves its response? This is the crux of Reflection.\\nTake the task of asking an LLM to write code. We can prompt it to generate the desired code directly to carry out some task X. Then, we can prompt it to reflect on its own output, perhaps as follows:\\nHereâ€™s code intended for task X:\\n[previously generated code]\\nCheck the code carefully for correctness, style, and efficiency, and give constructive criticism for how to improve it.\\nSometimes this causes the LLM to spot problems and come up with constructive suggestions. Next, we can prompt the LLM with context including (i) the previously generated code and (ii) the constructive feedback, and ask it to use the feedback to rewrite the code. This can lead to a better response. Repeating the criticism/rewrite process might yield further improvements. This self-reflection process allows the LLM to spot gaps and improve its output on a variety of tasks including producing code, writing text, and answering questions.\\nAnd we can go beyond self-reflection by giving the LLM tools that help evaluate its output; for example, running its code through a few unit tests to check whether it generates correct results on test cases or searching the web to double-check text output. Then it can reflect on any errors it found and come up with ideas for improvement.\\nFurther, we can implement Reflection using a multi-agent framework. I\\'ve found it convenient to create two agents, one prompted to generate good outputs and the other prompted to give constructive criticism of the first agent\\'s output. The resulting discussion between the two agents leads to improved responses.\\nReflection is a relatively basic type of agentic workflow, but I\\'ve been delighted by how much it improved my applicationsâ€™ results. If youâ€™re interested in learning more about reflection, I recommend:\\n- Self-Refine: Iterative Refinement with Self-Feedback, by Madaan et al. (2023)\\n- Reflexion: Language Agents with Verbal Reinforcement Learning, by Shinn et al. (2023)\\n- CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing, by Gou et al. (2024)\\n[Original text: https://lnkd.in/g4bTuWtU ]\\nOne Agent For Many Worlds, Cross-Species Cell Embeddings, and more\\nTo view or add a comment, sign in\\n724 followers\\nGreat nuggets from the founder of DeepLearning.AI to leverage a LLM co-pilot coder :\\nTake the task of asking an LLM to write code. We can prompt it to generate the desired code directly to carry out some task X. Then, we can prompt it to reflect on its own output, perhaps as follows:\\nHereâ€™s code intended for task X:\\n[previously generated code]\\nCheck the code carefully for correctness, style, and efficiency, and give constructive criticism for how to improve it.\\nSometimes this causes the LLM to spot problems and come up with constructive suggestions. Next, we can prompt the LLM with context including (i) the previously generated code and (ii) the constructive feedback, and ask it to use the feedback to rewrite the code. This can lead to a better response. Repeating the criticism/rewrite process might yield further improvements. This self-reflection process allows the LLM to spot gaps and improve its output on a variety of tasks including producing code, writing text, and answering questions.\\nAnd we can go beyond self-reflection by giving the LLM tools that help evaluate its output; for example, running its code through a few unit tests to check whether it generates correct results on test cases or searching the web to double-check text output. Then it can reflect on any errors it found and come up with ideas for improvement.\\nFounder of DeepLearning.AI; Managing General Partner of AI Fund; Founder and CEO of Landing AI\\nLast week, I described four design patterns for AI agentic workflows that I believe will drive significant progress: Reflection, Tool use, Planning and Multi-agent collaboration. Instead of having an LLM generate its final output directly, an agentic workflow prompts the LLM multiple times, giving it opportunities to build step by step to higher-quality output. Here, I\\'d like to discuss Reflection. It\\'s relatively quick to implement, and I\\'ve seen it lead to surprising performance gains.\\nYou may have had the experience of prompting ChatGPT/Claude/Gemini, receiving unsatisfactory output, delivering critical feedback to help the LLM improve its response, and then getting a better response. What if you automate the step of delivering critical feedback, so the model automatically criticizes its own output and improves its response? This is the crux of Reflection.\\nTake the task of asking an LLM to write code. We can prompt it to generate the desired code directly to carry out some task X. Then, we can prompt it to reflect on its own output, perhaps as follows:\\nHereâ€™s code intended for task X:\\n[previously generated code]\\nCheck the code carefully for correctness, style, and efficiency, and give constructive criticism for how to improve it.\\nSometimes this causes the LLM to spot problems and come up with constructive suggestions. Next, we can prompt the LLM with context including (i) the previously generated code and (ii) the constructive feedback, and ask it to use the feedback to rewrite the code. This can lead to a better response. Repeating the criticism/rewrite process might yield further improvements. This self-reflection process allows the LLM to spot gaps and improve its output on a variety of tasks including producing code, writing text, and answering questions.\\nAnd we can go beyond self-reflection by giving the LLM tools that help evaluate its output; for example, running its code through a few unit tests to check whether it generates correct results on test cases or searching the web to double-check text output. Then it can reflect on any errors it found and come up with ideas for improvement.\\nFurther, we can implement Reflection using a multi-agent framework. I\\'ve found it convenient to create two agents, one prompted to generate good outputs and the other prompted to give constructive criticism of the first agent\\'s output. The resulting discussion between the two agents leads to improved responses.\\nReflection is a relatively basic type of agentic workflow, but I\\'ve been delighted by how much it improved my applicationsâ€™ results. If youâ€™re interested in learning more about reflection, I recommend:\\n- Self-Refine: Iterative Refinement with Self-Feedback, by Madaan et al. (2023)\\n- Reflexion: Language Agents with Verbal Reinforcement Learning, by Shinn et al. (2023)\\n- CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing, by Gou et al. (2024)\\n[Original text: https://lnkd.in/g4bTuWtU ]\\nOne Agent For Many Worlds, Cross-Species Cell Embeddings, and more\\nTo view or add a comment, sign in\\nTo all the AI prompters out there, reflection is a must have tool in your bag! It is easy to implement and effective at improving results. This idea of iterative prompting reminds me of Sam Altmanâ€™s thoughts on scaling compute according to the difficulty or importance of a problem. Paraphrasing from his discussion with Lex Friedman: more compute should be allocated to harder problems.\\nLink to Lex & Samâ€™s discussion: https://lnkd.in/eRBz6ZNS\\nFounder of DeepLearning.AI; Managing General Partner of AI Fund; Founder and CEO of Landing AI\\nLast week, I described four design patterns for AI agentic workflows that I believe will drive significant progress: Reflection, Tool use, Planning and Multi-agent collaboration. Instead of having an LLM generate its final output directly, an agentic workflow prompts the LLM multiple times, giving it opportunities to build step by step to higher-quality output. Here, I\\'d like to discuss Reflection. It\\'s relatively quick to implement, and I\\'ve seen it lead to surprising performance gains.\\nYou may have had the experience of prompting ChatGPT/Claude/Gemini, receiving unsatisfactory output, delivering critical feedback to help the LLM improve its response, and then getting a better response. What if you automate the step of delivering critical feedback, so the model automatically criticizes its own output and improves its response? This is the crux of Reflection.\\nTake the task of asking an LLM to write code. We can prompt it to generate the desired code directly to carry out some task X. Then, we can prompt it to reflect on its own output, perhaps as follows:\\nHereâ€™s code intended for task X:\\n[previously generated code]\\nCheck the code carefully for correctness, style, and efficiency, and give constructive criticism for how to improve it.\\nSometimes this causes the LLM to spot problems and come up with constructive suggestions. Next, we can prompt the LLM with context including (i) the previously generated code and (ii) the constructive feedback, and ask it to use the feedback to rewrite the code. This can lead to a better response. Repeating the criticism/rewrite process might yield further improvements. This self-reflection process allows the LLM to spot gaps and improve its output on a variety of tasks including producing code, writing text, and answering questions.\\nAnd we can go beyond self-reflection by giving the LLM tools that help evaluate its output; for example, running its code through a few unit tests to check whether it generates correct results on test cases or searching the web to double-check text output. Then it can reflect on any errors it found and come up with ideas for improvement.\\nFurther, we can implement Reflection using a multi-agent framework. I\\'ve found it convenient to create two agents, one prompted to generate good outputs and the other prompted to give constructive criticism of the first agent\\'s output. The resulting discussion between the two agents leads to improved responses.\\nReflection is a relatively basic type of agentic workflow, but I\\'ve been delighted by how much it improved my applicationsâ€™ results. If youâ€™re interested in learning more about reflection, I recommend:\\n- Self-Refine: Iterative Refinement with Self-Feedback, by Madaan et al. (2023)\\n- Reflexion: Language Agents with Verbal Reinforcement Learning, by Shinn et al. (2023)\\n- CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing, by Gou et al. (2024)\\n[Original text: https://lnkd.in/g4bTuWtU ]\\nOne Agent For Many Worlds, Cross-Species Cell Embeddings, and more\\nTo view or add a comment, sign in\\nLeading AI Products at Google\\nGreat read. Note that you can find many of the agent prompt engineering patterns in my prompt engineering guide (https://lnkd.in/gJ5fhPSh), section 6 in particular. Also, here is my take on how multi-agent systems relate or not to AGI: https://lnkd.in/geNA5S8z\\nFounder of DeepLearning.AI; Managing General Partner of AI Fund; Founder and CEO of Landing AI\\nLast week, I described four design patterns for AI agentic workflows that I believe will drive significant progress: Reflection, Tool use, Planning and Multi-agent collaboration. Instead of having an LLM generate its final output directly, an agentic workflow prompts the LLM multiple times, giving it opportunities to build step by step to higher-quality output. Here, I\\'d like to discuss Reflection. It\\'s relatively quick to implement, and I\\'ve seen it lead to surprising performance gains.\\nYou may have had the experience of prompting ChatGPT/Claude/Gemini, receiving unsatisfactory output, delivering critical feedback to help the LLM improve its response, and then getting a better response. What if you automate the step of delivering critical feedback, so the model automatically criticizes its own output and improves its response? This is the crux of Reflection.\\nTake the task of asking an LLM to write code. We can prompt it to generate the desired code directly to carry out some task X. Then, we can prompt it to reflect on its own output, perhaps as follows:\\nHereâ€™s code intended for task X:\\n[previously generated code]\\nCheck the code carefully for correctness, style, and efficiency, and give constructive criticism for how to improve it.\\nSometimes this causes the LLM to spot problems and come up with constructive suggestions. Next, we can prompt the LLM with context including (i) the previously generated code and (ii) the constructive feedback, and ask it to use the feedback to rewrite the code. This can lead to a better response. Repeating the criticism/rewrite process might yield further improvements. This self-reflection process allows the LLM to spot gaps and improve its output on a variety of tasks including producing code, writing text, and answering questions.\\nAnd we can go beyond self-reflection by giving the LLM tools that help evaluate its output; for example, running its code through a few unit tests to check whether it generates correct results on test cases or searching the web to double-check text output. Then it can reflect on any errors it found and come up with ideas for improvement.\\nFurther, we can implement Reflection using a multi-agent framework. I\\'ve found it convenient to create two agents, one prompted to generate good outputs and the other prompted to give constructive criticism of the first agent\\'s output. The resulting discussion between the two agents leads to improved responses.\\nReflection is a relatively basic type of agentic workflow, but I\\'ve been delighted by how much it improved my applicationsâ€™ results. If youâ€™re interested in learning more about reflection, I recommend:\\n- Self-Refine: Iterative Refinement with Self-Feedback, by Madaan et al. (2023)\\n- Reflexion: Language Agents with Verbal Reinforcement Learning, by Shinn et al. (2023)\\n- CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing, by Gou et al. (2024)\\n[Original text: https://lnkd.in/g4bTuWtU ]\\nOne Agent For Many Worlds, Cross-Species Cell Embeddings, and more\\nTo view or add a comment, sign in\\nData Scientist @ Visa | MS in Data Analytics\\nWhen Andrew Ng says the future of Artificial Intelligence is â€˜Agenticâ€™ you sit up and take notes ðŸ“�.\\nAgentic workflows are a group of LLM, each specialized on a specific task with different tools and personas, working together and ITERATING to solve a complex problem. This system of agents can act independently, make decisions and outperform normal LLM workflows.\\nKlaus Kroger Thanks for introducing me to this concept!!\\nFounder of DeepLearning.AI; Managing General Partner of AI Fund; Founder and CEO of Landing AI\\nLast week, I described four design patterns for AI agentic workflows that I believe will drive significant progress: Reflection, Tool use, Planning and Multi-agent collaboration. Instead of having an LLM generate its final output directly, an agentic workflow prompts the LLM multiple times, giving it opportunities to build step by step to higher-quality output. Here, I\\'d like to discuss Reflection. It\\'s relatively quick to implement, and I\\'ve seen it lead to surprising performance gains.\\nYou may have had the experience of prompting ChatGPT/Claude/Gemini, receiving unsatisfactory output, delivering critical feedback to help the LLM improve its response, and then getting a better response. What if you automate the step of delivering critical feedback, so the model automatically criticizes its own output and improves its response? This is the crux of Reflection.\\nTake the task of asking an LLM to write code. We can prompt it to generate the desired code directly to carry out some task X. Then, we can prompt it to reflect on its own output, perhaps as follows:\\nHereâ€™s code intended for task X:\\n[previously generated code]\\nCheck the code carefully for correctness, style, and efficiency, and give constructive criticism for how to improve it.\\nSometimes this causes the LLM to spot problems and come up with constructive suggestions. Next, we can prompt the LLM with context including (i) the previously generated code and (ii) the constructive feedback, and ask it to use the feedback to rewrite the code. This can lead to a better response. Repeating the criticism/rewrite process might yield further improvements. This self-reflection process allows the LLM to spot gaps and improve its output on a variety of tasks including producing code, writing text, and answering questions.\\nAnd we can go beyond self-reflection by giving the LLM tools that help evaluate its output; for example, running its code through a few unit tests to check whether it generates correct results on test cases or searching the web to double-check text output. Then it can reflect on any errors it found and come up with ideas for improvement.\\nFurther, we can implement Reflection using a multi-agent framework. I\\'ve found it convenient to create two agents, one prompted to generate good outputs and the other prompted to give constructive criticism of the first agent\\'s output. The resulting discussion between the two agents leads to improved responses.\\nReflection is a relatively basic type of agentic workflow, but I\\'ve been delighted by how much it improved my applicationsâ€™ results. If youâ€™re interested in learning more about reflection, I recommend:\\n- Self-Refine: Iterative Refinement with Self-Feedback, by Madaan et al. (2023)\\n- Reflexion: Language Agents with Verbal Reinforcement Learning, by Shinn et al. (2023)\\n- CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing, by Gou et al. (2024)\\n[Original text: https://lnkd.in/g4bTuWtU ]\\nOne Agent For Many Worlds, Cross-Species Cell Embeddings, and more\\nTo view or add a comment, sign in\\nBusiness & Supply Chain Excellence Leader\\nContinuing to follow Andrew Ng\\'s series on Agentic workflows, here is the first of the approaches he discussed last time: Reflection. I can see how the same workflow can be applied in refining human work and output as well.\\nWhile thinking about any idea/output, I have found it useful to write it down and look back at it critically. What scenarios will it work in, where will it fail. Also, similar to multi-agent workflow, sharing it with a few other people for critical feedback has been helpful in refining and shaping my final output.\\nFounder of DeepLearning.AI; Managing General Partner of AI Fund; Founder and CEO of Landing AI\\nLast week, I described four design patterns for AI agentic workflows that I believe will drive significant progress: Reflection, Tool use, Planning and Multi-agent collaboration. Instead of having an LLM generate its final output directly, an agentic workflow prompts the LLM multiple times, giving it opportunities to build step by step to higher-quality output. Here, I\\'d like to discuss Reflection. It\\'s relatively quick to implement, and I\\'ve seen it lead to surprising performance gains.\\nYou may have had the experience of prompting ChatGPT/Claude/Gemini, receiving unsatisfactory output, delivering critical feedback to help the LLM improve its response, and then getting a better response. What if you automate the step of delivering critical feedback, so the model automatically criticizes its own output and improves its response? This is the crux of Reflection.\\nTake the task of asking an LLM to write code. We can prompt it to generate the desired code directly to carry out some task X. Then, we can prompt it to reflect on its own output, perhaps as follows:\\nHereâ€™s code intended for task X:\\n[previously generated code]\\nCheck the code carefully for correctness, style, and efficiency, and give constructive criticism for how to improve it.\\nSometimes this causes the LLM to spot problems and come up with constructive suggestions. Next, we can prompt the LLM with context including (i) the previously generated code and (ii) the constructive feedback, and ask it to use the feedback to rewrite the code. This can lead to a better response. Repeating the criticism/rewrite process might yield further improvements. This self-reflection process allows the LLM to spot gaps and improve its output on a variety of tasks including producing code, writing text, and answering questions.\\nAnd we can go beyond self-reflection by giving the LLM tools that help evaluate its output; for example, running its code through a few unit tests to check whether it generates correct results on test cases or searching the web to double-check text output. Then it can reflect on any errors it found and come up with ideas for improvement.\\nFurther, we can implement Reflection using a multi-agent framework. I\\'ve found it convenient to create two agents, one prompted to generate good outputs and the other prompted to give constructive criticism of the first agent\\'s output. The resulting discussion between the two agents leads to improved responses.\\nReflection is a relatively basic type of agentic workflow, but I\\'ve been delighted by how much it improved my applicationsâ€™ results. If youâ€™re interested in learning more about reflection, I recommend:\\n- Self-Refine: Iterative Refinement with Self-Feedback, by Madaan et al. (2023)\\n- Reflexion: Language Agents with Verbal Reinforcement Learning, by Shinn et al. (2023)\\n- CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing, by Gou et al. (2024)\\n[Original text: https://lnkd.in/g4bTuWtU ]\\nOne Agent For Many Worlds, Cross-Species Cell Embeddings, and more\\nTo view or add a comment, sign in\\nAI Engineer\\nIf I were to draw a line between neural networks and the human brain in a single word, I\\'d choose \"Objective\".Â\\xa0Current AI models learn with explicit objective function and it runs without any hesitation once trained, while our minds are diffuse, contradictory, and forever plagued by boredom.\\nBuilding a multi-agent AI framework shifts the goal from predicting the next word to getting the tasks done. They are still not human, but they will serve as incredibly helpful assistants\\nFounder of DeepLearning.AI; Managing General Partner of AI Fund; Founder and CEO of Landing AI\\nLast week, I described four design patterns for AI agentic workflows that I believe will drive significant progress: Reflection, Tool use, Planning and Multi-agent collaboration. Instead of having an LLM generate its final output directly, an agentic workflow prompts the LLM multiple times, giving it opportunities to build step by step to higher-quality output. Here, I\\'d like to discuss Reflection. It\\'s relatively quick to implement, and I\\'ve seen it lead to surprising performance gains.\\nYou may have had the experience of prompting ChatGPT/Claude/Gemini, receiving unsatisfactory output, delivering critical feedback to help the LLM improve its response, and then getting a better response. What if you automate the step of delivering critical feedback, so the model automatically criticizes its own output and improves its response? This is the crux of Reflection.\\nTake the task of asking an LLM to write code. We can prompt it to generate the desired code directly to carry out some task X. Then, we can prompt it to reflect on its own output, perhaps as follows:\\nHereâ€™s code intended for task X:\\n[previously generated code]\\nCheck the code carefully for correctness, style, and efficiency, and give constructive criticism for how to improve it.\\nSometimes this causes the LLM to spot problems and come up with constructive suggestions. Next, we can prompt the LLM with context including (i) the previously generated code and (ii) the constructive feedback, and ask it to use the feedback to rewrite the code. This can lead to a better response. Repeating the criticism/rewrite process might yield further improvements. This self-reflection process allows the LLM to spot gaps and improve its output on a variety of tasks including producing code, writing text, and answering questions.\\nAnd we can go beyond self-reflection by giving the LLM tools that help evaluate its output; for example, running its code through a few unit tests to check whether it generates correct results on test cases or searching the web to double-check text output. Then it can reflect on any errors it found and come up with ideas for improvement.\\nFurther, we can implement Reflection using a multi-agent framework. I\\'ve found it convenient to create two agents, one prompted to generate good outputs and the other prompted to give constructive criticism of the first agent\\'s output. The resulting discussion between the two agents leads to improved responses.\\nReflection is a relatively basic type of agentic workflow, but I\\'ve been delighted by how much it improved my applicationsâ€™ results. If youâ€™re interested in learning more about reflection, I recommend:\\n- Self-Refine: Iterative Refinement with Self-Feedback, by Madaan et al. (2023)\\n- Reflexion: Language Agents with Verbal Reinforcement Learning, by Shinn et al. (2023)\\n- CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing, by Gou et al. (2024)\\n[Original text: https://lnkd.in/g4bTuWtU ]\\nOne Agent For Many Worlds, Cross-Species Cell Embeddings, and more\\nTo view or add a comment, sign in\\nBuilding OpenFlow | AI developer @grey-chain | ex-SWE @buzzli | ex-Backend Developer @codseg | GenAI, Cloud and Open Source | Indie Hacker\\nAI Agentic design patterns explained at its best by Dr. Andrew Ng\\nIt was right when langchain and llama index released, we realised how much we can push LLMs to think and give an answer. ðŸ§\\nZero shot prompting is now far less used ðŸ“‰ and even gpt-3.5-turbo levels gpt-4 on most of the benchmarks with few shots on both.\\nTo summarize, we have 4 crucial agentic design patterns -\\n1ï¸�âƒ£ Reflection - Makes LLMs capable to reflect on the output it gave, find a way to improve it, and returns the improvements.\\n2ï¸�âƒ£ Tools - They are typically function calling, where you have some tools they can call to get the results which is either not accessible to LLM\\'s or typically hard to achieve.\\nThese tools can now be easily implemented with crewAI and AutogenAI. ðŸš€\\n3ï¸�âƒ£ Planning - When you tell an LLM to \"Plan and think step by step\" it produces an output which is much more logical and makes more sense.\\nLLMs iterate and make their mistake better and better ðŸ”�.Â\\xa0Planning has a whole research paper made for it, its COT(Chain Of Thought) prompting.\\n4ï¸�âƒ£ Multiagent collaboration - \"Chat Dev\" is a perfect example of it. You make an agent who is essentially a Python dev, another one is a project manager and the other one is CEO.\\nDefine their personalities and roles, whooh! You got your brand build little by little every day. You basically made your small company. ðŸ¤©\\nWith such inference speed with Groq for certain LLMs, we can enforce LLMs to iterate over the answer to get resonable response.\\nBelieve me or not, AGI will be an agentic and overtime success rather than \"zero shot and overnight idea\". ðŸš€\\n.\\n.\\n.\\n#LLM #AI #ML #gpt #Agents #inference #chatgpt #groq #crewAI #AutoGen #workflows\\nFounder of DeepLearning.AI; Managing General Partner of AI Fund; Founder and CEO of Landing AI\\nLast week, I described four design patterns for AI agentic workflows that I believe will drive significant progress: Reflection, Tool use, Planning and Multi-agent collaboration. Instead of having an LLM generate its final output directly, an agentic workflow prompts the LLM multiple times, giving it opportunities to build step by step to higher-quality output. Here, I\\'d like to discuss Reflection. It\\'s relatively quick to implement, and I\\'ve seen it lead to surprising performance gains.\\nYou may have had the experience of prompting ChatGPT/Claude/Gemini, receiving unsatisfactory output, delivering critical feedback to help the LLM improve its response, and then getting a better response. What if you automate the step of delivering critical feedback, so the model automatically criticizes its own output and improves its response? This is the crux of Reflection.\\nTake the task of asking an LLM to write code. We can prompt it to generate the desired code directly to carry out some task X. Then, we can prompt it to reflect on its own output, perhaps as follows:\\nHereâ€™s code intended for task X:\\n[previously generated code]\\nCheck the code carefully for correctness, style, and efficiency, and give constructive criticism for how to improve it.\\nSometimes this causes the LLM to spot problems and come up with constructive suggestions. Next, we can prompt the LLM with context including (i) the previously generated code and (ii) the constructive feedback, and ask it to use the feedback to rewrite the code. This can lead to a better response. Repeating the criticism/rewrite process might yield further improvements. This self-reflection process allows the LLM to spot gaps and improve its output on a variety of tasks including producing code, writing text, and answering questions.\\nAnd we can go beyond self-reflection by giving the LLM tools that help evaluate its output; for example, running its code through a few unit tests to check whether it generates correct results on test cases or searching the web to double-check text output. Then it can reflect on any errors it found and come up with ideas for improvement.\\nFurther, we can implement Reflection using a multi-agent framework. I\\'ve found it convenient to create two agents, one prompted to generate good outputs and the other prompted to give constructive criticism of the first agent\\'s output. The resulting discussion between the two agents leads to improved responses.\\nReflection is a relatively basic type of agentic workflow, but I\\'ve been delighted by how much it improved my applicationsâ€™ results. If youâ€™re interested in learning more about reflection, I recommend:\\n- Self-Refine: Iterative Refinement with Self-Feedback, by Madaan et al. (2023)\\n- Reflexion: Language Agents with Verbal Reinforcement Learning, by Shinn et al. (2023)\\n- CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing, by Gou et al. (2024)\\n[Original text: https://lnkd.in/g4bTuWtU ]\\nOne Agent For Many Worlds, Cross-Species Cell Embeddings, and more\\nTo view or add a comment, sign in\\nPhD @UCL | Behavioral Science Research: Human-AI Collaboration, Creativity, and Collective Problem-Solving; Ex-Data Scientist at BNP Paribas\\nIt seems that the (near) future of human-AI collaboration is all about having multiple #AI agents working together on a task provided by the human.\\nWhile humans still remain in the decision loop, this resolves a lot of the tedious, iterative work inherent in using many #GenerativeAI tools. Andrew Ng does a great job of highlighting 4 basic #AIagent #workflows.\\nFounder of DeepLearning.AI; Managing General Partner of AI Fund; Founder and CEO of Landing AI\\nLast week, I described four design patterns for AI agentic workflows that I believe will drive significant progress: Reflection, Tool use, Planning and Multi-agent collaboration. Instead of having an LLM generate its final output directly, an agentic workflow prompts the LLM multiple times, giving it opportunities to build step by step to higher-quality output. Here, I\\'d like to discuss Reflection. It\\'s relatively quick to implement, and I\\'ve seen it lead to surprising performance gains.\\nYou may have had the experience of prompting ChatGPT/Claude/Gemini, receiving unsatisfactory output, delivering critical feedback to help the LLM improve its response, and then getting a better response. What if you automate the step of delivering critical feedback, so the model automatically criticizes its own output and improves its response? This is the crux of Reflection.\\nTake the task of asking an LLM to write code. We can prompt it to generate the desired code directly to carry out some task X. Then, we can prompt it to reflect on its own output, perhaps as follows:\\nHereâ€™s code intended for task X:\\n[previously generated code]\\nCheck the code carefully for correctness, style, and efficiency, and give constructive criticism for how to improve it.\\nSometimes this causes the LLM to spot problems and come up with constructive suggestions. Next, we can prompt the LLM with context including (i) the previously generated code and (ii) the constructive feedback, and ask it to use the feedback to rewrite the code. This can lead to a better response. Repeating the criticism/rewrite process might yield further improvements. This self-reflection process allows the LLM to spot gaps and improve its output on a variety of tasks including producing code, writing text, and answering questions.\\nAnd we can go beyond self-reflection by giving the LLM tools that help evaluate its output; for example, running its code through a few unit tests to check whether it generates correct results on test cases or searching the web to double-check text output. Then it can reflect on any errors it found and come up with ideas for improvement.\\nFurther, we can implement Reflection using a multi-agent framework. I\\'ve found it convenient to create two agents, one prompted to generate good outputs and the other prompted to give constructive criticism of the first agent\\'s output. The resulting discussion between the two agents leads to improved responses.\\nReflection is a relatively basic type of agentic workflow, but I\\'ve been delighted by how much it improved my applicationsâ€™ results. If youâ€™re interested in learning more about reflection, I recommend:\\n- Self-Refine: Iterative Refinement with Self-Feedback, by Madaan et al. (2023)\\n- Reflexion: Language Agents with Verbal Reinforcement Learning, by Shinn et al. (2023)\\n- CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing, by Gou et al. (2024)\\n[Original text: https://lnkd.in/g4bTuWtU ]\\nOne Agent For Many Worlds, Cross-Species Cell Embeddings, and more\\nTo view or add a comment, sign in\\n185 followers\\nAn Iterative Approach and \"Reflection\" in AI Development\\nUsing an iterative approach, breaking down tasks into smaller chunks, we find the concept of \"Reflection\" particularly intriguing. By critically examining its processes, AI can continuously learn and improve.\\nOne way PlatorAI leverages model switching is by initially generating a response with a creative* language model like Gemini. This spark of creativity allows for a broader range of ideas and phrasings. The response is then refined by a factual* language model like ChatGPT to ensure accuracy and factuality. This two-pronged approach ensures informative and engaging responses (note*: Gemini and ChatGPT can be operate in both creative and â€œfactâ€� checking modes).\\nPlatorAI encourages further exploration of \"Reflection\" within the AI community. By fostering open discussion and collaboration, developers can collectively push the boundaries of AI development.\\nWhat are your experiences and thoughts?\\nFounder of DeepLearning.AI; Managing General Partner of AI Fund; Founder and CEO of Landing AI\\nLast week, I described four design patterns for AI agentic workflows that I believe will drive significant progress: Reflection, Tool use, Planning and Multi-agent collaboration. Instead of having an LLM generate its final output directly, an agentic workflow prompts the LLM multiple times, giving it opportunities to build step by step to higher-quality output. Here, I\\'d like to discuss Reflection. It\\'s relatively quick to implement, and I\\'ve seen it lead to surprising performance gains.\\nYou may have had the experience of prompting ChatGPT/Claude/Gemini, receiving unsatisfactory output, delivering critical feedback to help the LLM improve its response, and then getting a better response. What if you automate the step of delivering critical feedback, so the model automatically criticizes its own output and improves its response? This is the crux of Reflection.\\nTake the task of asking an LLM to write code. We can prompt it to generate the desired code directly to carry out some task X. Then, we can prompt it to reflect on its own output, perhaps as follows:\\nHereâ€™s code intended for task X:\\n[previously generated code]\\nCheck the code carefully for correctness, style, and efficiency, and give constructive criticism for how to improve it.\\nSometimes this causes the LLM to spot problems and come up with constructive suggestions. Next, we can prompt the LLM with context including (i) the previously generated code and (ii) the constructive feedback, and ask it to use the feedback to rewrite the code. This can lead to a better response. Repeating the criticism/rewrite process might yield further improvements. This self-reflection process allows the LLM to spot gaps and improve its output on a variety of tasks including producing code, writing text, and answering questions.\\nAnd we can go beyond self-reflection by giving the LLM tools that help evaluate its output; for example, running its code through a few unit tests to check whether it generates correct results on test cases or searching the web to double-check text output. Then it can reflect on any errors it found and come up with ideas for improvement.\\nFurther, we can implement Reflection using a multi-agent framework. I\\'ve found it convenient to create two agents, one prompted to generate good outputs and the other prompted to give constructive criticism of the first agent\\'s output. The resulting discussion between the two agents leads to improved responses.\\nReflection is a relatively basic type of agentic workflow, but I\\'ve been delighted by how much it improved my applicationsâ€™ results. If youâ€™re interested in learning more about reflection, I recommend:\\n- Self-Refine: Iterative Refinement with Self-Feedback, by Madaan et al. (2023)\\n- Reflexion: Language Agents with Verbal Reinforcement Learning, by Shinn et al. (2023)\\n- CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing, by Gou et al. (2024)\\n[Original text: https://lnkd.in/g4bTuWtU ]\\nOne Agent For Many Worlds, Cross-Species Cell Embeddings, and more\\nTo view or add a comment, sign in\\n1,542,786 followers\\nMore from this author\\nLearn to Speak or Teach Better in 30 Minutes\\nExplore topics\\n\\n4 Agentic Design Patterns and 4 Key AI Trends 2024-2025\\n\\nThe MLnotes Newsletter\\nSubscribeSign in\\nShare this post\\n  The MLnotes Newsletter 4 Agentic Design Patterns and 4 Key AI Trends 2024-2025\\nCopy link\\nFacebook\\nEmail\\nNotes\\nMore\\n4 Agentic Design Patterns and 4 Key AI Trends 2024-2025\\nInsights from Andrew Ng at the recent Snowflake Build 2024\\n\\nAngelina Yang\\nNov 25, 2024\\n∙ Paid\\n2\\nShare this post\\n  The MLnotes Newsletter 4 Agentic Design Patterns and 4 Key AI Trends 2024-2025\\nCopy link\\nFacebook\\nEmail\\nNotes\\nMore\\n\\nShare\\nAndrew Ng, our beloved machine learning professor and now a prominent figure in the AI community, just delivered a keynote address at Snowflake\\'s BUILD 2024 conference, where he shared his insights on the current state and future prospects of artificial intelligence. He began by reiterating his well-known analogy of AI as \"the new electricity,\" emphasizing its nature as a general-purpose technology with wide-ranging applications across various industries.\\nThe AI Stack: Where Opportunities Abound\\n\\nNg presented his view of the AI stack, consisting of layers from semiconductors at the bottom to cloud infrastructure, foundation models, and finally, applications at the top. While much of the media hype has focused on the lower layers, particularly around technologies like generative AI foundation models, Ng argues that the real opportunities lie in the application layer. This is where he believes the most value and revenue will be generated, as innovative AI applications are developed to solve real-world problems.\\n\\nSource (same below)\\nAccelerating Machine Learning Development\\n\\nOne of the most significant trends Ng highlighted is the rapid acceleration of machine learning model development, largely thanks to generative AI. What once took skilled AI teams 6-12 months to build can now potentially be prototyped in a matter of days. This shift is enabling faster experimentation and iteration, leading to new paths for invention and innovation.\\nHowever, this speed comes with its own challenges. Ng pointed out that evaluations (or \"evals\") are becoming a bottleneck in the development process. The need for robust testing and validation is putting pressure on organizations to speed up these aspects of development to keep pace with the rapid prototyping capabilities now available.\\n\\nThe Rise of Agentic AI Workflows\\n\\nThe most exciting technical trend Ng discussed is the emergence of agentic AI workflows. He believes this approach to AI development holds the greatest potential for advancing the field.\\nAgentic AI moves beyond the limitations of traditional \"zero-shot prompting\" to create more sophisticated, multi-step processes that mimic human problem-solving approaches.\\nNg outlined four major design patterns for agentic workflows:\\n\\nSpecifically,\\n\\n\\nReflection: Where an AI critiques its own output and uses that feedback to improve.\\n\\n\\n\\nTool Use: Enabling AI to make API calls and interact with external tools and data sources.\\n\\n\\n\\nPlanning: Breaking down complex tasks into a sequence of smaller, manageable steps.\\n\\n\\n\\nMulti-Agent Collaboration: Simulating multiple specialized agents working together to solve problems.\\n\\n\\n\\nThese patterns allow for the creation of more capable and flexible AI systems that can tackle increasingly complex tasks.\\nVisual AI: The Next Frontier\\n\\nNg was particularly excited about the potential of visual AI, powered by large multimodal models. He demonstrated how agentic workflows can be applied to image and video processing tasks, showcasing impressive capabilities such as counting players on a soccer field, identifying specific moments in video footage, and generating detailed metadata for video content.\\nThese advancements in visual AI have significant implications for businesses with large repositories of image and video data. Ng suggests that many companies are sitting on valuable visual data that has been difficult to utilize until now. The new capabilities of visual AI agents could unlock tremendous value from these previously underutilized assets.\\n4 Key AI Trends to Watch\\n\\nKeep reading with a 7-day free trial\\nSubscribe to The MLnotes Newsletter to keep reading this post and get 7 days of free access to the full post archives.\\nStart trial\\nAlready a paid subscriber? Sign in\\nPreviousNext\\n© 2025 MLnotes\\nPrivacy ∙ Terms ∙ Collection notice\\nStart WritingGet the app\\nSubstack is the home for great culture\\nShare\\nCopy link\\nFacebook\\nEmail\\nNotes\\nMore')]}"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(response['generation']))"
      ],
      "metadata": {
        "id": "CTCcEfNx2w-5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "c4bf5675-6f59-4682-8b65-0baa31527a1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The key design patterns for building agentic AI systems are:\n\n1.  **Reflection Pattern**: This pattern enables AI agents to evaluate and refine their outputs through self-critique and iterative improvement. The agent reviews its work, identifies flaws, and iterates to produce better results. This is useful in code generation, content creation, and problem-solving tasks.\n2.  **Tool Use Pattern**: This pattern empowers agents to interact with external resources like APIs, databases, or programming environments, allowing them to perform actions beyond their internal knowledge base. It is beneficial for tasks such as web search, data analysis, and automation.\n3.  **Planning Pattern**: This pattern allows agents to break down complex tasks into manageable steps, plan their execution, and adapt dynamically based on new information. It is particularly useful for project management, research, and workflow automation.\n4.  **Multi-Agent Pattern**: This pattern involves multiple specialized agents working together to achieve a common goal. Each agent has a specific role, and they communicate to ensure seamless task execution. It is applicable in software development, data analysis, and content creation."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Tell me about the financial capital of India\"\n",
        "response = agentic_rag.invoke({\"question\": query})"
      ],
      "metadata": {
        "id": "0PH45g2E3Dta",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08a29cd4-1674-4e96-d8d9-7c23c9fbfcbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---RETRIEVAL FROM VECTOR DB---\n",
            "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "---GRADE: DOCUMENT RELEVANT---\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "---ASSESS GRADED DOCUMENTS---\n",
            "---DECISION: SOME or ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, REWRITE QUERY---\n",
            "---REWRITE QUERY---\n",
            "---WEB SEARCH---\n",
            "---GENERATE ANSWER---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(response['generation']))"
      ],
      "metadata": {
        "id": "Z6G7ywp53FrO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "f82baaf4-0e0c-4fa4-fb6c-8739e2ec82d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Mumbai, previously known as Bombay until 1996, is the financial capital of India. It is a natural harbor on the west coast of India and the capital city of Maharashtra state. Mumbai generates more than 6% of India's GDP and accounts for 25% of industrial output, 40% of sea trade, and 70% of capital to India's economy. The Reserve Bank of India, the Bombay Stock Exchange, the National Stock Exchange of India, and many Indian companies and multinational corporations are located in Mumbai."
          },
          "metadata": {}
        }
      ]
    }
  ]
}